{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('kaggle datasets download -d uciml/breast-cancer-wisconsin-data -f data.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS = 'diagnosis'\n",
    "TARGET = 'radius_mean'\n",
    "FEATURES_PREFIX = 'mean'\n",
    "FEATURES = [feature for feature in df.columns if \\\n",
    "            (feature not in TARGET) and (FEATURES_PREFIX in feature)]\n",
    "N_FEATURES = len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0         10.38          122.80     1001.0          0.11840           0.27760   \n",
       "1         17.77          132.90     1326.0          0.08474           0.07864   \n",
       "2         21.25          130.00     1203.0          0.10960           0.15990   \n",
       "3         20.38           77.58      386.1          0.14250           0.28390   \n",
       "4         14.34          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  \n",
       "0          0.3001              0.14710         0.2419                 0.07871  \n",
       "1          0.0869              0.07017         0.1812                 0.05667  \n",
       "2          0.1974              0.12790         0.2069                 0.05999  \n",
       "3          0.2414              0.10520         0.2597                 0.09744  \n",
       "4          0.1980              0.10430         0.1809                 0.05883  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[TARGET]\n",
    "x = df[FEATURES]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = df[DIAGNOSIS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= x.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264257</td>\n",
       "      <td>0.651459</td>\n",
       "      <td>0.400240</td>\n",
       "      <td>0.724602</td>\n",
       "      <td>0.803706</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.807779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.596053</td>\n",
       "      <td>0.581589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.670747</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.680592</td>\n",
       "      <td>0.615661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518839</td>\n",
       "      <td>0.411565</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.854276</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365071</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.518593</td>\n",
       "      <td>0.613831</td>\n",
       "      <td>0.384482</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.595066</td>\n",
       "      <td>0.603756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0      0.264257        0.651459   0.400240         0.724602          0.803706   \n",
       "1      0.452393        0.705040   0.530188         0.518605          0.227678   \n",
       "2      0.540988        0.689655   0.481008         0.670747          0.462942   \n",
       "3      0.518839        0.411565   0.154378         0.872093          0.821946   \n",
       "4      0.365071        0.716711   0.518593         0.613831          0.384482   \n",
       "\n",
       "   concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  \n",
       "0        0.703140             0.731113       0.795724                0.807779  \n",
       "1        0.203608             0.348757       0.596053                0.581589  \n",
       "2        0.462512             0.635686       0.680592                0.615661  \n",
       "3        0.565604             0.522863       0.854276                1.000000  \n",
       "4        0.463918             0.518390       0.595066                0.603756  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train, Val & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_healthy, y_healthy = x[diagnosis == 'B'], y[diagnosis == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(x_healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_idxs = np.random.choice(x_healthy.index, TRAIN_SIZE, replace=False)\n",
    "val_idxs = x_healthy.index.drop(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for training: 285\n",
      "# Examples for validation: 72\n"
     ]
    }
   ],
   "source": [
    "x_train = x_healthy.loc[train_idxs].values\n",
    "y_train = y_healthy.loc[train_idxs].values\n",
    "print('# Examples for training:',  len(x_train))\n",
    "\n",
    "x_val = x_healthy.loc[val_idxs].values\n",
    "y_val = y_healthy.loc[val_idxs].values\n",
    "print('# Examples for validation:',  len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unhealthy, y_unhealthy = x[diagnosis == 'M'], y[diagnosis == 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for test: 212\n"
     ]
    }
   ],
   "source": [
    "x_test = x_unhealthy.values\n",
    "y_test = y_unhealthy.values\n",
    "print('# Examples for test:',  len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bearch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(n_hidden):\n",
    "    i = Input((N_FEATURES, ))\n",
    "    h = Dense(n_hidden, kernel_initializer='normal', use_bias=True)(i)\n",
    "    h = LeakyReLU()(h)\n",
    "    o = Dense(1)(h)\n",
    "    return Model(i, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "N_MODELS = 5\n",
    "n_hidden_neurons = 32\n",
    "for _ in range(N_MODELS):\n",
    "    models.append(create_base_model(n_hidden_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 353\n",
      "Trainable params: 353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, lr, batch_size, epochs=50, history=None):\n",
    "    current_epoch = 0 if history is None else len(history.history['loss'])\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    new_history = model.fit(\n",
    "        train_data[0], train_data[1], epochs=current_epoch+epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=val_data,\n",
    "        initial_epoch=current_epoch,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if history is not None:\n",
    "        for key in new_history.history:\n",
    "            history.history[key].extend(new_history.history[key])\n",
    "    else:\n",
    "        history = new_history\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 4s 13ms/step - loss: 148.8573 - mean_squared_error: 148.8573 - val_loss: 18.5348 - val_mean_squared_error: 18.5348\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 20.3959 - mean_squared_error: 20.3959 - val_loss: 949.5780 - val_mean_squared_error: 949.5780\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 889.4991 - mean_squared_error: 889.4991 - val_loss: 38.2756 - val_mean_squared_error: 38.2756\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 34.6568 - mean_squared_error: 34.6568 - val_loss: 64.7996 - val_mean_squared_error: 64.7996\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 66.0322 - mean_squared_error: 66.0322 - val_loss: 110.7904 - val_mean_squared_error: 110.7904\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 110.8513 - mean_squared_error: 110.8513 - val_loss: 49.3032 - val_mean_squared_error: 49.3032\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 50.8314 - mean_squared_error: 50.8314 - val_loss: 5.1030 - val_mean_squared_error: 5.1030\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1158 - mean_squared_error: 5.1158 - val_loss: 128.9938 - val_mean_squared_error: 128.9938\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 118.5831 - mean_squared_error: 118.5831 - val_loss: 179.6307 - val_mean_squared_error: 179.6307\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 165.8216 - mean_squared_error: 165.8216 - val_loss: 87.2379 - val_mean_squared_error: 87.2379\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 79.7713 - mean_squared_error: 79.7713 - val_loss: 13.8160 - val_mean_squared_error: 13.8160\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 12.5509 - mean_squared_error: 12.5509 - val_loss: 5.7566 - val_mean_squared_error: 5.7566\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.1549 - mean_squared_error: 7.1549 - val_loss: 27.6163 - val_mean_squared_error: 27.6163\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 29.4256 - mean_squared_error: 29.4256 - val_loss: 34.0331 - val_mean_squared_error: 34.0331\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 35.7957 - mean_squared_error: 35.7957 - val_loss: 17.6840 - val_mean_squared_error: 17.6840\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 19.4514 - mean_squared_error: 19.4514 - val_loss: 3.2639 - val_mean_squared_error: 3.2639\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.3050 - mean_squared_error: 4.3050 - val_loss: 9.8221 - val_mean_squared_error: 9.8221\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.9929 - mean_squared_error: 8.9929 - val_loss: 30.8616 - val_mean_squared_error: 30.8616\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 27.8111 - mean_squared_error: 27.8111 - val_loss: 42.5437 - val_mean_squared_error: 42.5437\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 38.4729 - mean_squared_error: 38.4729 - val_loss: 31.2067 - val_mean_squared_error: 31.2067\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 28.1282 - mean_squared_error: 28.1282 - val_loss: 10.3565 - val_mean_squared_error: 10.3565\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 9.4327 - mean_squared_error: 9.4327 - val_loss: 2.6977 - val_mean_squared_error: 2.6977\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.5300 - mean_squared_error: 3.5300 - val_loss: 11.8627 - val_mean_squared_error: 11.8627\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 13.2661 - mean_squared_error: 13.2661 - val_loss: 18.9707 - val_mean_squared_error: 18.9707\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 20.3718 - mean_squared_error: 20.3718 - val_loss: 9.9729 - val_mean_squared_error: 9.9729\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.3643 - mean_squared_error: 11.3643 - val_loss: 2.3823 - val_mean_squared_error: 2.3823\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 3.0463 - mean_squared_error: 3.0463 - val_loss: 8.8622 - val_mean_squared_error: 8.8622\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.0669 - mean_squared_error: 8.0669 - val_loss: 16.9691 - val_mean_squared_error: 16.9691\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 15.3320 - mean_squared_error: 15.3320 - val_loss: 9.4684 - val_mean_squared_error: 9.4684\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 8.6383 - mean_squared_error: 8.6383 - val_loss: 1.9543 - val_mean_squared_error: 1.9543\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.3842 - mean_squared_error: 2.3842 - val_loss: 6.4686 - val_mean_squared_error: 6.4686\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 7.3727 - mean_squared_error: 7.3727 - val_loss: 9.7760 - val_mean_squared_error: 9.7760\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 10.6632 - mean_squared_error: 10.6632 - val_loss: 4.4640 - val_mean_squared_error: 4.4640\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.2227 - mean_squared_error: 5.2227 - val_loss: 1.9166 - val_mean_squared_error: 1.9166\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.1420 - mean_squared_error: 2.1420 - val_loss: 6.9463 - val_mean_squared_error: 6.9463\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.4093 - mean_squared_error: 6.4093 - val_loss: 7.7513 - val_mean_squared_error: 7.7513\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 7.1316 - mean_squared_error: 7.1316 - val_loss: 2.6322 - val_mean_squared_error: 2.6322\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6283 - mean_squared_error: 2.6283 - val_loss: 1.9244 - val_mean_squared_error: 1.9244\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.3802 - mean_squared_error: 2.3802 - val_loss: 4.7385 - val_mean_squared_error: 4.7385\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 5.2777 - mean_squared_error: 5.2777 - val_loss: 3.9055 - val_mean_squared_error: 3.9055\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.4050 - mean_squared_error: 4.4050 - val_loss: 1.2990 - val_mean_squared_error: 1.2990\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 1.6285 - mean_squared_error: 1.6285 - val_loss: 2.2973 - val_mean_squared_error: 2.2973\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.2571 - mean_squared_error: 2.2571 - val_loss: 4.2387 - val_mean_squared_error: 4.2387\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 3.9565 - mean_squared_error: 3.9565 - val_loss: 2.7626 - val_mean_squared_error: 2.7626\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 2.6433 - mean_squared_error: 2.6433 - val_loss: 0.9533 - val_mean_squared_error: 0.9533\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 1.1436 - mean_squared_error: 1.1436 - val_loss: 1.7590 - val_mean_squared_error: 1.7590\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.0915 - mean_squared_error: 2.0915 - val_loss: 2.4869 - val_mean_squared_error: 2.4869\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.8108 - mean_squared_error: 2.8108 - val_loss: 1.3105 - val_mean_squared_error: 1.3105\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.5959 - mean_squared_error: 1.5959 - val_loss: 0.7961 - val_mean_squared_error: 0.7961\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.9397 - mean_squared_error: 0.9397 - val_loss: 1.8159 - val_mean_squared_error: 1.8159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 150.8649 - mean_squared_error: 150.8649 - val_loss: 72.4424 - val_mean_squared_error: 72.4424\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 73.5357 - mean_squared_error: 73.5357 - val_loss: 191.8806 - val_mean_squared_error: 191.8806\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 147us/step - loss: 177.4399 - mean_squared_error: 177.4399 - val_loss: 13.4396 - val_mean_squared_error: 13.4396\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 12.3206 - mean_squared_error: 12.3206 - val_loss: 45.4543 - val_mean_squared_error: 45.4543\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 45us/step - loss: 46.8464 - mean_squared_error: 46.8464 - val_loss: 84.0178 - val_mean_squared_error: 84.0178\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 84.4743 - mean_squared_error: 84.4743 - val_loss: 47.1958 - val_mean_squared_error: 47.1958\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 48.3966 - mean_squared_error: 48.3966 - val_loss: 3.3846 - val_mean_squared_error: 3.3846\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.3994 - mean_squared_error: 4.3994 - val_loss: 44.7595 - val_mean_squared_error: 44.7595\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 41.0109 - mean_squared_error: 41.0109 - val_loss: 23.0427 - val_mean_squared_error: 23.0427\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 21.1113 - mean_squared_error: 21.1113 - val_loss: 6.7900 - val_mean_squared_error: 6.7900\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 7.9857 - mean_squared_error: 7.9857 - val_loss: 28.5682 - val_mean_squared_error: 28.5682\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 29.6953 - mean_squared_error: 29.6953 - val_loss: 3.5677 - val_mean_squared_error: 3.5677\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5111 - mean_squared_error: 4.5111 - val_loss: 15.5765 - val_mean_squared_error: 15.5765\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 14.4178 - mean_squared_error: 14.4178 - val_loss: 24.6119 - val_mean_squared_error: 24.6119\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 22.7114 - mean_squared_error: 22.7114 - val_loss: 6.3907 - val_mean_squared_error: 6.3907\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 6.1748 - mean_squared_error: 6.1748 - val_loss: 7.2835 - val_mean_squared_error: 7.2835\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.1974 - mean_squared_error: 8.1974 - val_loss: 14.1139 - val_mean_squared_error: 14.1139\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 14.9296 - mean_squared_error: 14.9296 - val_loss: 3.5455 - val_mean_squared_error: 3.5455\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.2940 - mean_squared_error: 4.2940 - val_loss: 3.7278 - val_mean_squared_error: 3.7278\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.8032 - mean_squared_error: 3.8032 - val_loss: 9.4587 - val_mean_squared_error: 9.4587\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.9209 - mean_squared_error: 8.9209 - val_loss: 6.9486 - val_mean_squared_error: 6.9486\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.6460 - mean_squared_error: 6.6460 - val_loss: 2.0125 - val_mean_squared_error: 2.0125\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.3304 - mean_squared_error: 2.3304 - val_loss: 3.4120 - val_mean_squared_error: 3.4120\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.0235 - mean_squared_error: 4.0235 - val_loss: 5.8827 - val_mean_squared_error: 5.8827\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.5001 - mean_squared_error: 6.5001 - val_loss: 3.7976 - val_mean_squared_error: 3.7976\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.3712 - mean_squared_error: 4.3712 - val_loss: 1.5817 - val_mean_squared_error: 1.5817\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9703 - mean_squared_error: 1.9703 - val_loss: 3.1888 - val_mean_squared_error: 3.1888\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.2404 - mean_squared_error: 3.2404 - val_loss: 4.7309 - val_mean_squared_error: 4.7309\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.6096 - mean_squared_error: 4.6096 - val_loss: 3.0736 - val_mean_squared_error: 3.0736\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1220 - mean_squared_error: 3.1220 - val_loss: 1.4518 - val_mean_squared_error: 1.4518\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.7681 - mean_squared_error: 1.7681 - val_loss: 2.2464 - val_mean_squared_error: 2.2464\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6873 - mean_squared_error: 2.6873 - val_loss: 3.0498 - val_mean_squared_error: 3.0498\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.4914 - mean_squared_error: 3.4914 - val_loss: 2.0762 - val_mean_squared_error: 2.0762\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.4722 - mean_squared_error: 2.4722 - val_loss: 1.2473 - val_mean_squared_error: 1.2473\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 1.5275 - mean_squared_error: 1.5275 - val_loss: 1.9912 - val_mean_squared_error: 1.9912\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.1000 - mean_squared_error: 2.1000 - val_loss: 2.5798 - val_mean_squared_error: 2.5798\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6097 - mean_squared_error: 2.6097 - val_loss: 1.7289 - val_mean_squared_error: 1.7289\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8387 - mean_squared_error: 1.8387 - val_loss: 1.0326 - val_mean_squared_error: 1.0326\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2625 - mean_squared_error: 1.2625 - val_loss: 1.4778 - val_mean_squared_error: 1.4778\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.7460 - mean_squared_error: 1.7460 - val_loss: 1.6834 - val_mean_squared_error: 1.6834\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.9297 - mean_squared_error: 1.9297 - val_loss: 1.0409 - val_mean_squared_error: 1.0409\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.2576 - mean_squared_error: 1.2576 - val_loss: 0.8750 - val_mean_squared_error: 0.8750\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.0230 - mean_squared_error: 1.0230 - val_loss: 1.3126 - val_mean_squared_error: 1.3126\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 1.3881 - mean_squared_error: 1.3881 - val_loss: 1.1170 - val_mean_squared_error: 1.1170\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.1955 - mean_squared_error: 1.1955 - val_loss: 0.6051 - val_mean_squared_error: 0.6051\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7244 - mean_squared_error: 0.7244 - val_loss: 0.8202 - val_mean_squared_error: 0.8202\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.9353 - mean_squared_error: 0.9353 - val_loss: 0.8985 - val_mean_squared_error: 0.8985\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.9959 - mean_squared_error: 0.9959 - val_loss: 0.4744 - val_mean_squared_error: 0.4744\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5652 - mean_squared_error: 0.5652 - val_loss: 0.5637 - val_mean_squared_error: 0.5637\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.6275 - mean_squared_error: 0.6275 - val_loss: 0.6960 - val_mean_squared_error: 0.6960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 150.2121 - mean_squared_error: 150.2121 - val_loss: 30.8307 - val_mean_squared_error: 30.8307\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 32.7269 - mean_squared_error: 32.7269 - val_loss: 472.4473 - val_mean_squared_error: 472.4473\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 439.9533 - mean_squared_error: 439.9533 - val_loss: 6.8237 - val_mean_squared_error: 6.8237\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.5180 - mean_squared_error: 6.5180 - val_loss: 97.8463 - val_mean_squared_error: 97.8463\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 98.2786 - mean_squared_error: 98.2786 - val_loss: 128.1075 - val_mean_squared_error: 128.1075\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 127.6375 - mean_squared_error: 127.6375 - val_loss: 55.0736 - val_mean_squared_error: 55.0736\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 56.3697 - mean_squared_error: 56.3697 - val_loss: 2.7939 - val_mean_squared_error: 2.7939\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.4730 - mean_squared_error: 3.4730 - val_loss: 72.6255 - val_mean_squared_error: 72.6255\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 66.4922 - mean_squared_error: 66.4922 - val_loss: 81.7890 - val_mean_squared_error: 81.7890\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 75.0226 - mean_squared_error: 75.0226 - val_loss: 20.6501 - val_mean_squared_error: 20.6501\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 18.7849 - mean_squared_error: 18.7849 - val_loss: 9.3053 - val_mean_squared_error: 9.3053\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.7900 - mean_squared_error: 10.7900 - val_loss: 41.7130 - val_mean_squared_error: 41.7130\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 43.1119 - mean_squared_error: 43.1119 - val_loss: 19.0639 - val_mean_squared_error: 19.0639\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 20.6410 - mean_squared_error: 20.6410 - val_loss: 2.9423 - val_mean_squared_error: 2.9423\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.4560 - mean_squared_error: 3.4560 - val_loss: 22.2248 - val_mean_squared_error: 22.2248\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 20.2588 - mean_squared_error: 20.2588 - val_loss: 34.6548 - val_mean_squared_error: 34.6548\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 31.6268 - mean_squared_error: 31.6268 - val_loss: 18.6388 - val_mean_squared_error: 18.6388\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 17.0304 - mean_squared_error: 17.0304 - val_loss: 2.6676 - val_mean_squared_error: 2.6676\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.1574 - mean_squared_error: 3.1574 - val_loss: 12.0186 - val_mean_squared_error: 12.0186\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 13.2898 - mean_squared_error: 13.2898 - val_loss: 18.3063 - val_mean_squared_error: 18.3063\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 19.5195 - mean_squared_error: 19.5195 - val_loss: 5.9253 - val_mean_squared_error: 5.9253\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.0017 - mean_squared_error: 7.0017 - val_loss: 3.4878 - val_mean_squared_error: 3.4878\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 3.6581 - mean_squared_error: 3.6581 - val_loss: 12.2177 - val_mean_squared_error: 12.2177\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 11.2759 - mean_squared_error: 11.2759 - val_loss: 13.7164 - val_mean_squared_error: 13.7164\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 12.6294 - mean_squared_error: 12.6294 - val_loss: 6.3219 - val_mean_squared_error: 6.3219\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.0314 - mean_squared_error: 6.0314 - val_loss: 2.0885 - val_mean_squared_error: 2.0885\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6297 - mean_squared_error: 2.6297 - val_loss: 5.1440 - val_mean_squared_error: 5.1440\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 6.0386 - mean_squared_error: 6.0386 - val_loss: 7.9224 - val_mean_squared_error: 7.9224\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 8.8459 - mean_squared_error: 8.8459 - val_loss: 5.4359 - val_mean_squared_error: 5.4359\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.2892 - mean_squared_error: 6.2892 - val_loss: 2.1641 - val_mean_squared_error: 2.1641\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7727 - mean_squared_error: 2.7727 - val_loss: 2.7379 - val_mean_squared_error: 2.7379\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.9106 - mean_squared_error: 2.9106 - val_loss: 5.3729 - val_mean_squared_error: 5.3729\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1581 - mean_squared_error: 5.1581 - val_loss: 5.8469 - val_mean_squared_error: 5.8469\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.5723 - mean_squared_error: 5.5723 - val_loss: 3.6492 - val_mean_squared_error: 3.6492\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.6428 - mean_squared_error: 3.6428 - val_loss: 1.8133 - val_mean_squared_error: 1.8133\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.1520 - mean_squared_error: 2.1520 - val_loss: 2.1636 - val_mean_squared_error: 2.1636\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.7154 - mean_squared_error: 2.7154 - val_loss: 3.3014 - val_mean_squared_error: 3.3014\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 3.9152 - mean_squared_error: 3.9152 - val_loss: 3.1946 - val_mean_squared_error: 3.1946\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.7833 - mean_squared_error: 3.7833 - val_loss: 2.0249 - val_mean_squared_error: 2.0249\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.5209 - mean_squared_error: 2.5209 - val_loss: 1.4953 - val_mean_squared_error: 1.4953\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8194 - mean_squared_error: 1.8194 - val_loss: 2.2031 - val_mean_squared_error: 2.2031\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3261 - mean_squared_error: 2.3261 - val_loss: 2.9549 - val_mean_squared_error: 2.9549\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9597 - mean_squared_error: 2.9597 - val_loss: 2.6293 - val_mean_squared_error: 2.6293\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6666 - mean_squared_error: 2.6666 - val_loss: 1.6800 - val_mean_squared_error: 1.6800\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8520 - mean_squared_error: 1.8520 - val_loss: 1.2683 - val_mean_squared_error: 1.2683\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.5707 - mean_squared_error: 1.5707 - val_loss: 1.5989 - val_mean_squared_error: 1.5989\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9658 - mean_squared_error: 1.9658 - val_loss: 1.8573 - val_mean_squared_error: 1.8573\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.2287 - mean_squared_error: 2.2287 - val_loss: 1.5434 - val_mean_squared_error: 1.5434\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8811 - mean_squared_error: 1.8811 - val_loss: 1.1206 - val_mean_squared_error: 1.1206\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3895 - mean_squared_error: 1.3895 - val_loss: 1.1786 - val_mean_squared_error: 1.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 150.0765 - mean_squared_error: 150.0765 - val_loss: 7.9731 - val_mean_squared_error: 7.9731\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 9.5450 - mean_squared_error: 9.5450 - val_loss: 731.9800 - val_mean_squared_error: 731.9800\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 684.9078 - mean_squared_error: 684.9078 - val_loss: 19.8838 - val_mean_squared_error: 19.8838\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 18.0452 - mean_squared_error: 18.0452 - val_loss: 104.5650 - val_mean_squared_error: 104.5650\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 104.7037 - mean_squared_error: 104.7037 - val_loss: 191.3000 - val_mean_squared_error: 191.3000\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 188.7743 - mean_squared_error: 188.7743 - val_loss: 141.6296 - val_mean_squared_error: 141.6296\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 140.6906 - mean_squared_error: 140.6906 - val_loss: 41.9299 - val_mean_squared_error: 41.9299\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 43.5177 - mean_squared_error: 43.5177 - val_loss: 10.2818 - val_mean_squared_error: 10.2818\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 9.5197 - mean_squared_error: 9.5197 - val_loss: 118.9137 - val_mean_squared_error: 118.9137\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 109.3180 - mean_squared_error: 109.3180 - val_loss: 92.2360 - val_mean_squared_error: 92.2360\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 84.5889 - mean_squared_error: 84.5889 - val_loss: 10.4429 - val_mean_squared_error: 10.4429\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 9.7060 - mean_squared_error: 9.7060 - val_loss: 25.4632 - val_mean_squared_error: 25.4632\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 27.1321 - mean_squared_error: 27.1321 - val_loss: 49.4072 - val_mean_squared_error: 49.4072\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 50.7068 - mean_squared_error: 50.7068 - val_loss: 12.7203 - val_mean_squared_error: 12.7203\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 14.2889 - mean_squared_error: 14.2889 - val_loss: 9.5636 - val_mean_squared_error: 9.5636\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 8.9601 - mean_squared_error: 8.9601 - val_loss: 41.4660 - val_mean_squared_error: 41.4660\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 37.8698 - mean_squared_error: 37.8698 - val_loss: 40.2590 - val_mean_squared_error: 40.2590\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 36.7998 - mean_squared_error: 36.7998 - val_loss: 10.7015 - val_mean_squared_error: 10.7015\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 9.9398 - mean_squared_error: 9.9398 - val_loss: 5.8519 - val_mean_squared_error: 5.8519\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 6.9696 - mean_squared_error: 6.9696 - val_loss: 25.3914 - val_mean_squared_error: 25.3914\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 26.4224 - mean_squared_error: 26.4224 - val_loss: 14.9554 - val_mean_squared_error: 14.9554\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 16.0438 - mean_squared_error: 16.0438 - val_loss: 2.1893 - val_mean_squared_error: 2.1893\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.7351 - mean_squared_error: 2.7351 - val_loss: 13.5214 - val_mean_squared_error: 13.5214\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 12.5008 - mean_squared_error: 12.5008 - val_loss: 21.7954 - val_mean_squared_error: 21.7954\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 20.0675 - mean_squared_error: 20.0675 - val_loss: 10.6909 - val_mean_squared_error: 10.6909\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 9.9492 - mean_squared_error: 9.9492 - val_loss: 1.9064 - val_mean_squared_error: 1.9064\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 2.4018 - mean_squared_error: 2.4018 - val_loss: 9.3243 - val_mean_squared_error: 9.3243\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 10.0827 - mean_squared_error: 10.0827 - val_loss: 12.4061 - val_mean_squared_error: 12.4061\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 13.0797 - mean_squared_error: 13.0797 - val_loss: 4.0108 - val_mean_squared_error: 4.0108\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 4.6593 - mean_squared_error: 4.6593 - val_loss: 2.7277 - val_mean_squared_error: 2.7277\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 2.8437 - mean_squared_error: 2.8437 - val_loss: 9.1534 - val_mean_squared_error: 9.1534\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 8.5673 - mean_squared_error: 8.5673 - val_loss: 9.0030 - val_mean_squared_error: 9.0030\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 8.4311 - mean_squared_error: 8.4311 - val_loss: 2.9028 - val_mean_squared_error: 2.9028\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.9475 - mean_squared_error: 2.9475 - val_loss: 2.1378 - val_mean_squared_error: 2.1378\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 2.5957 - mean_squared_error: 2.5957 - val_loss: 5.9099 - val_mean_squared_error: 5.9099\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 6.3789 - mean_squared_error: 6.3789 - val_loss: 5.0413 - val_mean_squared_error: 5.0413\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 5.4854 - mean_squared_error: 5.4854 - val_loss: 1.5409 - val_mean_squared_error: 1.5409\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.9040 - mean_squared_error: 1.9040 - val_loss: 2.3551 - val_mean_squared_error: 2.3551\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.4031 - mean_squared_error: 2.4031 - val_loss: 4.9055 - val_mean_squared_error: 4.9055\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.6846 - mean_squared_error: 4.6846 - val_loss: 3.7821 - val_mean_squared_error: 3.7821\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.6589 - mean_squared_error: 3.6589 - val_loss: 1.2637 - val_mean_squared_error: 1.2637\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.4268 - mean_squared_error: 1.4268 - val_loss: 1.6986 - val_mean_squared_error: 1.6986\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.9978 - mean_squared_error: 1.9978 - val_loss: 3.1169 - val_mean_squared_error: 3.1169\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 3.4036 - mean_squared_error: 3.4036 - val_loss: 2.1774 - val_mean_squared_error: 2.1774\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.4481 - mean_squared_error: 2.4481 - val_loss: 0.8730 - val_mean_squared_error: 0.8730\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 40us/step - loss: 1.0747 - mean_squared_error: 1.0747 - val_loss: 1.6372 - val_mean_squared_error: 1.6372\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 1.6761 - mean_squared_error: 1.6761 - val_loss: 2.5177 - val_mean_squared_error: 2.5177\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 45us/step - loss: 2.4609 - mean_squared_error: 2.4609 - val_loss: 1.6288 - val_mean_squared_error: 1.6288\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.6486 - mean_squared_error: 1.6486 - val_loss: 0.6985 - val_mean_squared_error: 0.6985\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.8405 - mean_squared_error: 0.8405 - val_loss: 1.1875 - val_mean_squared_error: 1.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 152.5513 - mean_squared_error: 152.5513 - val_loss: 57.0869 - val_mean_squared_error: 57.0869\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 58.5527 - mean_squared_error: 58.5527 - val_loss: 346.1681 - val_mean_squared_error: 346.1681\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 321.7568 - mean_squared_error: 321.7568 - val_loss: 18.0446 - val_mean_squared_error: 18.0446\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 16.3755 - mean_squared_error: 16.3755 - val_loss: 80.0697 - val_mean_squared_error: 80.0697\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 80.7967 - mean_squared_error: 80.7967 - val_loss: 157.3806 - val_mean_squared_error: 157.3806\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 155.7731 - mean_squared_error: 155.7731 - val_loss: 101.1219 - val_mean_squared_error: 101.1219\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 101.1371 - mean_squared_error: 101.1371 - val_loss: 26.6241 - val_mean_squared_error: 26.6241\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 28.1607 - mean_squared_error: 28.1607 - val_loss: 3.6123 - val_mean_squared_error: 3.6123\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.9155 - mean_squared_error: 3.9155 - val_loss: 33.5562 - val_mean_squared_error: 33.5562\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 30.6542 - mean_squared_error: 30.6542 - val_loss: 25.5390 - val_mean_squared_error: 25.5390\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 23.3395 - mean_squared_error: 23.3395 - val_loss: 6.3068 - val_mean_squared_error: 6.3068\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 7.5093 - mean_squared_error: 7.5093 - val_loss: 48.3159 - val_mean_squared_error: 48.3159\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 49.0355 - mean_squared_error: 49.0355 - val_loss: 2.7362 - val_mean_squared_error: 2.7362\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.5459 - mean_squared_error: 3.5459 - val_loss: 33.6425 - val_mean_squared_error: 33.6425\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 31.0009 - mean_squared_error: 31.0009 - val_loss: 21.8248 - val_mean_squared_error: 21.8248\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 20.1658 - mean_squared_error: 20.1658 - val_loss: 6.1730 - val_mean_squared_error: 6.1730\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.9218 - mean_squared_error: 6.9218 - val_loss: 26.1440 - val_mean_squared_error: 26.1440\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 26.3223 - mean_squared_error: 26.3223 - val_loss: 1.7376 - val_mean_squared_error: 1.7376\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.1041 - mean_squared_error: 2.1041 - val_loss: 19.2111 - val_mean_squared_error: 19.2111\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 17.9387 - mean_squared_error: 17.9387 - val_loss: 11.3115 - val_mean_squared_error: 11.3115\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.6454 - mean_squared_error: 10.6454 - val_loss: 3.3998 - val_mean_squared_error: 3.3998\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.7645 - mean_squared_error: 3.7645 - val_loss: 14.6300 - val_mean_squared_error: 14.6300\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 14.6178 - mean_squared_error: 14.6178 - val_loss: 1.5529 - val_mean_squared_error: 1.5529\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.8549 - mean_squared_error: 1.8549 - val_loss: 8.7506 - val_mean_squared_error: 8.7506\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.3132 - mean_squared_error: 8.3132 - val_loss: 8.1911 - val_mean_squared_error: 8.1911\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.7930 - mean_squared_error: 7.7930 - val_loss: 1.0870 - val_mean_squared_error: 1.0870\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.3007 - mean_squared_error: 1.3007 - val_loss: 9.0977 - val_mean_squared_error: 9.0977\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 8.9306 - mean_squared_error: 8.9306 - val_loss: 1.7645 - val_mean_squared_error: 1.7645\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9306 - mean_squared_error: 1.9306 - val_loss: 4.0603 - val_mean_squared_error: 4.0603\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.9139 - mean_squared_error: 3.9139 - val_loss: 5.6301 - val_mean_squared_error: 5.6301\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.3744 - mean_squared_error: 5.3744 - val_loss: 0.5389 - val_mean_squared_error: 0.5389\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6447 - mean_squared_error: 0.6447 - val_loss: 4.7792 - val_mean_squared_error: 4.7792\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.7615 - mean_squared_error: 4.7615 - val_loss: 1.9350 - val_mean_squared_error: 1.9350\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.0003 - mean_squared_error: 2.0003 - val_loss: 1.6183 - val_mean_squared_error: 1.6183\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.5756 - mean_squared_error: 1.5756 - val_loss: 3.8188 - val_mean_squared_error: 3.8188\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.6217 - mean_squared_error: 3.6217 - val_loss: 0.3849 - val_mean_squared_error: 0.3849\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4219 - mean_squared_error: 0.4219 - val_loss: 2.5308 - val_mean_squared_error: 2.5308\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.5364 - mean_squared_error: 2.5364 - val_loss: 1.5341 - val_mean_squared_error: 1.5341\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.5637 - mean_squared_error: 1.5637 - val_loss: 0.6972 - val_mean_squared_error: 0.6972\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.6738 - mean_squared_error: 0.6738 - val_loss: 2.3970 - val_mean_squared_error: 2.3970\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2446 - mean_squared_error: 2.2446 - val_loss: 0.3015 - val_mean_squared_error: 0.3015\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3011 - mean_squared_error: 0.3011 - val_loss: 1.3876 - val_mean_squared_error: 1.3876\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3997 - mean_squared_error: 1.3997 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.0325 - mean_squared_error: 1.0325 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3492 - mean_squared_error: 0.3492 - val_loss: 1.4719 - val_mean_squared_error: 1.4719\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.3572 - mean_squared_error: 1.3572 - val_loss: 0.1937 - val_mean_squared_error: 0.1937\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1814 - mean_squared_error: 0.1814 - val_loss: 0.8508 - val_mean_squared_error: 0.8508\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.8572 - mean_squared_error: 0.8572 - val_loss: 0.5897 - val_mean_squared_error: 0.5897\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.5983 - mean_squared_error: 0.5983 - val_loss: 0.2769 - val_mean_squared_error: 0.2769\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2485 - mean_squared_error: 0.2485 - val_loss: 0.8964 - val_mean_squared_error: 0.8964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7746 - mean_squared_error: 1.7746 - val_loss: 19.8866 - val_mean_squared_error: 19.8866\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 19.5966 - mean_squared_error: 19.5966 - val_loss: 1.3247 - val_mean_squared_error: 1.3247\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5931 - mean_squared_error: 1.5931 - val_loss: 9.3779 - val_mean_squared_error: 9.3779\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 8.6474 - mean_squared_error: 8.6474 - val_loss: 11.8397 - val_mean_squared_error: 11.8397\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 10.9152 - mean_squared_error: 10.9152 - val_loss: 3.3016 - val_mean_squared_error: 3.3016\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 45us/step - loss: 3.0679 - mean_squared_error: 3.0679 - val_loss: 1.1407 - val_mean_squared_error: 1.1407\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 1.3936 - mean_squared_error: 1.3936 - val_loss: 5.3435 - val_mean_squared_error: 5.3435\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 44us/step - loss: 5.6574 - mean_squared_error: 5.6574 - val_loss: 6.5015 - val_mean_squared_error: 6.5015\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 6.8014 - mean_squared_error: 6.8014 - val_loss: 3.2772 - val_mean_squared_error: 3.2772\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 3.5880 - mean_squared_error: 3.5880 - val_loss: 0.7668 - val_mean_squared_error: 0.7668\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.9525 - mean_squared_error: 0.9525 - val_loss: 2.0895 - val_mean_squared_error: 2.0895\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.9725 - mean_squared_error: 1.9725 - val_loss: 4.5416 - val_mean_squared_error: 4.5416\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.1736 - mean_squared_error: 4.1736 - val_loss: 4.2085 - val_mean_squared_error: 4.2085\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 3.8678 - mean_squared_error: 3.8678 - val_loss: 1.8697 - val_mean_squared_error: 1.8697\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 1.7692 - mean_squared_error: 1.7692 - val_loss: 0.6682 - val_mean_squared_error: 0.6682\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.8053 - mean_squared_error: 0.8053 - val_loss: 1.4856 - val_mean_squared_error: 1.4856\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 1.7395 - mean_squared_error: 1.7395 - val_loss: 2.5121 - val_mean_squared_error: 2.5121\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 2.7892 - mean_squared_error: 2.7892 - val_loss: 2.1937 - val_mean_squared_error: 2.1937\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 2.4603 - mean_squared_error: 2.4603 - val_loss: 1.0542 - val_mean_squared_error: 1.0542\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 1.2719 - mean_squared_error: 1.2719 - val_loss: 0.6078 - val_mean_squared_error: 0.6078\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 0.7087 - mean_squared_error: 0.7087 - val_loss: 1.3144 - val_mean_squared_error: 1.3144\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 56us/step - loss: 1.2614 - mean_squared_error: 1.2614 - val_loss: 2.0428 - val_mean_squared_error: 2.0428\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 49us/step - loss: 1.8963 - mean_squared_error: 1.8963 - val_loss: 1.7453 - val_mean_squared_error: 1.7453\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 45us/step - loss: 1.6306 - mean_squared_error: 1.6306 - val_loss: 0.8713 - val_mean_squared_error: 0.8713\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.8742 - mean_squared_error: 0.8742 - val_loss: 0.4996 - val_mean_squared_error: 0.4996\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.6166 - mean_squared_error: 0.6166 - val_loss: 0.8288 - val_mean_squared_error: 0.8288\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 1.0061 - mean_squared_error: 1.0061 - val_loss: 1.1344 - val_mean_squared_error: 1.1344\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 1.3250 - mean_squared_error: 1.3250 - val_loss: 0.9112 - val_mean_squared_error: 0.9112\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.0866 - mean_squared_error: 1.0866 - val_loss: 0.4923 - val_mean_squared_error: 0.4923\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.6233 - mean_squared_error: 0.6233 - val_loss: 0.4647 - val_mean_squared_error: 0.4647\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.5218 - mean_squared_error: 0.5218 - val_loss: 0.8110 - val_mean_squared_error: 0.8110\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.7956 - mean_squared_error: 0.7956 - val_loss: 0.9693 - val_mean_squared_error: 0.9693\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 45us/step - loss: 0.9294 - mean_squared_error: 0.9294 - val_loss: 0.6935 - val_mean_squared_error: 0.6935\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 45us/step - loss: 0.6889 - mean_squared_error: 0.6889 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 52us/step - loss: 0.4227 - mean_squared_error: 0.4227 - val_loss: 0.3565 - val_mean_squared_error: 0.3565\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 49us/step - loss: 0.4618 - mean_squared_error: 0.4618 - val_loss: 0.5195 - val_mean_squared_error: 0.5195\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.6416 - mean_squared_error: 0.6416 - val_loss: 0.5051 - val_mean_squared_error: 0.5051\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6224 - mean_squared_error: 0.6224 - val_loss: 0.3168 - val_mean_squared_error: 0.3168\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4134 - mean_squared_error: 0.4134 - val_loss: 0.2502 - val_mean_squared_error: 0.2502\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3101 - mean_squared_error: 0.3101 - val_loss: 0.3835 - val_mean_squared_error: 0.3835\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4046 - mean_squared_error: 0.4046 - val_loss: 0.4580 - val_mean_squared_error: 0.4580\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.4644 - mean_squared_error: 0.4644 - val_loss: 0.3215 - val_mean_squared_error: 0.3215\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3470 - mean_squared_error: 0.3470 - val_loss: 0.1717 - val_mean_squared_error: 0.1717\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2226 - mean_squared_error: 0.2226 - val_loss: 0.2033 - val_mean_squared_error: 0.2033\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2623 - mean_squared_error: 0.2623 - val_loss: 0.2814 - val_mean_squared_error: 0.2814\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3326 - mean_squared_error: 0.3326 - val_loss: 0.2124 - val_mean_squared_error: 0.2124\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2580 - mean_squared_error: 0.2580 - val_loss: 0.1186 - val_mean_squared_error: 0.1186\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1574 - mean_squared_error: 0.1574 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1862 - mean_squared_error: 0.1862 - val_loss: 0.2155 - val_mean_squared_error: 0.2155\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2314 - mean_squared_error: 0.2314 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.7416 - mean_squared_error: 0.7416 - val_loss: 11.8543 - val_mean_squared_error: 11.8543\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 11.4026 - mean_squared_error: 11.4026 - val_loss: 0.6882 - val_mean_squared_error: 0.6882\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.7547 - mean_squared_error: 0.7547 - val_loss: 5.0764 - val_mean_squared_error: 5.0764\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.8453 - mean_squared_error: 4.8453 - val_loss: 6.4289 - val_mean_squared_error: 6.4289\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.0864 - mean_squared_error: 6.0864 - val_loss: 2.1196 - val_mean_squared_error: 2.1196\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.0408 - mean_squared_error: 2.0408 - val_loss: 0.6197 - val_mean_squared_error: 0.6197\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.7544 - mean_squared_error: 0.7544 - val_loss: 2.6977 - val_mean_squared_error: 2.6977\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.8692 - mean_squared_error: 2.8692 - val_loss: 3.3232 - val_mean_squared_error: 3.3232\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.5089 - mean_squared_error: 3.5089 - val_loss: 1.8356 - val_mean_squared_error: 1.8356\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.0438 - mean_squared_error: 2.0438 - val_loss: 0.6573 - val_mean_squared_error: 0.6573\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.8089 - mean_squared_error: 0.8089 - val_loss: 1.4966 - val_mean_squared_error: 1.4966\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4821 - mean_squared_error: 1.4821 - val_loss: 2.2135 - val_mean_squared_error: 2.2135\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.1220 - mean_squared_error: 2.1220 - val_loss: 1.4251 - val_mean_squared_error: 1.4251\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4100 - mean_squared_error: 1.4100 - val_loss: 0.6292 - val_mean_squared_error: 0.6292\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7169 - mean_squared_error: 0.7169 - val_loss: 0.6721 - val_mean_squared_error: 0.6721\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.8122 - mean_squared_error: 0.8122 - val_loss: 1.0005 - val_mean_squared_error: 1.0005\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 1.1428 - mean_squared_error: 1.1428 - val_loss: 0.9918 - val_mean_squared_error: 0.9918\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.1227 - mean_squared_error: 1.1227 - val_loss: 0.6439 - val_mean_squared_error: 0.6439\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.7564 - mean_squared_error: 0.7564 - val_loss: 0.4023 - val_mean_squared_error: 0.4023\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.4829 - mean_squared_error: 0.4829 - val_loss: 0.5392 - val_mean_squared_error: 0.5392\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.5756 - mean_squared_error: 0.5756 - val_loss: 0.8001 - val_mean_squared_error: 0.8001\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8029 - mean_squared_error: 0.8029 - val_loss: 0.7723 - val_mean_squared_error: 0.7723\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7743 - mean_squared_error: 0.7743 - val_loss: 0.4696 - val_mean_squared_error: 0.4696\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.4978 - mean_squared_error: 0.4978 - val_loss: 0.2831 - val_mean_squared_error: 0.2831\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.3370 - mean_squared_error: 0.3370 - val_loss: 0.3971 - val_mean_squared_error: 0.3971\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.4573 - mean_squared_error: 0.4573 - val_loss: 0.5253 - val_mean_squared_error: 0.5253\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.5797 - mean_squared_error: 0.5797 - val_loss: 0.4013 - val_mean_squared_error: 0.4013\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.4514 - mean_squared_error: 0.4514 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2659 - mean_squared_error: 0.2659 - val_loss: 0.2526 - val_mean_squared_error: 0.2526\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2821 - mean_squared_error: 0.2821 - val_loss: 0.3777 - val_mean_squared_error: 0.3777\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3944 - mean_squared_error: 0.3944 - val_loss: 0.3345 - val_mean_squared_error: 0.3345\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3523 - mean_squared_error: 0.3523 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2046 - mean_squared_error: 0.2046 - val_loss: 0.1614 - val_mean_squared_error: 0.1614\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1888 - mean_squared_error: 0.1888 - val_loss: 0.2635 - val_mean_squared_error: 0.2635\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2811 - mean_squared_error: 0.2811 - val_loss: 0.2309 - val_mean_squared_error: 0.2309\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2464 - mean_squared_error: 0.2464 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1360 - mean_squared_error: 0.1360 - val_loss: 0.1364 - val_mean_squared_error: 0.1364\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1531 - mean_squared_error: 0.1531 - val_loss: 0.1995 - val_mean_squared_error: 0.1995\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2105 - mean_squared_error: 0.2105 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.0845 - val_mean_squared_error: 0.0845\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0949 - mean_squared_error: 0.0949 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1439 - mean_squared_error: 0.1439 - val_loss: 0.1483 - val_mean_squared_error: 0.1483\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0869 - mean_squared_error: 0.0869 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0979 - mean_squared_error: 0.0979 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1298 - mean_squared_error: 0.1298 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0907 - mean_squared_error: 0.0907 - val_loss: 0.0763 - val_mean_squared_error: 0.0763\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0753 - mean_squared_error: 0.0753 - val_loss: 0.1099 - val_mean_squared_error: 0.1099\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1077 - mean_squared_error: 0.1077 - val_loss: 0.0934 - val_mean_squared_error: 0.0934\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.3535 - mean_squared_error: 1.3535 - val_loss: 10.2851 - val_mean_squared_error: 10.2851\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.5045 - mean_squared_error: 10.5045 - val_loss: 1.0711 - val_mean_squared_error: 1.0711\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3263 - mean_squared_error: 1.3263 - val_loss: 6.1991 - val_mean_squared_error: 6.1991\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.8571 - mean_squared_error: 5.8571 - val_loss: 6.5035 - val_mean_squared_error: 6.5035\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.1390 - mean_squared_error: 6.1390 - val_loss: 1.9623 - val_mean_squared_error: 1.9623\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9823 - mean_squared_error: 1.9823 - val_loss: 1.3541 - val_mean_squared_error: 1.3541\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.6196 - mean_squared_error: 1.6196 - val_loss: 3.8246 - val_mean_squared_error: 3.8246\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.0963 - mean_squared_error: 4.0963 - val_loss: 3.5801 - val_mean_squared_error: 3.5801\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.8497 - mean_squared_error: 3.8497 - val_loss: 1.5743 - val_mean_squared_error: 1.5743\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.8352 - mean_squared_error: 1.8352 - val_loss: 0.8904 - val_mean_squared_error: 0.8904\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.0441 - mean_squared_error: 1.0441 - val_loss: 2.0089 - val_mean_squared_error: 2.0089\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9995 - mean_squared_error: 1.9995 - val_loss: 2.8638 - val_mean_squared_error: 2.8638\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.7709 - mean_squared_error: 2.7709 - val_loss: 2.2214 - val_mean_squared_error: 2.2214\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.1837 - mean_squared_error: 2.1837 - val_loss: 1.0797 - val_mean_squared_error: 1.0797\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.1647 - mean_squared_error: 1.1647 - val_loss: 0.7912 - val_mean_squared_error: 0.7912\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9719 - mean_squared_error: 0.9719 - val_loss: 1.3598 - val_mean_squared_error: 1.3598\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.5744 - mean_squared_error: 1.5744 - val_loss: 1.7060 - val_mean_squared_error: 1.7060\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9204 - mean_squared_error: 1.9204 - val_loss: 1.3138 - val_mean_squared_error: 1.3138\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.5176 - mean_squared_error: 1.5176 - val_loss: 0.7619 - val_mean_squared_error: 0.7619\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9338 - mean_squared_error: 0.9338 - val_loss: 0.7199 - val_mean_squared_error: 0.7199\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.8291 - mean_squared_error: 0.8291 - val_loss: 1.1083 - val_mean_squared_error: 1.1083\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.1501 - mean_squared_error: 1.1501 - val_loss: 1.3217 - val_mean_squared_error: 1.3217\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.3342 - mean_squared_error: 1.3342 - val_loss: 1.0627 - val_mean_squared_error: 1.0627\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 1.0986 - mean_squared_error: 1.0986 - val_loss: 0.6580 - val_mean_squared_error: 0.6580\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.7465 - mean_squared_error: 0.7465 - val_loss: 0.5522 - val_mean_squared_error: 0.5522\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.6806 - mean_squared_error: 0.6806 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.8832 - mean_squared_error: 0.8832 - val_loss: 0.8428 - val_mean_squared_error: 0.8428\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9705 - mean_squared_error: 0.9705 - val_loss: 0.6427 - val_mean_squared_error: 0.6427\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.7598 - mean_squared_error: 0.7598 - val_loss: 0.4344 - val_mean_squared_error: 0.4344\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.5315 - mean_squared_error: 0.5315 - val_loss: 0.4869 - val_mean_squared_error: 0.4869\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.5511 - mean_squared_error: 0.5511 - val_loss: 0.6390 - val_mean_squared_error: 0.6390\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.6761 - mean_squared_error: 0.6761 - val_loss: 0.5905 - val_mean_squared_error: 0.5905\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6255 - mean_squared_error: 0.6255 - val_loss: 0.3827 - val_mean_squared_error: 0.3827\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.4336 - mean_squared_error: 0.4336 - val_loss: 0.3107 - val_mean_squared_error: 0.3107\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3749 - mean_squared_error: 0.3749 - val_loss: 0.4110 - val_mean_squared_error: 0.4110\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.4743 - mean_squared_error: 0.4743 - val_loss: 0.4113 - val_mean_squared_error: 0.4113\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.4688 - mean_squared_error: 0.4688 - val_loss: 0.2703 - val_mean_squared_error: 0.2703\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.2337 - val_mean_squared_error: 0.2337\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2702 - mean_squared_error: 0.2702 - val_loss: 0.3206 - val_mean_squared_error: 0.3206\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.3412 - mean_squared_error: 0.3412 - val_loss: 0.3024 - val_mean_squared_error: 0.3024\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.3195 - mean_squared_error: 0.3195 - val_loss: 0.1825 - val_mean_squared_error: 0.1825\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2069 - mean_squared_error: 0.2069 - val_loss: 0.1706 - val_mean_squared_error: 0.1706\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1983 - mean_squared_error: 0.1983 - val_loss: 0.2259 - val_mean_squared_error: 0.2259\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2501 - mean_squared_error: 0.2501 - val_loss: 0.1687 - val_mean_squared_error: 0.1687\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1896 - mean_squared_error: 0.1896 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1270 - mean_squared_error: 0.1270 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1670 - mean_squared_error: 0.1670 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1619 - mean_squared_error: 0.1619 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0972 - mean_squared_error: 0.0972 - val_loss: 0.1065 - val_mean_squared_error: 0.1065\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1129 - mean_squared_error: 0.1129 - val_loss: 0.1267 - val_mean_squared_error: 0.1267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.3663 - mean_squared_error: 1.3663 - val_loss: 19.2470 - val_mean_squared_error: 19.2470\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 18.0860 - mean_squared_error: 18.0860 - val_loss: 1.1050 - val_mean_squared_error: 1.1050\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 1.1582 - mean_squared_error: 1.1582 - val_loss: 7.5657 - val_mean_squared_error: 7.5657\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.6001 - mean_squared_error: 7.6001 - val_loss: 11.3117 - val_mean_squared_error: 11.3117\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 11.2267 - mean_squared_error: 11.2267 - val_loss: 4.7676 - val_mean_squared_error: 4.7676\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.8925 - mean_squared_error: 4.8925 - val_loss: 0.6267 - val_mean_squared_error: 0.6267\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.7575 - mean_squared_error: 0.7575 - val_loss: 4.2449 - val_mean_squared_error: 4.2449\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.0127 - mean_squared_error: 4.0127 - val_loss: 7.0904 - val_mean_squared_error: 7.0904\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.6555 - mean_squared_error: 6.6555 - val_loss: 4.3795 - val_mean_squared_error: 4.3795\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.1352 - mean_squared_error: 4.1352 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.0603 - mean_squared_error: 1.0603 - val_loss: 1.0444 - val_mean_squared_error: 1.0444\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2072 - mean_squared_error: 1.2072 - val_loss: 3.0223 - val_mean_squared_error: 3.0223\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1656 - mean_squared_error: 3.1656 - val_loss: 3.5990 - val_mean_squared_error: 3.5990\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.7306 - mean_squared_error: 3.7306 - val_loss: 2.1577 - val_mean_squared_error: 2.1577\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3123 - mean_squared_error: 2.3123 - val_loss: 0.6713 - val_mean_squared_error: 0.6713\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.8097 - mean_squared_error: 0.8097 - val_loss: 0.8763 - val_mean_squared_error: 0.8763\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.9135 - mean_squared_error: 0.9135 - val_loss: 2.1659 - val_mean_squared_error: 2.1659\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.0770 - mean_squared_error: 2.0770 - val_loss: 2.5608 - val_mean_squared_error: 2.5608\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.4369 - mean_squared_error: 2.4369 - val_loss: 1.5763 - val_mean_squared_error: 1.5763\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.5317 - mean_squared_error: 1.5317 - val_loss: 0.5797 - val_mean_squared_error: 0.5797\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.6442 - mean_squared_error: 0.6442 - val_loss: 0.6365 - val_mean_squared_error: 0.6365\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7620 - mean_squared_error: 0.7620 - val_loss: 1.2869 - val_mean_squared_error: 1.2869\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4225 - mean_squared_error: 1.4225 - val_loss: 1.4745 - val_mean_squared_error: 1.4745\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.6067 - mean_squared_error: 1.6067 - val_loss: 0.9585 - val_mean_squared_error: 0.9585\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.0857 - mean_squared_error: 1.0857 - val_loss: 0.4481 - val_mean_squared_error: 0.4481\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.5477 - mean_squared_error: 0.5477 - val_loss: 0.5690 - val_mean_squared_error: 0.5690\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.6084 - mean_squared_error: 0.6084 - val_loss: 1.0442 - val_mean_squared_error: 1.0442\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.0240 - mean_squared_error: 1.0240 - val_loss: 1.1399 - val_mean_squared_error: 1.1399\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.1071 - mean_squared_error: 1.1071 - val_loss: 0.7284 - val_mean_squared_error: 0.7284\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.3726 - val_mean_squared_error: 0.3726\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.4316 - mean_squared_error: 0.4316 - val_loss: 0.4469 - val_mean_squared_error: 0.4469\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.5361 - mean_squared_error: 0.5361 - val_loss: 0.6830 - val_mean_squared_error: 0.6830\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.7786 - mean_squared_error: 0.7786 - val_loss: 0.6630 - val_mean_squared_error: 0.6630\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.7547 - mean_squared_error: 0.7547 - val_loss: 0.4146 - val_mean_squared_error: 0.4146\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.4941 - mean_squared_error: 0.4941 - val_loss: 0.2991 - val_mean_squared_error: 0.2991\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3512 - mean_squared_error: 0.3512 - val_loss: 0.4498 - val_mean_squared_error: 0.4498\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.4661 - mean_squared_error: 0.4661 - val_loss: 0.5922 - val_mean_squared_error: 0.5922\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.5878 - mean_squared_error: 0.5878 - val_loss: 0.4900 - val_mean_squared_error: 0.4900\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.4943 - mean_squared_error: 0.4943 - val_loss: 0.2923 - val_mean_squared_error: 0.2923\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.2548 - val_mean_squared_error: 0.2548\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.3048 - mean_squared_error: 0.3048 - val_loss: 0.3497 - val_mean_squared_error: 0.3497\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.4065 - mean_squared_error: 0.4065 - val_loss: 0.3661 - val_mean_squared_error: 0.3661\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.4209 - mean_squared_error: 0.4209 - val_loss: 0.2628 - val_mean_squared_error: 0.2628\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.3096 - mean_squared_error: 0.3096 - val_loss: 0.2031 - val_mean_squared_error: 0.2031\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2343 - mean_squared_error: 0.2343 - val_loss: 0.2659 - val_mean_squared_error: 0.2659\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2779 - mean_squared_error: 0.2779 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3236 - mean_squared_error: 0.3236 - val_loss: 0.2643 - val_mean_squared_error: 0.2643\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.2707 - mean_squared_error: 0.2707 - val_loss: 0.1782 - val_mean_squared_error: 0.1782\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1973 - mean_squared_error: 0.1973 - val_loss: 0.1758 - val_mean_squared_error: 0.1758\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2040 - mean_squared_error: 0.2040 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.8169 - mean_squared_error: 0.8169 - val_loss: 24.6470 - val_mean_squared_error: 24.6470\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 23.7166 - mean_squared_error: 23.7166 - val_loss: 0.7772 - val_mean_squared_error: 0.7772\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.7815 - mean_squared_error: 0.7815 - val_loss: 11.1699 - val_mean_squared_error: 11.1699\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 10.4879 - mean_squared_error: 10.4879 - val_loss: 13.7826 - val_mean_squared_error: 13.7826\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 12.9453 - mean_squared_error: 12.9453 - val_loss: 3.1771 - val_mean_squared_error: 3.1771\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.9362 - mean_squared_error: 2.9362 - val_loss: 0.8573 - val_mean_squared_error: 0.8573\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8772 - mean_squared_error: 0.8772 - val_loss: 6.8656 - val_mean_squared_error: 6.8656\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.7163 - mean_squared_error: 6.7163 - val_loss: 6.9624 - val_mean_squared_error: 6.9624\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 6.8134 - mean_squared_error: 6.8134 - val_loss: 2.1870 - val_mean_squared_error: 2.1870\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.1899 - mean_squared_error: 2.1899 - val_loss: 0.1726 - val_mean_squared_error: 0.1726\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1628 - mean_squared_error: 0.1628 - val_loss: 2.7050 - val_mean_squared_error: 2.7050\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.4851 - mean_squared_error: 2.4851 - val_loss: 4.6322 - val_mean_squared_error: 4.6322\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.2910 - mean_squared_error: 4.2910 - val_loss: 3.0585 - val_mean_squared_error: 3.0585\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.8226 - mean_squared_error: 2.8226 - val_loss: 0.6353 - val_mean_squared_error: 0.6353\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5773 - mean_squared_error: 0.5773 - val_loss: 0.2919 - val_mean_squared_error: 0.2919\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 1.6787 - val_mean_squared_error: 1.6787\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.6792 - mean_squared_error: 1.6792 - val_loss: 2.3975 - val_mean_squared_error: 2.3975\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.3760 - mean_squared_error: 2.3760 - val_loss: 1.4907 - val_mean_squared_error: 1.4907\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.4945 - mean_squared_error: 1.4945 - val_loss: 0.3084 - val_mean_squared_error: 0.3084\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.2864 - val_mean_squared_error: 0.2864\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2676 - mean_squared_error: 0.2676 - val_loss: 1.1603 - val_mean_squared_error: 1.1603\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.0688 - mean_squared_error: 1.0688 - val_loss: 1.5532 - val_mean_squared_error: 1.5532\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.4349 - mean_squared_error: 1.4349 - val_loss: 0.9539 - val_mean_squared_error: 0.9539\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.8792 - mean_squared_error: 0.8792 - val_loss: 0.2288 - val_mean_squared_error: 0.2288\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2182 - mean_squared_error: 0.2182 - val_loss: 0.2198 - val_mean_squared_error: 0.2198\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.6943 - val_mean_squared_error: 0.6943\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.7138 - mean_squared_error: 0.7138 - val_loss: 0.8757 - val_mean_squared_error: 0.8757\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.8911 - mean_squared_error: 0.8911 - val_loss: 0.5256 - val_mean_squared_error: 0.5256\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5456 - mean_squared_error: 0.5456 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.2217 - val_mean_squared_error: 0.2217\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2125 - mean_squared_error: 0.2125 - val_loss: 0.5526 - val_mean_squared_error: 0.5526\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.5139 - mean_squared_error: 0.5139 - val_loss: 0.6240 - val_mean_squared_error: 0.6240\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5804 - mean_squared_error: 0.5804 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1226 - mean_squared_error: 0.1226 - val_loss: 0.1994 - val_mean_squared_error: 0.1994\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2142 - mean_squared_error: 0.2142 - val_loss: 0.3796 - val_mean_squared_error: 0.3796\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3927 - mean_squared_error: 0.3927 - val_loss: 0.3536 - val_mean_squared_error: 0.3536\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.3659 - mean_squared_error: 0.3659 - val_loss: 0.1704 - val_mean_squared_error: 0.1704\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1826 - mean_squared_error: 0.1826 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1098 - mean_squared_error: 0.1098 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2145 - mean_squared_error: 0.2145 - val_loss: 0.3091 - val_mean_squared_error: 0.3091\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2927 - mean_squared_error: 0.2927 - val_loss: 0.2231 - val_mean_squared_error: 0.2231\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.2135 - mean_squared_error: 0.2135 - val_loss: 0.1041 - val_mean_squared_error: 0.1041\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1062 - mean_squared_error: 0.1062 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1223 - mean_squared_error: 0.1223 - val_loss: 0.1942 - val_mean_squared_error: 0.1942\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2009 - mean_squared_error: 0.2009 - val_loss: 0.1907 - val_mean_squared_error: 0.1907\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1965 - mean_squared_error: 0.1965 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1173 - mean_squared_error: 0.1173 - val_loss: 0.0855 - val_mean_squared_error: 0.0855\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0880 - mean_squared_error: 0.0880 - val_loss: 0.1386 - val_mean_squared_error: 0.1386\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1354 - mean_squared_error: 0.1354 - val_loss: 0.1651 - val_mean_squared_error: 0.1651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.1680 - mean_squared_error: 0.1680 - val_loss: 5.4047 - val_mean_squared_error: 5.4047\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 5.1937 - mean_squared_error: 5.1937 - val_loss: 0.2086 - val_mean_squared_error: 0.2086\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2352 - mean_squared_error: 0.2352 - val_loss: 2.6162 - val_mean_squared_error: 2.6162\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.4636 - mean_squared_error: 2.4636 - val_loss: 3.4947 - val_mean_squared_error: 3.4947\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.2768 - mean_squared_error: 3.2768 - val_loss: 1.1897 - val_mean_squared_error: 1.1897\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.1197 - mean_squared_error: 1.1197 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1388 - mean_squared_error: 0.1388 - val_loss: 1.1920 - val_mean_squared_error: 1.1920\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.1963 - mean_squared_error: 1.1963 - val_loss: 1.9835 - val_mean_squared_error: 1.9835\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9613 - mean_squared_error: 1.9613 - val_loss: 1.2827 - val_mean_squared_error: 1.2827\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.2904 - mean_squared_error: 1.2904 - val_loss: 0.2733 - val_mean_squared_error: 0.2733\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.3075 - mean_squared_error: 0.3075 - val_loss: 0.2374 - val_mean_squared_error: 0.2374\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2326 - mean_squared_error: 0.2326 - val_loss: 0.9781 - val_mean_squared_error: 0.9781\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.8963 - mean_squared_error: 0.8963 - val_loss: 1.2940 - val_mean_squared_error: 1.2940\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.1814 - mean_squared_error: 1.1814 - val_loss: 0.7959 - val_mean_squared_error: 0.7959\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.7262 - mean_squared_error: 0.7262 - val_loss: 0.2028 - val_mean_squared_error: 0.2028\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1991 - mean_squared_error: 0.1991 - val_loss: 0.1730 - val_mean_squared_error: 0.1730\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2066 - mean_squared_error: 0.2066 - val_loss: 0.5433 - val_mean_squared_error: 0.5433\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.5820 - mean_squared_error: 0.5820 - val_loss: 0.7056 - val_mean_squared_error: 0.7056\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.7423 - mean_squared_error: 0.7423 - val_loss: 0.4524 - val_mean_squared_error: 0.4524\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.4911 - mean_squared_error: 0.4911 - val_loss: 0.1441 - val_mean_squared_error: 0.1441\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1740 - mean_squared_error: 0.1740 - val_loss: 0.1607 - val_mean_squared_error: 0.1607\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1601 - mean_squared_error: 0.1601 - val_loss: 0.4227 - val_mean_squared_error: 0.4227\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3853 - mean_squared_error: 0.3853 - val_loss: 0.5404 - val_mean_squared_error: 0.5404\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.4897 - mean_squared_error: 0.4897 - val_loss: 0.3630 - val_mean_squared_error: 0.3630\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3320 - mean_squared_error: 0.3320 - val_loss: 0.1358 - val_mean_squared_error: 0.1358\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1371 - mean_squared_error: 0.1371 - val_loss: 0.1172 - val_mean_squared_error: 0.1172\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1403 - mean_squared_error: 0.1403 - val_loss: 0.2519 - val_mean_squared_error: 0.2519\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.2810 - mean_squared_error: 0.2810 - val_loss: 0.3017 - val_mean_squared_error: 0.3017\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.1941 - val_mean_squared_error: 0.1941\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.2195 - mean_squared_error: 0.2195 - val_loss: 0.0903 - val_mean_squared_error: 0.0903\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1060 - mean_squared_error: 0.1060 - val_loss: 0.1293 - val_mean_squared_error: 0.1293\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1275 - mean_squared_error: 0.1275 - val_loss: 0.2337 - val_mean_squared_error: 0.2337\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2168 - mean_squared_error: 0.2168 - val_loss: 0.2406 - val_mean_squared_error: 0.2406\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2228 - mean_squared_error: 0.2228 - val_loss: 0.1424 - val_mean_squared_error: 0.1424\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1370 - mean_squared_error: 0.1370 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0848 - mean_squared_error: 0.0848 - val_loss: 0.1092 - val_mean_squared_error: 0.1092\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1235 - mean_squared_error: 0.1235 - val_loss: 0.1559 - val_mean_squared_error: 0.1559\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1705 - mean_squared_error: 0.1705 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1451 - mean_squared_error: 0.1451 - val_loss: 0.0774 - val_mean_squared_error: 0.0774\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0873 - mean_squared_error: 0.0873 - val_loss: 0.0771 - val_mean_squared_error: 0.0771\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0801 - mean_squared_error: 0.0801 - val_loss: 0.1218 - val_mean_squared_error: 0.1218\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1178 - mean_squared_error: 0.1178 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1266 - mean_squared_error: 0.1266 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0901 - mean_squared_error: 0.0901 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0669 - mean_squared_error: 0.0669 - val_loss: 0.0785 - val_mean_squared_error: 0.0785\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0853 - mean_squared_error: 0.0853 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1028 - mean_squared_error: 0.1028 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0857 - mean_squared_error: 0.0857 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0627 - mean_squared_error: 0.0627 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0682 - mean_squared_error: 0.0682 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0679 - mean_squared_error: 0.0679 - val_loss: 3.5115 - val_mean_squared_error: 3.5115\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.3957 - mean_squared_error: 3.3957 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0987 - mean_squared_error: 0.0987 - val_loss: 1.9575 - val_mean_squared_error: 1.9575\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.8304 - mean_squared_error: 1.8304 - val_loss: 2.3597 - val_mean_squared_error: 2.3597\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2066 - mean_squared_error: 2.2066 - val_loss: 0.8043 - val_mean_squared_error: 0.8043\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.7389 - mean_squared_error: 0.7389 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0751 - mean_squared_error: 0.0751 - val_loss: 0.7154 - val_mean_squared_error: 0.7154\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.7135 - mean_squared_error: 0.7135 - val_loss: 1.2983 - val_mean_squared_error: 1.2983\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.2853 - mean_squared_error: 1.2853 - val_loss: 0.9945 - val_mean_squared_error: 0.9945\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.9936 - mean_squared_error: 0.9936 - val_loss: 0.3335 - val_mean_squared_error: 0.3335\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.0935 - val_mean_squared_error: 0.0935\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0904 - mean_squared_error: 0.0904 - val_loss: 0.4254 - val_mean_squared_error: 0.4254\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.7945 - val_mean_squared_error: 0.7945\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.7195 - mean_squared_error: 0.7195 - val_loss: 0.7320 - val_mean_squared_error: 0.7320\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6625 - mean_squared_error: 0.6625 - val_loss: 0.3639 - val_mean_squared_error: 0.3639\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1044 - mean_squared_error: 0.1044 - val_loss: 0.1660 - val_mean_squared_error: 0.1660\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1820 - mean_squared_error: 0.1820 - val_loss: 0.3734 - val_mean_squared_error: 0.3734\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.3920 - mean_squared_error: 0.3920 - val_loss: 0.4341 - val_mean_squared_error: 0.4341\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4521 - mean_squared_error: 0.4521 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3059 - mean_squared_error: 0.3059 - val_loss: 0.1185 - val_mean_squared_error: 0.1185\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1317 - mean_squared_error: 0.1317 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1042 - mean_squared_error: 0.1042 - val_loss: 0.2280 - val_mean_squared_error: 0.2280\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2103 - mean_squared_error: 0.2103 - val_loss: 0.3188 - val_mean_squared_error: 0.3188\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2924 - mean_squared_error: 0.2924 - val_loss: 0.2684 - val_mean_squared_error: 0.2684\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2473 - mean_squared_error: 0.2473 - val_loss: 0.1417 - val_mean_squared_error: 0.1417\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1346 - mean_squared_error: 0.1346 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0813 - mean_squared_error: 0.0813 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1270 - mean_squared_error: 0.1270 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1912 - mean_squared_error: 0.1912 - val_loss: 0.1764 - val_mean_squared_error: 0.1764\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1842 - mean_squared_error: 0.1842 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1159 - mean_squared_error: 0.1159 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0695 - mean_squared_error: 0.0695 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0898 - mean_squared_error: 0.0898 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1324 - mean_squared_error: 0.1324 - val_loss: 0.1366 - val_mean_squared_error: 0.1366\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1313 - mean_squared_error: 0.1313 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0878 - mean_squared_error: 0.0878 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0596 - mean_squared_error: 0.0596 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0766 - mean_squared_error: 0.0766 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1032 - mean_squared_error: 0.1032 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0960 - mean_squared_error: 0.0960 - val_loss: 0.0649 - val_mean_squared_error: 0.0649\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0661 - mean_squared_error: 0.0661 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0558 - mean_squared_error: 0.0558 - val_loss: 0.0725 - val_mean_squared_error: 0.0725\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0730 - mean_squared_error: 0.0730 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0845 - mean_squared_error: 0.0845 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0713 - mean_squared_error: 0.0713 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0569 - mean_squared_error: 0.0569 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0695 - mean_squared_error: 0.0695 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0683 - mean_squared_error: 0.0683 - val_loss: 0.0562 - val_mean_squared_error: 0.0562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.1316 - mean_squared_error: 0.1316 - val_loss: 3.0055 - val_mean_squared_error: 3.0055\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.8209 - mean_squared_error: 2.8209 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1414 - mean_squared_error: 0.1414 - val_loss: 1.2503 - val_mean_squared_error: 1.2503\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2243 - mean_squared_error: 1.2243 - val_loss: 1.7636 - val_mean_squared_error: 1.7636\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.7214 - mean_squared_error: 1.7214 - val_loss: 0.6530 - val_mean_squared_error: 0.6530\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.6509 - mean_squared_error: 0.6509 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0887 - mean_squared_error: 0.0887 - val_loss: 0.7073 - val_mean_squared_error: 0.7073\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.6534 - mean_squared_error: 0.6534 - val_loss: 1.0603 - val_mean_squared_error: 1.0603\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.9822 - mean_squared_error: 0.9822 - val_loss: 0.6040 - val_mean_squared_error: 0.6040\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.5583 - mean_squared_error: 0.5583 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1229 - mean_squared_error: 0.1229 - val_loss: 0.2063 - val_mean_squared_error: 0.2063\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2190 - mean_squared_error: 0.2190 - val_loss: 0.5206 - val_mean_squared_error: 0.5206\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.5296 - mean_squared_error: 0.5296 - val_loss: 0.5059 - val_mean_squared_error: 0.5059\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.5155 - mean_squared_error: 0.5155 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2451 - mean_squared_error: 0.2451 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.2220 - val_mean_squared_error: 0.2220\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2081 - mean_squared_error: 0.2081 - val_loss: 0.3929 - val_mean_squared_error: 0.3929\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.3550 - val_mean_squared_error: 0.3550\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.3284 - mean_squared_error: 0.3284 - val_loss: 0.1762 - val_mean_squared_error: 0.1762\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.1659 - mean_squared_error: 0.1659 - val_loss: 0.0850 - val_mean_squared_error: 0.0850\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0900 - mean_squared_error: 0.0900 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1656 - mean_squared_error: 0.1656 - val_loss: 0.2412 - val_mean_squared_error: 0.2412\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.2528 - mean_squared_error: 0.2528 - val_loss: 0.2115 - val_mean_squared_error: 0.2115\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.2226 - mean_squared_error: 0.2226 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1224 - mean_squared_error: 0.1224 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1356 - mean_squared_error: 0.1356 - val_loss: 0.1982 - val_mean_squared_error: 0.1982\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1828 - mean_squared_error: 0.1828 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0883 - mean_squared_error: 0.0883 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0783 - mean_squared_error: 0.0783 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1184 - mean_squared_error: 0.1184 - val_loss: 0.1299 - val_mean_squared_error: 0.1299\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1358 - mean_squared_error: 0.1358 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1022 - mean_squared_error: 0.1022 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0681 - mean_squared_error: 0.0681 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0775 - mean_squared_error: 0.0775 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1033 - mean_squared_error: 0.1033 - val_loss: 0.1068 - val_mean_squared_error: 0.1068\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0983 - mean_squared_error: 0.0983 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0700 - mean_squared_error: 0.0700 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0615 - mean_squared_error: 0.0615 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0786 - mean_squared_error: 0.0786 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0857 - mean_squared_error: 0.0857 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0692 - mean_squared_error: 0.0692 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0694 - val_mean_squared_error: 0.0694\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0644 - mean_squared_error: 0.0644 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0733 - mean_squared_error: 0.0733 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0650 - mean_squared_error: 0.0650 - val_loss: 0.0569 - val_mean_squared_error: 0.0569\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0570 - mean_squared_error: 0.0570 - val_loss: 0.0655 - val_mean_squared_error: 0.0655\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0642 - mean_squared_error: 0.0642 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.2440 - mean_squared_error: 0.2440 - val_loss: 4.5147 - val_mean_squared_error: 4.5147\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.2213 - mean_squared_error: 4.2213 - val_loss: 0.2560 - val_mean_squared_error: 0.2560\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2560 - mean_squared_error: 0.2560 - val_loss: 1.9177 - val_mean_squared_error: 1.9177\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.9203 - mean_squared_error: 1.9203 - val_loss: 2.7686 - val_mean_squared_error: 2.7686\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.7453 - mean_squared_error: 2.7453 - val_loss: 1.1241 - val_mean_squared_error: 1.1241\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.1474 - mean_squared_error: 1.1474 - val_loss: 0.1512 - val_mean_squared_error: 0.1512\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1703 - mean_squared_error: 0.1703 - val_loss: 0.9942 - val_mean_squared_error: 0.9942\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9265 - mean_squared_error: 0.9265 - val_loss: 1.7664 - val_mean_squared_error: 1.7664\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.6423 - mean_squared_error: 1.6423 - val_loss: 1.1913 - val_mean_squared_error: 1.1913\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.1072 - mean_squared_error: 1.1072 - val_loss: 0.2988 - val_mean_squared_error: 0.2988\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2903 - mean_squared_error: 0.2903 - val_loss: 0.2533 - val_mean_squared_error: 0.2533\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2846 - mean_squared_error: 0.2846 - val_loss: 0.8182 - val_mean_squared_error: 0.8182\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.8480 - mean_squared_error: 0.8480 - val_loss: 0.9587 - val_mean_squared_error: 0.9587\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9856 - mean_squared_error: 0.9856 - val_loss: 0.5264 - val_mean_squared_error: 0.5264\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5586 - mean_squared_error: 0.5586 - val_loss: 0.1549 - val_mean_squared_error: 0.1549\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1785 - mean_squared_error: 0.1785 - val_loss: 0.2781 - val_mean_squared_error: 0.2781\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2688 - mean_squared_error: 0.2688 - val_loss: 0.6202 - val_mean_squared_error: 0.6202\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.5772 - mean_squared_error: 0.5772 - val_loss: 0.6624 - val_mean_squared_error: 0.6624\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6155 - mean_squared_error: 0.6155 - val_loss: 0.3712 - val_mean_squared_error: 0.3712\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3504 - mean_squared_error: 0.3504 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1485 - mean_squared_error: 0.1485 - val_loss: 0.2016 - val_mean_squared_error: 0.2016\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.2265 - mean_squared_error: 0.2265 - val_loss: 0.3790 - val_mean_squared_error: 0.3790\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.4056 - mean_squared_error: 0.4056 - val_loss: 0.3861 - val_mean_squared_error: 0.3861\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4117 - mean_squared_error: 0.4117 - val_loss: 0.2213 - val_mean_squared_error: 0.2213\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2446 - mean_squared_error: 0.2446 - val_loss: 0.1155 - val_mean_squared_error: 0.1155\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1287 - mean_squared_error: 0.1287 - val_loss: 0.1931 - val_mean_squared_error: 0.1931\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1884 - mean_squared_error: 0.1884 - val_loss: 0.3132 - val_mean_squared_error: 0.3132\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2949 - mean_squared_error: 0.2949 - val_loss: 0.2920 - val_mean_squared_error: 0.2920\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2755 - mean_squared_error: 0.2755 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1619 - mean_squared_error: 0.1619 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1122 - mean_squared_error: 0.1122 - val_loss: 0.1546 - val_mean_squared_error: 0.1546\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1698 - mean_squared_error: 0.1698 - val_loss: 0.2066 - val_mean_squared_error: 0.2066\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2219 - mean_squared_error: 0.2219 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1829 - mean_squared_error: 0.1829 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1116 - mean_squared_error: 0.1116 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1047 - mean_squared_error: 0.1047 - val_loss: 0.1566 - val_mean_squared_error: 0.1566\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1695 - val_mean_squared_error: 0.1695\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.1197 - val_mean_squared_error: 0.1197\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0854 - mean_squared_error: 0.0854 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1047 - mean_squared_error: 0.1047 - val_loss: 0.1219 - val_mean_squared_error: 0.1219\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1288 - mean_squared_error: 0.1288 - val_loss: 0.1059 - val_mean_squared_error: 0.1059\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1119 - mean_squared_error: 0.1119 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0806 - mean_squared_error: 0.0806 - val_loss: 0.0805 - val_mean_squared_error: 0.0805\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0807 - mean_squared_error: 0.0807 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1006 - mean_squared_error: 0.1006 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0984 - mean_squared_error: 0.0984 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0760 - mean_squared_error: 0.0760 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0693 - mean_squared_error: 0.0693 - val_loss: 0.0802 - val_mean_squared_error: 0.0802\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0823 - mean_squared_error: 0.0823 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.1599 - mean_squared_error: 0.1599 - val_loss: 5.2957 - val_mean_squared_error: 5.2957\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.0867 - mean_squared_error: 5.0867 - val_loss: 0.1948 - val_mean_squared_error: 0.1948\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1972 - mean_squared_error: 0.1972 - val_loss: 2.4708 - val_mean_squared_error: 2.4708\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 2.3387 - mean_squared_error: 2.3387 - val_loss: 3.3373 - val_mean_squared_error: 3.3373\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.1596 - mean_squared_error: 3.1596 - val_loss: 1.1021 - val_mean_squared_error: 1.1021\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.0412 - mean_squared_error: 1.0412 - val_loss: 0.0990 - val_mean_squared_error: 0.0990\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1038 - mean_squared_error: 0.1038 - val_loss: 1.2167 - val_mean_squared_error: 1.2167\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.1848 - mean_squared_error: 1.1848 - val_loss: 1.9504 - val_mean_squared_error: 1.9504\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.8896 - mean_squared_error: 1.8896 - val_loss: 1.1905 - val_mean_squared_error: 1.1905\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.1600 - mean_squared_error: 1.1600 - val_loss: 0.2123 - val_mean_squared_error: 0.2123\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2159 - mean_squared_error: 0.2159 - val_loss: 0.2435 - val_mean_squared_error: 0.2435\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2326 - mean_squared_error: 0.2326 - val_loss: 0.9556 - val_mean_squared_error: 0.9556\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9024 - mean_squared_error: 0.9024 - val_loss: 1.1588 - val_mean_squared_error: 1.1588\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.0941 - mean_squared_error: 1.0941 - val_loss: 0.6337 - val_mean_squared_error: 0.6337\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5983 - mean_squared_error: 0.5983 - val_loss: 0.1282 - val_mean_squared_error: 0.1282\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1259 - mean_squared_error: 0.1259 - val_loss: 0.1890 - val_mean_squared_error: 0.1890\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1943 - mean_squared_error: 0.1943 - val_loss: 0.5624 - val_mean_squared_error: 0.5624\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.5578 - mean_squared_error: 0.5578 - val_loss: 0.6707 - val_mean_squared_error: 0.6707\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6627 - mean_squared_error: 0.6627 - val_loss: 0.3922 - val_mean_squared_error: 0.3922\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3930 - mean_squared_error: 0.3930 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1146 - mean_squared_error: 0.1146 - val_loss: 0.1447 - val_mean_squared_error: 0.1447\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1407 - mean_squared_error: 0.1407 - val_loss: 0.3791 - val_mean_squared_error: 0.3791\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3583 - mean_squared_error: 0.3583 - val_loss: 0.4585 - val_mean_squared_error: 0.4585\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4327 - mean_squared_error: 0.4327 - val_loss: 0.2858 - val_mean_squared_error: 0.2858\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2713 - mean_squared_error: 0.2713 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0986 - mean_squared_error: 0.0986 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1158 - mean_squared_error: 0.1158 - val_loss: 0.2468 - val_mean_squared_error: 0.2468\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2490 - mean_squared_error: 0.2490 - val_loss: 0.2879 - val_mean_squared_error: 0.2879\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2884 - mean_squared_error: 0.2884 - val_loss: 0.1803 - val_mean_squared_error: 0.1803\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1833 - mean_squared_error: 0.1833 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.1054 - val_mean_squared_error: 0.1054\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1040 - mean_squared_error: 0.1040 - val_loss: 0.1949 - val_mean_squared_error: 0.1949\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1870 - mean_squared_error: 0.1870 - val_loss: 0.2041 - val_mean_squared_error: 0.2041\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1957 - mean_squared_error: 0.1957 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1200 - mean_squared_error: 0.1200 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0687 - mean_squared_error: 0.0687 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0996 - mean_squared_error: 0.0996 - val_loss: 0.1465 - val_mean_squared_error: 0.1465\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1464 - mean_squared_error: 0.1464 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1318 - mean_squared_error: 0.1318 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0795 - mean_squared_error: 0.0795 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0644 - mean_squared_error: 0.0644 - val_loss: 0.0971 - val_mean_squared_error: 0.0971\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0957 - mean_squared_error: 0.0957 - val_loss: 0.1153 - val_mean_squared_error: 0.1153\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1130 - mean_squared_error: 0.1130 - val_loss: 0.0878 - val_mean_squared_error: 0.0878\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0869 - mean_squared_error: 0.0869 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0668 - mean_squared_error: 0.0668 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0877 - mean_squared_error: 0.0877 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0825 - mean_squared_error: 0.0825 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0597 - mean_squared_error: 0.0597 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0545 - mean_squared_error: 0.0545 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0837 - mean_squared_error: 0.0837 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1715 - mean_squared_error: 0.1715 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0722 - mean_squared_error: 0.0722 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0880 - mean_squared_error: 0.0880 - val_loss: 0.1236 - val_mean_squared_error: 0.1236\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1188 - mean_squared_error: 0.1188 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0739 - mean_squared_error: 0.0739 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0605 - mean_squared_error: 0.0605 - val_loss: 0.0865 - val_mean_squared_error: 0.0865\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0898 - mean_squared_error: 0.0898 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0878 - mean_squared_error: 0.0878 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0612 - mean_squared_error: 0.0612 - val_loss: 0.0577 - val_mean_squared_error: 0.0577\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0586 - mean_squared_error: 0.0586 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0758 - mean_squared_error: 0.0758 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0745 - mean_squared_error: 0.0745 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0577 - mean_squared_error: 0.0577 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0544 - mean_squared_error: 0.0544 - val_loss: 0.0629 - val_mean_squared_error: 0.0629\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0650 - mean_squared_error: 0.0650 - val_loss: 0.0641 - val_mean_squared_error: 0.0641\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0660 - mean_squared_error: 0.0660 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0553 - mean_squared_error: 0.0553 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0510 - mean_squared_error: 0.0510 - val_loss: 0.0574 - val_mean_squared_error: 0.0574\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0573 - mean_squared_error: 0.0573 - val_loss: 0.0598 - val_mean_squared_error: 0.0598\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0593 - mean_squared_error: 0.0593 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0523 - mean_squared_error: 0.0523 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0483 - mean_squared_error: 0.0483 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0520 - mean_squared_error: 0.0520 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0491 - mean_squared_error: 0.0491 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0492 - mean_squared_error: 0.0492 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0435 - mean_squared_error: 0.0435 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0450 - mean_squared_error: 0.0450 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0454 - mean_squared_error: 0.0454 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0413 - mean_squared_error: 0.0413 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0329 - val_mean_squared_error: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0552 - mean_squared_error: 0.0552 - val_loss: 0.1436 - val_mean_squared_error: 0.1436\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1408 - mean_squared_error: 0.1408 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0535 - mean_squared_error: 0.0535 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0873 - mean_squared_error: 0.0873 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1023 - mean_squared_error: 0.1023 - val_loss: 0.0659 - val_mean_squared_error: 0.0659\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0639 - mean_squared_error: 0.0639 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0507 - mean_squared_error: 0.0507 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0730 - mean_squared_error: 0.0730 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0798 - mean_squared_error: 0.0798 - val_loss: 0.0623 - val_mean_squared_error: 0.0623\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0612 - mean_squared_error: 0.0612 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0483 - mean_squared_error: 0.0483 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0668 - mean_squared_error: 0.0668 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0560 - val_mean_squared_error: 0.0560\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0547 - mean_squared_error: 0.0547 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0578 - mean_squared_error: 0.0578 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0518 - mean_squared_error: 0.0518 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0468 - mean_squared_error: 0.0468 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0512 - mean_squared_error: 0.0512 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0506 - mean_squared_error: 0.0506 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.0433 - mean_squared_error: 0.0433 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0473 - mean_squared_error: 0.0473 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.0449 - mean_squared_error: 0.0449 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0439 - mean_squared_error: 0.0439 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.5, 0.1, 0.05, 0.01]:\n",
    "    for i in range(N_MODELS):\n",
    "        histories[i] = train(models[i], [x_train, y_train], (x_val, y_val), lr, 500, history=histories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict target feature using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = []\n",
    "y_val_preds = []\n",
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(x_train))\n",
    "    y_val_preds.append(model.predict(x_val))\n",
    "    y_test_preds.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble variance to predict diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_var = np.var(y_train_preds, axis=0)\n",
    "y_val_preds_var = np.var(y_val_preds, axis=0)\n",
    "y_test_preds_var = np.var(y_test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(y_train_preds_var, color='b',  bins=50, label='train')\n",
    "plt.hist(y_val_preds_var, fc=(1, 0, 0, 0.5), bins=50, label='val')\n",
    "plt.hist(y_test_preds_var, fc=(0, 1, 0, 0.5), bins=500, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_var = 1.5 * y_train_preds_var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = (y_train_preds_var < threshold_var).mean()\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (y_val_preds_var < threshold_var).mean()\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (y_test_preds_var >= threshold_var).mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
