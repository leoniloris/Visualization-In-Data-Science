{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('kaggle datasets download -d uciml/breast-cancer-wisconsin-data -f data.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS = 'diagnosis'\n",
    "TARGET = 'radius_mean'\n",
    "FEATURES_PREFIX = 'mean'\n",
    "FEATURES = [feature for feature in df.columns if \\\n",
    "            (feature not in TARGET) and (FEATURES_PREFIX in feature)]\n",
    "N_FEATURES = len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0         10.38          122.80     1001.0          0.11840           0.27760   \n",
       "1         17.77          132.90     1326.0          0.08474           0.07864   \n",
       "2         21.25          130.00     1203.0          0.10960           0.15990   \n",
       "3         20.38           77.58      386.1          0.14250           0.28390   \n",
       "4         14.34          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  \n",
       "0          0.3001              0.14710         0.2419                 0.07871  \n",
       "1          0.0869              0.07017         0.1812                 0.05667  \n",
       "2          0.1974              0.12790         0.2069                 0.05999  \n",
       "3          0.2414              0.10520         0.2597                 0.09744  \n",
       "4          0.1980              0.10430         0.1809                 0.05883  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[TARGET]\n",
    "x = df[FEATURES]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = df[DIAGNOSIS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= x.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264257</td>\n",
       "      <td>0.651459</td>\n",
       "      <td>0.400240</td>\n",
       "      <td>0.724602</td>\n",
       "      <td>0.803706</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.807779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.596053</td>\n",
       "      <td>0.581589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.670747</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.680592</td>\n",
       "      <td>0.615661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518839</td>\n",
       "      <td>0.411565</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.854276</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365071</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.518593</td>\n",
       "      <td>0.613831</td>\n",
       "      <td>0.384482</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.595066</td>\n",
       "      <td>0.603756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0      0.264257        0.651459   0.400240         0.724602          0.803706   \n",
       "1      0.452393        0.705040   0.530188         0.518605          0.227678   \n",
       "2      0.540988        0.689655   0.481008         0.670747          0.462942   \n",
       "3      0.518839        0.411565   0.154378         0.872093          0.821946   \n",
       "4      0.365071        0.716711   0.518593         0.613831          0.384482   \n",
       "\n",
       "   concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  \n",
       "0        0.703140             0.731113       0.795724                0.807779  \n",
       "1        0.203608             0.348757       0.596053                0.581589  \n",
       "2        0.462512             0.635686       0.680592                0.615661  \n",
       "3        0.565604             0.522863       0.854276                1.000000  \n",
       "4        0.463918             0.518390       0.595066                0.603756  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train, Val & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_healthy, y_healthy = x[diagnosis == 'B'], y[diagnosis == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(x_healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_idxs = np.random.choice(x_healthy.index, TRAIN_SIZE, replace=False)\n",
    "val_idxs = x_healthy.index.drop(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for training: 285\n",
      "# Examples for validation: 72\n"
     ]
    }
   ],
   "source": [
    "e = x_healthy.loc[train_idxs].values\n",
    "y_train = y_healthy.loc[train_idxs].values\n",
    "print('# Examples for training:',  len(x_train))\n",
    "\n",
    "x_val = x_healthy.loc[val_idxs].values\n",
    "y_val = y_healthy.loc[val_idxs].values\n",
    "print('# Examples for validation:',  len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unhealthy, y_unhealthy = x[diagnosis == 'M'], y[diagnosis == 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for test: 212\n"
     ]
    }
   ],
   "source": [
    "x_test = x_unhealthy.values\n",
    "y_test = y_unhealthy.values\n",
    "print('# Examples for test:',  len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l1_l2\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_size, n_hidden):\n",
    "    i = Input((input_size, ))\n",
    "    h = Dense(n_hidden, kernel_initializer='normal', use_bias=True, kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(i)\n",
    "#     h = Dropout(0.6)(h)\n",
    "    h = LeakyReLU()(h)\n",
    "    o = Dense(1)(h)\n",
    "    return Model(i, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "N_MODELS = 5\n",
    "n_hidden_neurons = 64\n",
    "for _ in range(N_MODELS):\n",
    "    models.append(create_base_model(N_FEATURES, n_hidden_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, lr, batch_size, epochs=50, history=None):\n",
    "    current_epoch = 0 if history is None else len(history.history['loss'])\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    new_history = model.fit(\n",
    "        train_data[0], train_data[1], epochs=current_epoch+epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=val_data,\n",
    "        initial_epoch=current_epoch,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if history is not None:\n",
    "        for key in new_history.history:\n",
    "            history.history[key].extend(new_history.history[key])\n",
    "    else:\n",
    "        history = new_history\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 4s 14ms/step - loss: 151.7268 - mean_squared_error: 151.4692 - val_loss: 41.7251 - val_mean_squared_error: 37.3880\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 43.5521 - mean_squared_error: 39.2150 - val_loss: 3367.3188 - val_mean_squared_error: 3360.2642\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3174.1038 - mean_squared_error: 3167.0491 - val_loss: 281.1982 - val_mean_squared_error: 275.4937\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 260.8189 - mean_squared_error: 255.1145 - val_loss: 503.8671 - val_mean_squared_error: 498.1130\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 490.3260 - mean_squared_error: 484.5719 - val_loss: 766.7534 - val_mean_squared_error: 762.1720\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 742.5373 - mean_squared_error: 737.9559 - val_loss: 264.0039 - val_mean_squared_error: 260.7086\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 43us/step - loss: 259.6041 - mean_squared_error: 256.3088 - val_loss: 10.1469 - val_mean_squared_error: 7.1521\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 11.7032 - mean_squared_error: 8.7084 - val_loss: 182.3848 - val_mean_squared_error: 178.5592\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 167.8989 - mean_squared_error: 164.0733 - val_loss: 391.8678 - val_mean_squared_error: 387.1688\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 364.0265 - mean_squared_error: 359.3275 - val_loss: 191.1512 - val_mean_squared_error: 186.1684\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 176.4663 - mean_squared_error: 171.4835 - val_loss: 13.1561 - val_mean_squared_error: 7.9660\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 12.6533 - mean_squared_error: 7.4633 - val_loss: 99.5506 - val_mean_squared_error: 93.9542\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 100.1280 - mean_squared_error: 94.5316 - val_loss: 195.4498 - val_mean_squared_error: 189.3634\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 193.0167 - mean_squared_error: 186.9303 - val_loss: 90.8410 - val_mean_squared_error: 84.2129\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 91.4817 - mean_squared_error: 84.8537 - val_loss: 10.0469 - val_mean_squared_error: 2.7869\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 10.8173 - mean_squared_error: 3.5573 - val_loss: 80.6831 - val_mean_squared_error: 72.7546\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 74.5365 - mean_squared_error: 66.6079 - val_loss: 129.0420 - val_mean_squared_error: 120.6101\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 119.6345 - mean_squared_error: 111.2026 - val_loss: 50.0664 - val_mean_squared_error: 41.3806\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 46.4766 - mean_squared_error: 37.7908 - val_loss: 15.3100 - val_mean_squared_error: 6.4561\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 16.5788 - mean_squared_error: 7.7248 - val_loss: 77.5090 - val_mean_squared_error: 68.4595\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 77.9665 - mean_squared_error: 68.9170 - val_loss: 82.3266 - val_mean_squared_error: 73.0673\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 82.5481 - mean_squared_error: 73.2888 - val_loss: 22.0868 - val_mean_squared_error: 12.6095\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 23.3449 - mean_squared_error: 13.8676 - val_loss: 25.6171 - val_mean_squared_error: 15.9019\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 24.4152 - mean_squared_error: 14.7000 - val_loss: 71.3130 - val_mean_squared_error: 61.4125\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 66.6945 - mean_squared_error: 56.7940 - val_loss: 54.9929 - val_mean_squared_error: 45.0395\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 51.5882 - mean_squared_error: 41.6348 - val_loss: 14.4760 - val_mean_squared_error: 4.5641\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 14.5015 - mean_squared_error: 4.5896 - val_loss: 26.3444 - val_mean_squared_error: 16.4749\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 27.2467 - mean_squared_error: 17.3772 - val_loss: 49.4062 - val_mean_squared_error: 39.5466\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 49.7498 - mean_squared_error: 39.8902 - val_loss: 31.1577 - val_mean_squared_error: 21.2819\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 31.8456 - mean_squared_error: 21.9698 - val_loss: 11.8842 - val_mean_squared_error: 1.9644\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 12.3978 - mean_squared_error: 2.4780 - val_loss: 26.7597 - val_mean_squared_error: 16.7932\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 25.6635 - mean_squared_error: 15.6969 - val_loss: 38.3788 - val_mean_squared_error: 28.4108\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 36.4935 - mean_squared_error: 26.5256 - val_loss: 22.0968 - val_mean_squared_error: 12.1940\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 21.3967 - mean_squared_error: 11.4939 - val_loss: 11.6454 - val_mean_squared_error: 1.8402\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 12.1235 - mean_squared_error: 2.3183 - val_loss: 22.5797 - val_mean_squared_error: 12.8580\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 23.0466 - mean_squared_error: 13.3249 - val_loss: 27.2696 - val_mean_squared_error: 17.5989\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 27.5755 - mean_squared_error: 17.9047 - val_loss: 15.8628 - val_mean_squared_error: 6.2122\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 16.3552 - mean_squared_error: 6.7046 - val_loss: 11.8538 - val_mean_squared_error: 2.2070\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 12.0468 - mean_squared_error: 2.3999 - val_loss: 20.9288 - val_mean_squared_error: 11.3000\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 20.3691 - mean_squared_error: 10.7403 - val_loss: 21.9261 - val_mean_squared_error: 12.3617\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 21.3057 - mean_squared_error: 11.7412 - val_loss: 12.9071 - val_mean_squared_error: 3.4522\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 12.9403 - mean_squared_error: 3.4854 - val_loss: 11.7374 - val_mean_squared_error: 2.4014\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 12.1099 - mean_squared_error: 2.7739 - val_loss: 17.5399 - val_mean_squared_error: 8.3065\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 17.7965 - mean_squared_error: 8.5631 - val_loss: 16.2094 - val_mean_squared_error: 7.0551\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 16.4691 - mean_squared_error: 7.3148 - val_loss: 10.6855 - val_mean_squared_error: 1.5926\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 10.9961 - mean_squared_error: 1.9032 - val_loss: 11.9496 - val_mean_squared_error: 2.9131\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.9964 - mean_squared_error: 2.9599 - val_loss: 15.6024 - val_mean_squared_error: 6.6404\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 15.3845 - mean_squared_error: 6.4224 - val_loss: 13.1614 - val_mean_squared_error: 4.3014\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 13.0944 - mean_squared_error: 4.2345 - val_loss: 9.7587 - val_mean_squared_error: 1.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 9.9652 - mean_squared_error: 1.2250 - val_loss: 11.4446 - val_mean_squared_error: 2.8227\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 16ms/step - loss: 150.8597 - mean_squared_error: 150.6052 - val_loss: 51.6184 - val_mean_squared_error: 47.2812\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 47.1374 - mean_squared_error: 42.8001 - val_loss: 2332.5811 - val_mean_squared_error: 2327.3494\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2242.5471 - mean_squared_error: 2237.3154 - val_loss: 18.9788 - val_mean_squared_error: 13.6681\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 17.8015 - mean_squared_error: 12.4907 - val_loss: 1508.3330 - val_mean_squared_error: 1502.6152\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1421.0466 - mean_squared_error: 1415.3289 - val_loss: 450.3492 - val_mean_squared_error: 446.3083\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 421.6749 - mean_squared_error: 417.6341 - val_loss: 6.1591 - val_mean_squared_error: 3.8651\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 6.3823 - mean_squared_error: 4.0882 - val_loss: 76.9759 - val_mean_squared_error: 75.7046\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 77.4012 - mean_squared_error: 76.1300 - val_loss: 132.5590 - val_mean_squared_error: 131.5413\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 131.5527 - mean_squared_error: 130.5350 - val_loss: 95.6229 - val_mean_squared_error: 94.2152\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 96.0568 - mean_squared_error: 94.6491 - val_loss: 11.2612 - val_mean_squared_error: 9.0911\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 12.9828 - mean_squared_error: 10.8127 - val_loss: 99.5264 - val_mean_squared_error: 96.3812\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 90.9786 - mean_squared_error: 87.8334 - val_loss: 214.0823 - val_mean_squared_error: 210.2618\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 197.3934 - mean_squared_error: 193.5728 - val_loss: 67.9345 - val_mean_squared_error: 63.8716\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 61.9894 - mean_squared_error: 57.9265 - val_loss: 8.2942 - val_mean_squared_error: 4.0850\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.5904 - mean_squared_error: 5.3812 - val_loss: 51.1418 - val_mean_squared_error: 46.7116\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 52.7982 - mean_squared_error: 48.3681 - val_loss: 65.9376 - val_mean_squared_error: 61.2514\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 67.2225 - mean_squared_error: 62.5362 - val_loss: 29.6164 - val_mean_squared_error: 24.6728\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 31.3900 - mean_squared_error: 26.4465 - val_loss: 8.4133 - val_mean_squared_error: 3.1458\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.0900 - mean_squared_error: 3.8225 - val_loss: 34.4780 - val_mean_squared_error: 28.8324\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 31.8262 - mean_squared_error: 26.1806 - val_loss: 70.6467 - val_mean_squared_error: 64.6769\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 65.0293 - mean_squared_error: 59.0595 - val_loss: 70.0018 - val_mean_squared_error: 63.8177\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 64.5027 - mean_squared_error: 58.3186 - val_loss: 38.1576 - val_mean_squared_error: 31.8631\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 35.3107 - mean_squared_error: 29.0162 - val_loss: 12.2762 - val_mean_squared_error: 5.9176\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 12.1954 - mean_squared_error: 5.8369 - val_loss: 12.2311 - val_mean_squared_error: 5.8010\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 13.4831 - mean_squared_error: 7.0530 - val_loss: 25.9191 - val_mean_squared_error: 19.3811\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 27.3120 - mean_squared_error: 20.7740 - val_loss: 29.5584 - val_mean_squared_error: 22.8990\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 30.8652 - mean_squared_error: 24.2058 - val_loss: 18.4693 - val_mean_squared_error: 11.6909\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 19.7625 - mean_squared_error: 12.9842 - val_loss: 9.7613 - val_mean_squared_error: 2.8529\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 10.6077 - mean_squared_error: 3.6993 - val_loss: 13.3220 - val_mean_squared_error: 6.2594\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 13.1411 - mean_squared_error: 6.0785 - val_loss: 21.9048 - val_mean_squared_error: 14.6936\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 20.7828 - mean_squared_error: 13.5716 - val_loss: 24.3270 - val_mean_squared_error: 17.0108\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 22.9935 - mean_squared_error: 15.6773 - val_loss: 18.3417 - val_mean_squared_error: 10.9746\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 17.6094 - mean_squared_error: 10.2423 - val_loss: 11.1911 - val_mean_squared_error: 3.8163\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 11.3593 - mean_squared_error: 3.9845 - val_loss: 10.2358 - val_mean_squared_error: 2.8704\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 11.0260 - mean_squared_error: 3.6606 - val_loss: 14.5544 - val_mean_squared_error: 7.1918\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 15.5378 - mean_squared_error: 8.1751 - val_loss: 17.1555 - val_mean_squared_error: 9.7743\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 18.1196 - mean_squared_error: 10.7384 - val_loss: 14.5064 - val_mean_squared_error: 7.0824\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 15.4116 - mean_squared_error: 7.9877 - val_loss: 10.3864 - val_mean_squared_error: 2.8991\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 11.1057 - mean_squared_error: 3.6185 - val_loss: 10.1163 - val_mean_squared_error: 2.5623\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 10.4329 - mean_squared_error: 2.8789 - val_loss: 13.2668 - val_mean_squared_error: 5.6660\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 13.1297 - mean_squared_error: 5.5289 - val_loss: 15.0203 - val_mean_squared_error: 7.4120\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 14.7036 - mean_squared_error: 7.0953 - val_loss: 12.9670 - val_mean_squared_error: 5.3967\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 12.8618 - mean_squared_error: 5.2915 - val_loss: 9.9757 - val_mean_squared_error: 2.4765\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 10.2512 - mean_squared_error: 2.7520 - val_loss: 9.5579 - val_mean_squared_error: 2.1406\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.0959 - mean_squared_error: 2.6785 - val_loss: 11.2301 - val_mean_squared_error: 3.8850\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 11.8389 - mean_squared_error: 4.4938 - val_loss: 11.8910 - val_mean_squared_error: 4.5946\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 12.4789 - mean_squared_error: 5.1824 - val_loss: 10.4870 - val_mean_squared_error: 3.2153\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 11.0294 - mean_squared_error: 3.7576 - val_loss: 9.0418 - val_mean_squared_error: 1.7791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 9.4759 - mean_squared_error: 2.2132 - val_loss: 9.4037 - val_mean_squared_error: 2.1505\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 9.6530 - mean_squared_error: 2.3997 - val_loss: 10.6279 - val_mean_squared_error: 3.4016\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 4s 14ms/step - loss: 152.4881 - mean_squared_error: 152.2590 - val_loss: 7.4015 - val_mean_squared_error: 3.0973\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.1444 - mean_squared_error: 3.8402 - val_loss: 34.1454 - val_mean_squared_error: 26.5551\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 32.4025 - mean_squared_error: 24.8122 - val_loss: 3627.5750 - val_mean_squared_error: 3618.3420\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 3456.3398 - mean_squared_error: 3447.1069 - val_loss: 32.9169 - val_mean_squared_error: 24.2446\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 31.3929 - mean_squared_error: 22.7206 - val_loss: 2529.1855 - val_mean_squared_error: 2520.5400\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2397.4985 - mean_squared_error: 2388.8530 - val_loss: 1468.4087 - val_mean_squared_error: 1460.9683\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 1389.2351 - mean_squared_error: 1381.7947 - val_loss: 106.3650 - val_mean_squared_error: 100.2801\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 99.3037 - mean_squared_error: 93.2189 - val_loss: 170.5437 - val_mean_squared_error: 165.4222\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 167.2975 - mean_squared_error: 162.1759 - val_loss: 605.8071 - val_mean_squared_error: 601.3831\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 586.3903 - mean_squared_error: 581.9663 - val_loss: 701.9083 - val_mean_squared_error: 698.1409\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 679.2458 - mean_squared_error: 675.4783 - val_loss: 521.8796 - val_mean_squared_error: 518.7921\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 4us/step - loss: 506.9018 - mean_squared_error: 503.8141 - val_loss: 298.7765 - val_mean_squared_error: 296.2997\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 292.5104 - mean_squared_error: 290.0335 - val_loss: 140.2508 - val_mean_squared_error: 138.2175\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 11us/step - loss: 139.5007 - mean_squared_error: 137.4674 - val_loss: 52.0008 - val_mean_squared_error: 50.1535\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 53.5926 - mean_squared_error: 51.7453 - val_loss: 12.3368 - val_mean_squared_error: 10.2615\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 62us/step - loss: 14.0515 - mean_squared_error: 11.9762 - val_loss: 6.2068 - val_mean_squared_error: 3.5576\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 6.7469 - mean_squared_error: 4.0977 - val_loss: 13.1323 - val_mean_squared_error: 9.8479\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 67us/step - loss: 12.5734 - mean_squared_error: 9.2890 - val_loss: 12.5306 - val_mean_squared_error: 8.6167\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 12.2098 - mean_squared_error: 8.2959 - val_loss: 7.8561 - val_mean_squared_error: 3.3201\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 51us/step - loss: 8.9010 - mean_squared_error: 4.3650 - val_loss: 19.4029 - val_mean_squared_error: 14.2580\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 21.1482 - mean_squared_error: 16.0034 - val_loss: 23.6068 - val_mean_squared_error: 17.8717\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 25.3033 - mean_squared_error: 19.5682 - val_loss: 9.5274 - val_mean_squared_error: 3.2482\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 10.4916 - mean_squared_error: 4.2124 - val_loss: 27.4765 - val_mean_squared_error: 20.6773\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 67us/step - loss: 26.0594 - mean_squared_error: 19.2602 - val_loss: 15.6929 - val_mean_squared_error: 8.4256\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 15.5497 - mean_squared_error: 8.2824 - val_loss: 21.4564 - val_mean_squared_error: 13.7499\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 22.3442 - mean_squared_error: 14.6377 - val_loss: 18.4749 - val_mean_squared_error: 10.3804\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 19.1483 - mean_squared_error: 11.0538 - val_loss: 23.7669 - val_mean_squared_error: 15.3261\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 23.3826 - mean_squared_error: 14.9418 - val_loss: 14.7418 - val_mean_squared_error: 5.9764\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 14.9957 - mean_squared_error: 6.2302 - val_loss: 28.4803 - val_mean_squared_error: 19.4144\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 28.0648 - mean_squared_error: 18.9989 - val_loss: 11.3763 - val_mean_squared_error: 2.0746\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 11.7444 - mean_squared_error: 2.4426 - val_loss: 24.0409 - val_mean_squared_error: 14.5276\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 23.9346 - mean_squared_error: 14.4213 - val_loss: 21.2557 - val_mean_squared_error: 11.5364\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 60us/step - loss: 20.6843 - mean_squared_error: 10.9650 - val_loss: 11.8002 - val_mean_squared_error: 1.9296\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 11.8531 - mean_squared_error: 1.9826 - val_loss: 23.6320 - val_mean_squared_error: 13.6363\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 23.5976 - mean_squared_error: 13.6019 - val_loss: 20.2290 - val_mean_squared_error: 10.1041\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 19.4385 - mean_squared_error: 9.3136 - val_loss: 10.9264 - val_mean_squared_error: 0.7219\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 10us/step - loss: 10.9744 - mean_squared_error: 0.7698 - val_loss: 18.3925 - val_mean_squared_error: 8.1246\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 18.4835 - mean_squared_error: 8.2155 - val_loss: 22.9344 - val_mean_squared_error: 12.5962\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 65us/step - loss: 21.7659 - mean_squared_error: 11.4277 - val_loss: 13.5472 - val_mean_squared_error: 3.1910\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 13.6691 - mean_squared_error: 3.3130 - val_loss: 11.1319 - val_mean_squared_error: 0.7537\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 11.2155 - mean_squared_error: 0.8373 - val_loss: 18.3753 - val_mean_squared_error: 7.9798\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 17.6176 - mean_squared_error: 7.2220 - val_loss: 20.0302 - val_mean_squared_error: 9.6551\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 19.8130 - mean_squared_error: 9.4379 - val_loss: 14.6406 - val_mean_squared_error: 4.2715\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 14.2992 - mean_squared_error: 3.9301 - val_loss: 10.4819 - val_mean_squared_error: 0.1459\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 10.4880 - mean_squared_error: 0.1520 - val_loss: 13.2946 - val_mean_squared_error: 2.9975\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 56us/step - loss: 13.1630 - mean_squared_error: 2.8659 - val_loss: 17.5074 - val_mean_squared_error: 7.2438\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 13us/step - loss: 17.2021 - mean_squared_error: 6.9384 - val_loss: 17.2943 - val_mean_squared_error: 7.0948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 46us/step - loss: 16.8874 - mean_squared_error: 6.6878 - val_loss: 12.9294 - val_mean_squared_error: 2.7807\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 12.8785 - mean_squared_error: 2.7298 - val_loss: 10.3601 - val_mean_squared_error: 0.2815\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 10.3654 - mean_squared_error: 0.2867 - val_loss: 11.7033 - val_mean_squared_error: 1.6961\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 4s 14ms/step - loss: 150.8208 - mean_squared_error: 150.5901 - val_loss: 17.2982 - val_mean_squared_error: 12.9821\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 16.2531 - mean_squared_error: 11.9370 - val_loss: 3193.7944 - val_mean_squared_error: 3186.9724\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3059.5984 - mean_squared_error: 3052.7764 - val_loss: 64.4101 - val_mean_squared_error: 57.6892\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 59.7518 - mean_squared_error: 53.0308 - val_loss: 2260.1621 - val_mean_squared_error: 2253.3242\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 2134.7573 - mean_squared_error: 2127.9194 - val_loss: 822.1007 - val_mean_squared_error: 817.1188\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 773.1010 - mean_squared_error: 768.1191 - val_loss: 40.6959 - val_mean_squared_error: 37.4874\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 37.5007 - mean_squared_error: 34.2922 - val_loss: 57.5834 - val_mean_squared_error: 55.5580\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 58.8061 - mean_squared_error: 56.7806 - val_loss: 138.5094 - val_mean_squared_error: 137.0084\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 138.1744 - mean_squared_error: 136.6734 - val_loss: 86.6084 - val_mean_squared_error: 85.0384\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 88.1705 - mean_squared_error: 86.6004 - val_loss: 5.4990 - val_mean_squared_error: 3.4317\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 6.4155 - mean_squared_error: 4.3481 - val_loss: 187.3085 - val_mean_squared_error: 184.4611\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 170.9705 - mean_squared_error: 168.1231 - val_loss: 249.1120 - val_mean_squared_error: 245.7696\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 228.3633 - mean_squared_error: 225.0209 - val_loss: 88.0817 - val_mean_squared_error: 84.5290\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 79.5999 - mean_squared_error: 76.0472 - val_loss: 7.2237 - val_mean_squared_error: 3.5254\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.0117 - mean_squared_error: 4.3134 - val_loss: 44.1078 - val_mean_squared_error: 40.2032\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 46.6016 - mean_squared_error: 42.6971 - val_loss: 76.6417 - val_mean_squared_error: 72.4913\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 78.6044 - mean_squared_error: 74.4540 - val_loss: 48.4883 - val_mean_squared_error: 44.0885\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 50.7346 - mean_squared_error: 46.3348 - val_loss: 10.9616 - val_mean_squared_error: 6.2740\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 12.6217 - mean_squared_error: 7.9341 - val_loss: 20.5560 - val_mean_squared_error: 15.5283\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 18.9908 - mean_squared_error: 13.9631 - val_loss: 64.1896 - val_mean_squared_error: 58.8418\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 59us/step - loss: 58.4787 - mean_squared_error: 53.1309 - val_loss: 82.5647 - val_mean_squared_error: 76.9749\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 75.4726 - mean_squared_error: 69.8828 - val_loss: 55.3535 - val_mean_squared_error: 49.6155\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 60us/step - loss: 50.5579 - mean_squared_error: 44.8198 - val_loss: 19.9351 - val_mean_squared_error: 14.1021\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 18.5887 - mean_squared_error: 12.7557 - val_loss: 8.9140 - val_mean_squared_error: 2.9856\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 61us/step - loss: 9.8880 - mean_squared_error: 3.9596 - val_loss: 20.5673 - val_mean_squared_error: 14.5139\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 22.2738 - mean_squared_error: 16.2204 - val_loss: 30.1581 - val_mean_squared_error: 23.9524\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 40us/step - loss: 31.8862 - mean_squared_error: 25.6805 - val_loss: 24.6200 - val_mean_squared_error: 18.2766\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 26.3115 - mean_squared_error: 19.9681 - val_loss: 13.0207 - val_mean_squared_error: 6.5597\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 14.4102 - mean_squared_error: 7.9491 - val_loss: 9.3880 - val_mean_squared_error: 2.8122\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 9.8845 - mean_squared_error: 3.3087 - val_loss: 16.0814 - val_mean_squared_error: 9.3858\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 15.3226 - mean_squared_error: 8.6269 - val_loss: 24.6666 - val_mean_squared_error: 17.8544\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 22.9326 - mean_squared_error: 16.1205 - val_loss: 26.0534 - val_mean_squared_error: 19.1454\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 56us/step - loss: 24.1900 - mean_squared_error: 17.2820 - val_loss: 19.4962 - val_mean_squared_error: 12.5216\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 18.3439 - mean_squared_error: 11.3693 - val_loss: 11.6936 - val_mean_squared_error: 4.6731\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 11.6084 - mean_squared_error: 4.5878 - val_loss: 9.5513 - val_mean_squared_error: 2.4951\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 10.3260 - mean_squared_error: 3.2698 - val_loss: 13.3470 - val_mean_squared_error: 6.2585\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 14.5338 - mean_squared_error: 7.4453 - val_loss: 16.9505 - val_mean_squared_error: 9.8326\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 18.2167 - mean_squared_error: 11.0988 - val_loss: 15.6721 - val_mean_squared_error: 8.5257\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 16.8734 - mean_squared_error: 9.7270 - val_loss: 11.3560 - val_mean_squared_error: 4.1804\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 12.3365 - mean_squared_error: 5.1609 - val_loss: 9.3014 - val_mean_squared_error: 2.0957\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 9.8245 - mean_squared_error: 2.6188 - val_loss: 11.3634 - val_mean_squared_error: 4.1307\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 11.2880 - mean_squared_error: 4.0553 - val_loss: 14.4810 - val_mean_squared_error: 7.2354\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 13.9617 - mean_squared_error: 6.7160 - val_loss: 14.8214 - val_mean_squared_error: 7.5837\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 63us/step - loss: 14.2607 - mean_squared_error: 7.0230 - val_loss: 12.1210 - val_mean_squared_error: 4.9131\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 11.9028 - mean_squared_error: 4.6949 - val_loss: 9.4200 - val_mean_squared_error: 2.2565\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 9.6786 - mean_squared_error: 2.5150 - val_loss: 9.2200 - val_mean_squared_error: 2.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 63us/step - loss: 9.8260 - mean_squared_error: 2.7104 - val_loss: 10.7012 - val_mean_squared_error: 3.6307\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 11.4554 - mean_squared_error: 4.3850 - val_loss: 11.3206 - val_mean_squared_error: 4.2880\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 0us/step - loss: 12.0811 - mean_squared_error: 5.0485 - val_loss: 10.1779 - val_mean_squared_error: 3.1754\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 78us/step - loss: 10.8574 - mean_squared_error: 3.8548 - val_loss: 8.7867 - val_mean_squared_error: 1.8086\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 4s 14ms/step - loss: 152.7791 - mean_squared_error: 152.5501 - val_loss: 14.0844 - val_mean_squared_error: 11.1539\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 15.7217 - mean_squared_error: 12.7912 - val_loss: 2594.0652 - val_mean_squared_error: 2587.3652\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 2445.3560 - mean_squared_error: 2438.6560 - val_loss: 36.5266 - val_mean_squared_error: 31.0230\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 33.5990 - mean_squared_error: 28.0954 - val_loss: 555.1269 - val_mean_squared_error: 549.5308\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 539.3507 - mean_squared_error: 533.7546 - val_loss: 551.8334 - val_mean_squared_error: 547.2651\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 536.5106 - mean_squared_error: 531.9423 - val_loss: 72.3999 - val_mean_squared_error: 68.4335\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 73.8426 - mean_squared_error: 69.8762 - val_loss: 230.5652 - val_mean_squared_error: 226.0816\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 212.8449 - mean_squared_error: 208.3613 - val_loss: 585.2947 - val_mean_squared_error: 580.4569\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 545.3186 - mean_squared_error: 540.4808 - val_loss: 310.6032 - val_mean_squared_error: 306.1578\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 288.0537 - mean_squared_error: 283.6083 - val_loss: 88.8460 - val_mean_squared_error: 84.8584\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 81.3487 - mean_squared_error: 77.3611 - val_loss: 15.0045 - val_mean_squared_error: 11.2887\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 14.0235 - mean_squared_error: 10.3077 - val_loss: 7.5171 - val_mean_squared_error: 3.7883\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 8.6840 - mean_squared_error: 4.9552 - val_loss: 15.4681 - val_mean_squared_error: 11.5847\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 17.1444 - mean_squared_error: 13.2610 - val_loss: 17.7111 - val_mean_squared_error: 13.5888\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 19.4323 - mean_squared_error: 15.3100 - val_loss: 11.2486 - val_mean_squared_error: 6.8296\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 12.7174 - mean_squared_error: 8.2983 - val_loss: 7.7408 - val_mean_squared_error: 2.9928\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 8.3042 - mean_squared_error: 3.5562 - val_loss: 17.9350 - val_mean_squared_error: 12.8393\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 16.7617 - mean_squared_error: 11.6660 - val_loss: 35.5695 - val_mean_squared_error: 30.1418\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 32.6034 - mean_squared_error: 27.1757 - val_loss: 40.6945 - val_mean_squared_error: 34.9786\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 37.2944 - mean_squared_error: 31.5785 - val_loss: 25.6638 - val_mean_squared_error: 19.6971\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 23.7145 - mean_squared_error: 17.7478 - val_loss: 9.4702 - val_mean_squared_error: 3.2450\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 9.7716 - mean_squared_error: 3.5464 - val_loss: 21.0331 - val_mean_squared_error: 14.5322\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 22.4637 - mean_squared_error: 15.9627 - val_loss: 28.9065 - val_mean_squared_error: 22.1652\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 30.3143 - mean_squared_error: 23.5731 - val_loss: 10.9011 - val_mean_squared_error: 3.9667\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.9212 - mean_squared_error: 4.9868 - val_loss: 18.8807 - val_mean_squared_error: 11.7688\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 17.8098 - mean_squared_error: 10.6980 - val_loss: 31.7990 - val_mean_squared_error: 24.5275\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 29.4620 - mean_squared_error: 22.1906 - val_loss: 15.1237 - val_mean_squared_error: 7.7259\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 14.5104 - mean_squared_error: 7.1125 - val_loss: 13.0570 - val_mean_squared_error: 5.5432\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 14.0141 - mean_squared_error: 6.5002 - val_loss: 23.8682 - val_mean_squared_error: 16.2592\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 24.8448 - mean_squared_error: 17.2358 - val_loss: 11.2550 - val_mean_squared_error: 3.5894\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 12.0072 - mean_squared_error: 4.3416 - val_loss: 15.5923 - val_mean_squared_error: 7.8826\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 14.9297 - mean_squared_error: 7.2200 - val_loss: 21.8103 - val_mean_squared_error: 14.0674\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 20.5563 - mean_squared_error: 12.8135 - val_loss: 9.9694 - val_mean_squared_error: 2.2094\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 10.0235 - mean_squared_error: 2.2635 - val_loss: 14.7144 - val_mean_squared_error: 6.9433\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 15.3054 - mean_squared_error: 7.5343 - val_loss: 15.4235 - val_mean_squared_error: 7.6596\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 15.9436 - mean_squared_error: 8.1797 - val_loss: 8.9503 - val_mean_squared_error: 1.2051\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.1244 - mean_squared_error: 1.3792 - val_loss: 15.9670 - val_mean_squared_error: 8.2441\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 15.3177 - mean_squared_error: 7.5948 - val_loss: 12.1430 - val_mean_squared_error: 4.4538\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.8425 - mean_squared_error: 4.1532 - val_loss: 9.3683 - val_mean_squared_error: 1.7204\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 9.6676 - mean_squared_error: 2.0198 - val_loss: 13.5711 - val_mean_squared_error: 5.9684\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 13.8292 - mean_squared_error: 6.2265 - val_loss: 8.7499 - val_mean_squared_error: 1.2014\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.9818 - mean_squared_error: 1.4333 - val_loss: 10.7792 - val_mean_squared_error: 3.2830\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 10.5841 - mean_squared_error: 3.0880 - val_loss: 11.6543 - val_mean_squared_error: 4.2174\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 11.3795 - mean_squared_error: 3.9426 - val_loss: 7.8954 - val_mean_squared_error: 0.5284\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.0190 - mean_squared_error: 0.6521 - val_loss: 10.5531 - val_mean_squared_error: 3.2576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 10.7018 - mean_squared_error: 3.4063 - val_loss: 8.8291 - val_mean_squared_error: 1.6063\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 8.9791 - mean_squared_error: 1.7562 - val_loss: 8.1934 - val_mean_squared_error: 1.0412\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.1760 - mean_squared_error: 1.0238 - val_loss: 9.9967 - val_mean_squared_error: 2.9184\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 9.8086 - mean_squared_error: 2.7304 - val_loss: 7.5451 - val_mean_squared_error: 0.5499\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 7.5670 - mean_squared_error: 0.5718 - val_loss: 8.3506 - val_mean_squared_error: 1.4406\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 11.6813 - mean_squared_error: 3.0595 - val_loss: 143.6346 - val_mean_squared_error: 134.6189\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 137.1339 - mean_squared_error: 128.1182 - val_loss: 25.5682 - val_mean_squared_error: 16.8698\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 24.7925 - mean_squared_error: 16.0941 - val_loss: 30.5921 - val_mean_squared_error: 22.1610\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 30.2207 - mean_squared_error: 21.7896 - val_loss: 74.8689 - val_mean_squared_error: 66.5730\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 72.9057 - mean_squared_error: 64.6098 - val_loss: 60.1447 - val_mean_squared_error: 51.8706\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 58.8616 - mean_squared_error: 50.5874 - val_loss: 20.2351 - val_mean_squared_error: 11.8821\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 20.3840 - mean_squared_error: 12.0310 - val_loss: 13.2600 - val_mean_squared_error: 4.7673\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 13.0373 - mean_squared_error: 4.5445 - val_loss: 41.6285 - val_mean_squared_error: 33.0690\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 39.5462 - mean_squared_error: 30.9867 - val_loss: 39.7171 - val_mean_squared_error: 31.2512\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 37.7744 - mean_squared_error: 29.3085 - val_loss: 18.7457 - val_mean_squared_error: 10.4515\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 18.1252 - mean_squared_error: 9.8310 - val_loss: 9.0344 - val_mean_squared_error: 0.9311\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 9.2567 - mean_squared_error: 1.1533 - val_loss: 15.1995 - val_mean_squared_error: 7.2557\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 15.4221 - mean_squared_error: 7.4783 - val_loss: 23.2034 - val_mean_squared_error: 15.3700\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 16us/step - loss: 23.1809 - mean_squared_error: 15.3475 - val_loss: 22.6432 - val_mean_squared_error: 14.8763\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 22.6175 - mean_squared_error: 14.8505 - val_loss: 15.2582 - val_mean_squared_error: 7.5209\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 15.4317 - mean_squared_error: 7.6944 - val_loss: 9.2314 - val_mean_squared_error: 1.4998\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 9.4913 - mean_squared_error: 1.7597 - val_loss: 9.8803 - val_mean_squared_error: 2.1466\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 9.9282 - mean_squared_error: 2.1946 - val_loss: 14.9474 - val_mean_squared_error: 7.2249\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 14.6412 - mean_squared_error: 6.9188 - val_loss: 17.8440 - val_mean_squared_error: 10.1618\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 17.3651 - mean_squared_error: 9.6829 - val_loss: 15.4406 - val_mean_squared_error: 7.8292\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 15.1077 - mean_squared_error: 7.4962 - val_loss: 10.7011 - val_mean_squared_error: 3.1826\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 10.6720 - mean_squared_error: 3.1535 - val_loss: 8.2762 - val_mean_squared_error: 0.8558\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 8.4635 - mean_squared_error: 1.0431 - val_loss: 9.5221 - val_mean_squared_error: 2.1915\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.7464 - mean_squared_error: 2.4158 - val_loss: 11.9909 - val_mean_squared_error: 4.7347\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 12.1580 - mean_squared_error: 4.9018 - val_loss: 12.6076 - val_mean_squared_error: 5.4069\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 12.7504 - mean_squared_error: 5.5496 - val_loss: 10.7990 - val_mean_squared_error: 3.6358\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 10.9801 - mean_squared_error: 3.8169 - val_loss: 8.5430 - val_mean_squared_error: 1.4034\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 8.7541 - mean_squared_error: 1.6146 - val_loss: 7.9728 - val_mean_squared_error: 0.8509\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.1335 - mean_squared_error: 1.0117 - val_loss: 9.1997 - val_mean_squared_error: 2.0996\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 9.2458 - mean_squared_error: 2.1457 - val_loss: 10.4646 - val_mean_squared_error: 3.3969\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.4237 - mean_squared_error: 3.3560 - val_loss: 10.2389 - val_mean_squared_error: 3.2204\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.2092 - mean_squared_error: 3.1907 - val_loss: 8.8143 - val_mean_squared_error: 1.8606\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 8.8740 - mean_squared_error: 1.9204 - val_loss: 7.6786 - val_mean_squared_error: 0.8000\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.8278 - mean_squared_error: 0.9492 - val_loss: 7.7782 - val_mean_squared_error: 0.9751\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 7.9598 - mean_squared_error: 1.1567 - val_loss: 8.5625 - val_mean_squared_error: 1.8263\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.7313 - mean_squared_error: 1.9951 - val_loss: 8.8967 - val_mean_squared_error: 2.2145\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 9.0519 - mean_squared_error: 2.3698 - val_loss: 8.3485 - val_mean_squared_error: 1.7079\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.5094 - mean_squared_error: 1.8688 - val_loss: 7.5275 - val_mean_squared_error: 0.9189\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 7.6938 - mean_squared_error: 1.0852 - val_loss: 7.2551 - val_mean_squared_error: 0.6736\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 7.4013 - mean_squared_error: 0.8199 - val_loss: 7.6244 - val_mean_squared_error: 1.0723\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 7.7292 - mean_squared_error: 1.1771 - val_loss: 8.0047 - val_mean_squared_error: 1.4909\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 8.0797 - mean_squared_error: 1.5659 - val_loss: 7.8582 - val_mean_squared_error: 1.3952\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 7.9383 - mean_squared_error: 1.4752 - val_loss: 7.3275 - val_mean_squared_error: 0.9239\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 13us/step - loss: 7.4378 - mean_squared_error: 1.0342 - val_loss: 6.9567 - val_mean_squared_error: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.0932 - mean_squared_error: 0.7535 - val_loss: 7.0167 - val_mean_squared_error: 0.7394\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 7.1585 - mean_squared_error: 0.8812 - val_loss: 7.2533 - val_mean_squared_error: 1.0305\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 7.3868 - mean_squared_error: 1.1640 - val_loss: 7.2652 - val_mean_squared_error: 1.0886\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.3933 - mean_squared_error: 1.2168 - val_loss: 6.9873 - val_mean_squared_error: 0.8489\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 7.1174 - mean_squared_error: 0.9790 - val_loss: 6.7042 - val_mean_squared_error: 0.5985\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.8343 - mean_squared_error: 0.7286 - val_loss: 6.6647 - val_mean_squared_error: 0.5904\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 10.7215 - mean_squared_error: 3.4951 - val_loss: 112.2927 - val_mean_squared_error: 105.4389\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 109.1953 - mean_squared_error: 102.3414 - val_loss: 23.2892 - val_mean_squared_error: 16.3029\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 23.4931 - mean_squared_error: 16.5068 - val_loss: 27.7348 - val_mean_squared_error: 20.4841\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 26.6160 - mean_squared_error: 19.3653 - val_loss: 69.2878 - val_mean_squared_error: 62.0038\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 65.7741 - mean_squared_error: 58.4901 - val_loss: 49.8646 - val_mean_squared_error: 42.7604\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 47.4339 - mean_squared_error: 40.3297 - val_loss: 16.3316 - val_mean_squared_error: 9.4746\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 15.9422 - mean_squared_error: 9.0852 - val_loss: 9.6129 - val_mean_squared_error: 2.9796\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 10.0710 - mean_squared_error: 3.4376 - val_loss: 24.5445 - val_mean_squared_error: 18.0730\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 24.7136 - mean_squared_error: 18.2420 - val_loss: 33.8629 - val_mean_squared_error: 27.4940\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 48us/step - loss: 33.7607 - mean_squared_error: 27.3918 - val_loss: 27.0821 - val_mean_squared_error: 20.7707\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 27.1974 - mean_squared_error: 20.8860 - val_loss: 13.6990 - val_mean_squared_error: 7.4084\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 45us/step - loss: 14.1491 - mean_squared_error: 7.8585 - val_loss: 7.8666 - val_mean_squared_error: 1.5709\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 8.1930 - mean_squared_error: 1.8973 - val_loss: 14.3604 - val_mean_squared_error: 8.0615\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 14.0114 - mean_squared_error: 7.7125 - val_loss: 21.3838 - val_mean_squared_error: 15.1264\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 20.5339 - mean_squared_error: 14.2765 - val_loss: 19.2135 - val_mean_squared_error: 13.0471\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 18.5113 - mean_squared_error: 12.3449 - val_loss: 11.8733 - val_mean_squared_error: 5.8270\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 11.7036 - mean_squared_error: 5.6573 - val_loss: 7.5007 - val_mean_squared_error: 1.5797\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 7.7752 - mean_squared_error: 1.8542 - val_loss: 8.7545 - val_mean_squared_error: 2.9496\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 49us/step - loss: 9.1772 - mean_squared_error: 3.3723 - val_loss: 12.0657 - val_mean_squared_error: 6.3525\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 12.4571 - mean_squared_error: 6.7440 - val_loss: 13.2349 - val_mean_squared_error: 7.5880\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 13.5945 - mean_squared_error: 7.9476 - val_loss: 11.2050 - val_mean_squared_error: 5.6072\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 11.5876 - mean_squared_error: 5.9899 - val_loss: 8.1384 - val_mean_squared_error: 2.5770\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 8.5276 - mean_squared_error: 2.9662 - val_loss: 6.8648 - val_mean_squared_error: 1.3318\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 7.1565 - mean_squared_error: 1.6236 - val_loss: 8.0845 - val_mean_squared_error: 2.5807\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 8.1853 - mean_squared_error: 2.6815 - val_loss: 9.9982 - val_mean_squared_error: 4.5335\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 9.9286 - mean_squared_error: 4.4639 - val_loss: 10.3932 - val_mean_squared_error: 4.9826\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 10.2881 - mean_squared_error: 4.8775 - val_loss: 8.9353 - val_mean_squared_error: 3.5928\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 8.9368 - mean_squared_error: 3.5943 - val_loss: 7.1011 - val_mean_squared_error: 1.8335\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 7.2631 - mean_squared_error: 1.9956 - val_loss: 6.4109 - val_mean_squared_error: 1.2202\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.6926 - mean_squared_error: 1.5019 - val_loss: 7.0329 - val_mean_squared_error: 1.9127\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.3577 - mean_squared_error: 2.2375 - val_loss: 7.8654 - val_mean_squared_error: 2.8066\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 8.1884 - mean_squared_error: 3.1296 - val_loss: 7.8818 - val_mean_squared_error: 2.8746\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 8.1975 - mean_squared_error: 3.1902 - val_loss: 7.0585 - val_mean_squared_error: 2.0918\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 7.3673 - mean_squared_error: 2.4006 - val_loss: 6.2086 - val_mean_squared_error: 1.2750\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 44us/step - loss: 6.4892 - mean_squared_error: 1.5556 - val_loss: 6.0588 - val_mean_squared_error: 1.1553\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 6.2754 - mean_squared_error: 1.3719 - val_loss: 6.5458 - val_mean_squared_error: 1.6740\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 6.6853 - mean_squared_error: 1.8134 - val_loss: 6.9822 - val_mean_squared_error: 2.1483\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 7.0724 - mean_squared_error: 2.2384 - val_loss: 6.8393 - val_mean_squared_error: 2.0517\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 6.9344 - mean_squared_error: 2.1468 - val_loss: 6.2415 - val_mean_squared_error: 1.5084\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.3848 - mean_squared_error: 1.6517 - val_loss: 5.7318 - val_mean_squared_error: 1.0582\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.9315 - mean_squared_error: 1.2580 - val_loss: 5.6680 - val_mean_squared_error: 1.0529\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.9042 - mean_squared_error: 1.2891 - val_loss: 5.9037 - val_mean_squared_error: 1.3409\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 51us/step - loss: 6.1508 - mean_squared_error: 1.5880 - val_loss: 6.0342 - val_mean_squared_error: 1.5157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 6.2786 - mean_squared_error: 1.7602 - val_loss: 5.8488 - val_mean_squared_error: 1.3671\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 6.0861 - mean_squared_error: 1.6044 - val_loss: 5.5124 - val_mean_squared_error: 1.0628\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 5.7359 - mean_squared_error: 1.2864 - val_loss: 5.3261 - val_mean_squared_error: 0.9064\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 5.5242 - mean_squared_error: 1.1044 - val_loss: 5.3979 - val_mean_squared_error: 1.0075\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 47us/step - loss: 5.5632 - mean_squared_error: 1.1728 - val_loss: 5.5430 - val_mean_squared_error: 1.1844\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 51us/step - loss: 5.6828 - mean_squared_error: 1.3241 - val_loss: 5.5292 - val_mean_squared_error: 1.2080\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 44us/step - loss: 5.6629 - mean_squared_error: 1.3417 - val_loss: 5.3251 - val_mean_squared_error: 1.0470\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 11.6001 - mean_squared_error: 1.5929 - val_loss: 926.4293 - val_mean_squared_error: 916.2018\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 880.4106 - mean_squared_error: 870.1832 - val_loss: 63.8835 - val_mean_squared_error: 53.8634\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 61.5499 - mean_squared_error: 51.5298 - val_loss: 209.5447 - val_mean_squared_error: 199.6232\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 199.3974 - mean_squared_error: 189.4759 - val_loss: 485.6421 - val_mean_squared_error: 475.8575\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 461.9268 - mean_squared_error: 452.1423 - val_loss: 379.3844 - val_mean_squared_error: 369.7570\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 360.7929 - mean_squared_error: 351.1655 - val_loss: 128.2661 - val_mean_squared_error: 118.7638\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 122.0198 - mean_squared_error: 112.5175 - val_loss: 10.2910 - val_mean_squared_error: 0.8576\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 15us/step - loss: 10.2181 - mean_squared_error: 0.7847 - val_loss: 77.9086 - val_mean_squared_error: 68.5068\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 75.1837 - mean_squared_error: 65.7818 - val_loss: 194.9917 - val_mean_squared_error: 185.6302\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 187.0594 - mean_squared_error: 177.6979 - val_loss: 211.0808 - val_mean_squared_error: 201.7909\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 202.4387 - mean_squared_error: 193.1488 - val_loss: 125.1474 - val_mean_squared_error: 115.9611\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 120.3836 - mean_squared_error: 111.1973 - val_loss: 33.1929 - val_mean_squared_error: 24.1159\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 15us/step - loss: 32.3939 - mean_squared_error: 23.3168 - val_loss: 11.5497 - val_mean_squared_error: 2.5679\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 11.3337 - mean_squared_error: 2.3519 - val_loss: 57.5006 - val_mean_squared_error: 48.5952\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 54.7166 - mean_squared_error: 45.8112 - val_loss: 108.6158 - val_mean_squared_error: 99.7762\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 103.1876 - mean_squared_error: 94.3480 - val_loss: 112.7942 - val_mean_squared_error: 104.0129\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 107.1564 - mean_squared_error: 98.3751 - val_loss: 72.6244 - val_mean_squared_error: 63.8924\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 69.0544 - mean_squared_error: 60.3224 - val_loss: 26.2498 - val_mean_squared_error: 17.5555\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 25.1458 - mean_squared_error: 16.4515 - val_loss: 8.8643 - val_mean_squared_error: 0.1967\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.8791 - mean_squared_error: 0.2116 - val_loss: 25.9750 - val_mean_squared_error: 17.3308\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 25.4316 - mean_squared_error: 16.7873 - val_loss: 53.2951 - val_mean_squared_error: 44.6774\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 51.6142 - mean_squared_error: 42.9966 - val_loss: 62.0211 - val_mean_squared_error: 53.4413\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 59.9607 - mean_squared_error: 51.3809 - val_loss: 45.6713 - val_mean_squared_error: 37.1429\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 44.3034 - mean_squared_error: 35.7750 - val_loss: 21.1448 - val_mean_squared_error: 12.6746\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 20.7745 - mean_squared_error: 12.3043 - val_loss: 8.7011 - val_mean_squared_error: 0.2893\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 8.7202 - mean_squared_error: 0.3085 - val_loss: 14.9725 - val_mean_squared_error: 6.6135\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 14.5111 - mean_squared_error: 6.1521 - val_loss: 29.9511 - val_mean_squared_error: 21.6378\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 28.6546 - mean_squared_error: 20.3413 - val_loss: 37.8452 - val_mean_squared_error: 29.5700\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 36.1334 - mean_squared_error: 27.8582 - val_loss: 31.9123 - val_mean_squared_error: 23.6677\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 30.5220 - mean_squared_error: 22.2774 - val_loss: 18.4667 - val_mean_squared_error: 10.2454\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 17.8130 - mean_squared_error: 9.5916 - val_loss: 9.0890 - val_mean_squared_error: 0.8861\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.0072 - mean_squared_error: 0.8042 - val_loss: 10.3436 - val_mean_squared_error: 2.1571\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 10.3217 - mean_squared_error: 2.1352 - val_loss: 18.2674 - val_mean_squared_error: 10.0996\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 17.9527 - mean_squared_error: 9.7849 - val_loss: 23.5384 - val_mean_squared_error: 15.3955\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 23.0037 - mean_squared_error: 14.8608 - val_loss: 21.0607 - val_mean_squared_error: 12.9516\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 20.6200 - mean_squared_error: 12.5109 - val_loss: 13.7915 - val_mean_squared_error: 5.7230\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 13.6327 - mean_squared_error: 5.5642 - val_loss: 8.5372 - val_mean_squared_error: 0.5129\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 8.5463 - mean_squared_error: 0.5220 - val_loss: 9.2907 - val_mean_squared_error: 1.3096\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.1893 - mean_squared_error: 1.2082 - val_loss: 13.7046 - val_mean_squared_error: 5.7619\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 13.3439 - mean_squared_error: 5.4013 - val_loss: 16.6031 - val_mean_squared_error: 8.6935\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 16.0870 - mean_squared_error: 8.1773 - val_loss: 15.1501 - val_mean_squared_error: 7.2675\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 10us/step - loss: 14.7151 - mean_squared_error: 6.8325 - val_loss: 11.0273 - val_mean_squared_error: 3.1666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 10.8222 - mean_squared_error: 2.9614 - val_loss: 8.1307 - val_mean_squared_error: 0.2887\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 8.1077 - mean_squared_error: 0.2657 - val_loss: 8.6486 - val_mean_squared_error: 0.8239\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.6423 - mean_squared_error: 0.8176 - val_loss: 11.1454 - val_mean_squared_error: 3.3404\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 11.0481 - mean_squared_error: 3.2431 - val_loss: 12.5262 - val_mean_squared_error: 4.7453\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 12.3706 - mean_squared_error: 4.5898 - val_loss: 11.3417 - val_mean_squared_error: 3.5899\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 11.2297 - mean_squared_error: 3.4779 - val_loss: 8.9908 - val_mean_squared_error: 1.2715\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 8.9647 - mean_squared_error: 1.2454 - val_loss: 7.7798 - val_mean_squared_error: 0.0939\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 7.7821 - mean_squared_error: 0.0962 - val_loss: 8.5132 - val_mean_squared_error: 0.8599\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 9.2918 - mean_squared_error: 2.3136 - val_loss: 54.5766 - val_mean_squared_error: 47.4165\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 51.1619 - mean_squared_error: 44.0019 - val_loss: 9.1146 - val_mean_squared_error: 2.2506\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 9.2773 - mean_squared_error: 2.4133 - val_loss: 33.6427 - val_mean_squared_error: 26.9872\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 34.0065 - mean_squared_error: 27.3510 - val_loss: 34.1108 - val_mean_squared_error: 27.6006\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 34.5076 - mean_squared_error: 27.9974 - val_loss: 14.7872 - val_mean_squared_error: 8.3208\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 15.5109 - mean_squared_error: 9.0445 - val_loss: 9.2207 - val_mean_squared_error: 2.7162\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 9.3004 - mean_squared_error: 2.7959 - val_loss: 21.1604 - val_mean_squared_error: 14.6552\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 20.0283 - mean_squared_error: 13.5231 - val_loss: 20.6807 - val_mean_squared_error: 14.2881\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 19.6049 - mean_squared_error: 13.2123 - val_loss: 11.2355 - val_mean_squared_error: 5.0009\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 11.0212 - mean_squared_error: 4.7865 - val_loss: 7.7511 - val_mean_squared_error: 1.6522\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 8.1821 - mean_squared_error: 2.0832 - val_loss: 11.1736 - val_mean_squared_error: 5.1726\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 11.7852 - mean_squared_error: 5.7843 - val_loss: 13.4368 - val_mean_squared_error: 7.5005\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 14.0397 - mean_squared_error: 8.1034 - val_loss: 11.1199 - val_mean_squared_error: 5.2226\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 11.6990 - mean_squared_error: 5.8016 - val_loss: 7.8751 - val_mean_squared_error: 1.9964\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 8.3393 - mean_squared_error: 2.4606 - val_loss: 7.6881 - val_mean_squared_error: 1.8192\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 7.8758 - mean_squared_error: 2.0068 - val_loss: 10.0451 - val_mean_squared_error: 4.1931\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 9.9187 - mean_squared_error: 4.0667 - val_loss: 11.3043 - val_mean_squared_error: 5.4908\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 11.0527 - mean_squared_error: 5.2391 - val_loss: 9.8316 - val_mean_squared_error: 4.0816\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.7161 - mean_squared_error: 3.9661 - val_loss: 7.5792 - val_mean_squared_error: 1.9102\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.7216 - mean_squared_error: 2.0526 - val_loss: 6.9669 - val_mean_squared_error: 1.3799\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 7.3125 - mean_squared_error: 1.7256 - val_loss: 8.0213 - val_mean_squared_error: 2.5059\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 8.4498 - mean_squared_error: 2.9344 - val_loss: 8.7738 - val_mean_squared_error: 3.3138\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 9.2087 - mean_squared_error: 3.7487 - val_loss: 8.0996 - val_mean_squared_error: 2.6780\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 8.5115 - mean_squared_error: 3.0899 - val_loss: 6.9140 - val_mean_squared_error: 1.5160\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 7.2635 - mean_squared_error: 1.8655 - val_loss: 6.6326 - val_mean_squared_error: 1.2506\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 6.8614 - mean_squared_error: 1.4794 - val_loss: 7.3562 - val_mean_squared_error: 1.9924\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 7.4517 - mean_squared_error: 2.0879 - val_loss: 7.8959 - val_mean_squared_error: 2.5648\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 7.9243 - mean_squared_error: 2.5932 - val_loss: 7.4683 - val_mean_squared_error: 2.1908\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 7.5341 - mean_squared_error: 2.2566 - val_loss: 6.5918 - val_mean_squared_error: 1.3836\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.7580 - mean_squared_error: 1.5498 - val_loss: 6.2232 - val_mean_squared_error: 1.0899\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 6.4787 - mean_squared_error: 1.3454 - val_loss: 6.4928 - val_mean_squared_error: 1.4304\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 6.7915 - mean_squared_error: 1.7290 - val_loss: 6.7511 - val_mean_squared_error: 1.7468\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.0558 - mean_squared_error: 2.0515 - val_loss: 6.5236 - val_mean_squared_error: 1.5598\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 6.8148 - mean_squared_error: 1.8510 - val_loss: 6.0705 - val_mean_squared_error: 1.1326\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 6.3294 - mean_squared_error: 1.3915 - val_loss: 5.9219 - val_mean_squared_error: 1.0035\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 6.1271 - mean_squared_error: 1.2088 - val_loss: 6.1504 - val_mean_squared_error: 1.2540\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.2989 - mean_squared_error: 1.4025 - val_loss: 6.3119 - val_mean_squared_error: 1.4489\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 6.4327 - mean_squared_error: 1.5697 - val_loss: 6.1125 - val_mean_squared_error: 1.2969\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 6.2478 - mean_squared_error: 1.4322 - val_loss: 5.7623 - val_mean_squared_error: 1.0035\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.9360 - mean_squared_error: 1.1771 - val_loss: 5.6123 - val_mean_squared_error: 0.9153\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 5.8190 - mean_squared_error: 1.1220 - val_loss: 5.6954 - val_mean_squared_error: 1.0564\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 5.9159 - mean_squared_error: 1.2769 - val_loss: 5.7441 - val_mean_squared_error: 1.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 5.9634 - mean_squared_error: 1.3706 - val_loss: 5.6003 - val_mean_squared_error: 1.0424\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.8105 - mean_squared_error: 1.2526 - val_loss: 5.4077 - val_mean_squared_error: 0.8758\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 5.6014 - mean_squared_error: 1.0694 - val_loss: 5.3611 - val_mean_squared_error: 0.8517\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 5.5316 - mean_squared_error: 1.0222 - val_loss: 5.4298 - val_mean_squared_error: 0.9479\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 48us/step - loss: 5.5790 - mean_squared_error: 1.0971 - val_loss: 5.4257 - val_mean_squared_error: 0.9804\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 5.5674 - mean_squared_error: 1.1222 - val_loss: 5.2841 - val_mean_squared_error: 0.8859\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.4334 - mean_squared_error: 1.0353 - val_loss: 5.1329 - val_mean_squared_error: 0.7876\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.2946 - mean_squared_error: 0.9494 - val_loss: 5.0874 - val_mean_squared_error: 0.7951\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 8.4544 - mean_squared_error: 1.5443 - val_loss: 111.0220 - val_mean_squared_error: 103.9198\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 105.2681 - mean_squared_error: 98.1658 - val_loss: 7.2074 - val_mean_squared_error: 0.3323\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 7.2603 - mean_squared_error: 0.3852 - val_loss: 64.9930 - val_mean_squared_error: 58.2543\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 62.9935 - mean_squared_error: 56.2547 - val_loss: 60.5708 - val_mean_squared_error: 53.9469\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 58.8186 - mean_squared_error: 52.1948 - val_loss: 16.8773 - val_mean_squared_error: 10.3211\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 16.8105 - mean_squared_error: 10.2543 - val_loss: 9.8036 - val_mean_squared_error: 3.2631\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 9.5494 - mean_squared_error: 3.0089 - val_loss: 33.6632 - val_mean_squared_error: 27.1438\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 31.8583 - mean_squared_error: 25.3389 - val_loss: 39.8744 - val_mean_squared_error: 33.4360\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 37.6812 - mean_squared_error: 31.2429 - val_loss: 22.6214 - val_mean_squared_error: 16.3142\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 21.4465 - mean_squared_error: 15.1393 - val_loss: 7.7210 - val_mean_squared_error: 1.5614\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 7.6212 - mean_squared_error: 1.4616 - val_loss: 10.0146 - val_mean_squared_error: 3.9908\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 10.2013 - mean_squared_error: 4.1776 - val_loss: 20.4759 - val_mean_squared_error: 14.5676\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 20.4378 - mean_squared_error: 14.5294 - val_loss: 22.9559 - val_mean_squared_error: 17.1423\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 22.8613 - mean_squared_error: 17.0477 - val_loss: 15.6568 - val_mean_squared_error: 9.9168\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 15.7696 - mean_squared_error: 10.0296 - val_loss: 7.7246 - val_mean_squared_error: 2.0393\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 7.9461 - mean_squared_error: 2.2608 - val_loss: 6.7156 - val_mean_squared_error: 1.0720\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 6.6908 - mean_squared_error: 1.0473 - val_loss: 11.4735 - val_mean_squared_error: 5.8728\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 10.9861 - mean_squared_error: 5.3854 - val_loss: 15.2189 - val_mean_squared_error: 9.6731\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 14.4437 - mean_squared_error: 8.8979 - val_loss: 13.8495 - val_mean_squared_error: 8.3775\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 13.1691 - mean_squared_error: 7.6971 - val_loss: 9.2584 - val_mean_squared_error: 3.8740\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 8.9429 - mean_squared_error: 3.5585 - val_loss: 6.0614 - val_mean_squared_error: 0.7697\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 47us/step - loss: 6.1080 - mean_squared_error: 0.8164 - val_loss: 6.5399 - val_mean_squared_error: 1.3355\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 6.7731 - mean_squared_error: 1.5687 - val_loss: 9.0199 - val_mean_squared_error: 3.8927\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 9.2851 - mean_squared_error: 4.1580 - val_loss: 10.2128 - val_mean_squared_error: 5.1494\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 10.4695 - mean_squared_error: 5.4062 - val_loss: 8.8861 - val_mean_squared_error: 3.8743\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 9.1497 - mean_squared_error: 4.1379 - val_loss: 6.5630 - val_mean_squared_error: 1.5915\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 47us/step - loss: 6.8052 - mean_squared_error: 1.8338 - val_loss: 5.5076 - val_mean_squared_error: 0.5695\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 5.6374 - mean_squared_error: 0.6992 - val_loss: 6.3844 - val_mean_squared_error: 1.4762\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.3307 - mean_squared_error: 1.4225 - val_loss: 7.8405 - val_mean_squared_error: 2.9661\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.6307 - mean_squared_error: 2.7562 - val_loss: 8.1777 - val_mean_squared_error: 3.3475\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.9359 - mean_squared_error: 3.1058 - val_loss: 7.0715 - val_mean_squared_error: 2.2976\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 6.9325 - mean_squared_error: 2.1586 - val_loss: 5.6872 - val_mean_squared_error: 0.9770\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 5.7063 - mean_squared_error: 0.9961 - val_loss: 5.2069 - val_mean_squared_error: 0.5624\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 5.3527 - mean_squared_error: 0.7082 - val_loss: 5.7221 - val_mean_squared_error: 1.1403\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 5.9283 - mean_squared_error: 1.3465 - val_loss: 6.3294 - val_mean_squared_error: 1.8024\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.5478 - mean_squared_error: 2.0209 - val_loss: 6.2280 - val_mean_squared_error: 1.7467\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 6.4407 - mean_squared_error: 1.9594 - val_loss: 5.5302 - val_mean_squared_error: 1.0865\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 51us/step - loss: 5.7233 - mean_squared_error: 1.2796 - val_loss: 4.9662 - val_mean_squared_error: 0.5548\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.1117 - mean_squared_error: 0.7003 - val_loss: 5.0310 - val_mean_squared_error: 0.6494\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.1018 - mean_squared_error: 0.7202 - val_loss: 5.4910 - val_mean_squared_error: 1.1414\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 5.4905 - mean_squared_error: 1.1409 - val_loss: 5.7265 - val_mean_squared_error: 1.4145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.6972 - mean_squared_error: 1.3852 - val_loss: 5.4362 - val_mean_squared_error: 1.1690\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.4338 - mean_squared_error: 1.1667 - val_loss: 4.9112 - val_mean_squared_error: 0.6945\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 47us/step - loss: 4.9683 - mean_squared_error: 0.7516 - val_loss: 4.6338 - val_mean_squared_error: 0.4687\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.7451 - mean_squared_error: 0.5800 - val_loss: 4.7259 - val_mean_squared_error: 0.6111\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.8664 - mean_squared_error: 0.7516 - val_loss: 4.9081 - val_mean_squared_error: 0.8391\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 5.0557 - mean_squared_error: 0.9866 - val_loss: 4.8707 - val_mean_squared_error: 0.8421\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 47us/step - loss: 5.0143 - mean_squared_error: 0.9858 - val_loss: 4.6168 - val_mean_squared_error: 0.6232\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 4.7493 - mean_squared_error: 0.7557 - val_loss: 4.4026 - val_mean_squared_error: 0.4395\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 4.5137 - mean_squared_error: 0.5506 - val_loss: 4.4095 - val_mean_squared_error: 0.4750\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 4s 16ms/step - loss: 6.7853 - mean_squared_error: 0.7110 - val_loss: 19.5725 - val_mean_squared_error: 13.7198\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 19.2977 - mean_squared_error: 13.4450 - val_loss: 6.5535 - val_mean_squared_error: 0.5718\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 6.6607 - mean_squared_error: 0.6790 - val_loss: 15.6863 - val_mean_squared_error: 9.6135\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 15.3051 - mean_squared_error: 9.2324 - val_loss: 13.0319 - val_mean_squared_error: 7.0210\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 12.7842 - mean_squared_error: 6.7732 - val_loss: 6.8988 - val_mean_squared_error: 0.9883\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 6.9717 - mean_squared_error: 1.0612 - val_loss: 8.0116 - val_mean_squared_error: 2.1769\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 8.0968 - mean_squared_error: 2.2621 - val_loss: 11.1527 - val_mean_squared_error: 5.3767\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 11.1298 - mean_squared_error: 5.3539 - val_loss: 9.7763 - val_mean_squared_error: 4.0367\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.7985 - mean_squared_error: 4.0589 - val_loss: 6.8528 - val_mean_squared_error: 1.1322\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 6.9628 - mean_squared_error: 1.2421 - val_loss: 6.4120 - val_mean_squared_error: 0.6999\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.5019 - mean_squared_error: 0.7898 - val_loss: 8.0726 - val_mean_squared_error: 2.3725\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 40us/step - loss: 8.0672 - mean_squared_error: 2.3672 - val_loss: 8.6671 - val_mean_squared_error: 2.9994\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 8.6318 - mean_squared_error: 2.9641 - val_loss: 7.4126 - val_mean_squared_error: 1.7965\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 7.4392 - mean_squared_error: 1.8231 - val_loss: 6.1392 - val_mean_squared_error: 0.5788\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 6.2353 - mean_squared_error: 0.6749 - val_loss: 6.2646 - val_mean_squared_error: 0.7560\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 6.3705 - mean_squared_error: 0.8619 - val_loss: 7.1735 - val_mean_squared_error: 1.7093\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.2488 - mean_squared_error: 1.7845 - val_loss: 7.3849 - val_mean_squared_error: 1.9543\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 7.4488 - mean_squared_error: 2.0183 - val_loss: 6.6220 - val_mean_squared_error: 1.2155\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.7077 - mean_squared_error: 1.3012 - val_loss: 5.8933 - val_mean_squared_error: 0.5045\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.9964 - mean_squared_error: 0.6075 - val_loss: 5.9914 - val_mean_squared_error: 0.6186\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 6.0791 - mean_squared_error: 0.7063 - val_loss: 6.5246 - val_mean_squared_error: 1.1737\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.5833 - mean_squared_error: 1.2324 - val_loss: 6.6023 - val_mean_squared_error: 1.2868\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.6555 - mean_squared_error: 1.3399 - val_loss: 6.0875 - val_mean_squared_error: 0.8199\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.1623 - mean_squared_error: 0.8947 - val_loss: 5.6478 - val_mean_squared_error: 0.4345\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 15us/step - loss: 5.7416 - mean_squared_error: 0.5284 - val_loss: 5.7342 - val_mean_squared_error: 0.5720\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.8241 - mean_squared_error: 0.6619 - val_loss: 6.0303 - val_mean_squared_error: 0.9125\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.1057 - mean_squared_error: 0.9879 - val_loss: 6.0126 - val_mean_squared_error: 0.9315\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 6.0848 - mean_squared_error: 1.0038 - val_loss: 5.6667 - val_mean_squared_error: 0.6159\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 5.7489 - mean_squared_error: 0.6981 - val_loss: 5.4248 - val_mean_squared_error: 0.3998\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.5133 - mean_squared_error: 0.4883 - val_loss: 5.5032 - val_mean_squared_error: 0.5028\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.5862 - mean_squared_error: 0.5857 - val_loss: 5.6583 - val_mean_squared_error: 0.6870\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.7331 - mean_squared_error: 0.7618 - val_loss: 5.5792 - val_mean_squared_error: 0.6461\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 5.6550 - mean_squared_error: 0.7218 - val_loss: 5.3367 - val_mean_squared_error: 0.4491\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 5.4186 - mean_squared_error: 0.5311 - val_loss: 5.2211 - val_mean_squared_error: 0.3799\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.3025 - mean_squared_error: 0.4613 - val_loss: 5.2938 - val_mean_squared_error: 0.4974\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 5.3664 - mean_squared_error: 0.5700 - val_loss: 5.3511 - val_mean_squared_error: 0.5942\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.4165 - mean_squared_error: 0.6597 - val_loss: 5.2440 - val_mean_squared_error: 0.5207\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 5.3113 - mean_squared_error: 0.5879 - val_loss: 5.0807 - val_mean_squared_error: 0.3862\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.1546 - mean_squared_error: 0.4601 - val_loss: 5.0331 - val_mean_squared_error: 0.3645\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 5.1103 - mean_squared_error: 0.4417 - val_loss: 5.0756 - val_mean_squared_error: 0.4345\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 26us/step - loss: 5.1521 - mean_squared_error: 0.5110 - val_loss: 5.0608 - val_mean_squared_error: 0.4532\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.1365 - mean_squared_error: 0.5289 - val_loss: 4.9550 - val_mean_squared_error: 0.3861\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.0304 - mean_squared_error: 0.4615 - val_loss: 4.8685 - val_mean_squared_error: 0.3404\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 4.9403 - mean_squared_error: 0.4122 - val_loss: 4.8676 - val_mean_squared_error: 0.3792\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.9318 - mean_squared_error: 0.4434 - val_loss: 4.8821 - val_mean_squared_error: 0.4296\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 4.9402 - mean_squared_error: 0.4877 - val_loss: 4.8285 - val_mean_squared_error: 0.4089\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.8868 - mean_squared_error: 0.4672 - val_loss: 4.7367 - val_mean_squared_error: 0.3473\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.8001 - mean_squared_error: 0.4107 - val_loss: 4.6869 - val_mean_squared_error: 0.3253\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.7553 - mean_squared_error: 0.3937 - val_loss: 4.6812 - val_mean_squared_error: 0.3472\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7518 - mean_squared_error: 0.4178 - val_loss: 4.6565 - val_mean_squared_error: 0.3531\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 4s 16ms/step - loss: 5.4717 - mean_squared_error: 1.1937 - val_loss: 13.7563 - val_mean_squared_error: 9.5696\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 13.7666 - mean_squared_error: 9.5798 - val_loss: 5.0652 - val_mean_squared_error: 0.8328\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 5.2471 - mean_squared_error: 1.0147 - val_loss: 10.4434 - val_mean_squared_error: 6.1632\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 10.2538 - mean_squared_error: 5.9737 - val_loss: 9.4282 - val_mean_squared_error: 5.1940\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 9.2952 - mean_squared_error: 5.0610 - val_loss: 5.5403 - val_mean_squared_error: 1.3727\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6494 - mean_squared_error: 1.4817 - val_loss: 5.6617 - val_mean_squared_error: 1.5516\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 13us/step - loss: 5.8557 - mean_squared_error: 1.7457 - val_loss: 7.7664 - val_mean_squared_error: 3.7056\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 7.9178 - mean_squared_error: 3.8570 - val_loss: 7.1854 - val_mean_squared_error: 3.1595\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 7.3499 - mean_squared_error: 3.3239 - val_loss: 5.2824 - val_mean_squared_error: 1.2752\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.4754 - mean_squared_error: 1.4683 - val_loss: 4.9220 - val_mean_squared_error: 0.9209\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.0654 - mean_squared_error: 1.0643 - val_loss: 6.0641 - val_mean_squared_error: 2.0724\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 6.1129 - mean_squared_error: 2.1212 - val_loss: 6.3458 - val_mean_squared_error: 2.3871\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.3738 - mean_squared_error: 2.4151 - val_loss: 5.4043 - val_mean_squared_error: 1.4972\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 5.4924 - mean_squared_error: 1.5854 - val_loss: 4.6341 - val_mean_squared_error: 0.7829\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 4.7881 - mean_squared_error: 0.9369 - val_loss: 4.8249 - val_mean_squared_error: 1.0233\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 5.0014 - mean_squared_error: 1.1998 - val_loss: 5.3457 - val_mean_squared_error: 1.5827\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 5.5155 - mean_squared_error: 1.7526 - val_loss: 5.2867 - val_mean_squared_error: 1.5531\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 5.4539 - mean_squared_error: 1.7202 - val_loss: 4.7342 - val_mean_squared_error: 1.0197\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.9027 - mean_squared_error: 1.1882 - val_loss: 4.4199 - val_mean_squared_error: 0.7169\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.5731 - mean_squared_error: 0.8701 - val_loss: 4.6328 - val_mean_squared_error: 0.9414\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.7524 - mean_squared_error: 1.0610 - val_loss: 4.9220 - val_mean_squared_error: 1.2506\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.0161 - mean_squared_error: 1.3447 - val_loss: 4.8044 - val_mean_squared_error: 1.1660\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 4.9031 - mean_squared_error: 1.2647 - val_loss: 4.4203 - val_mean_squared_error: 0.8244\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.5440 - mean_squared_error: 0.9481 - val_loss: 4.2290 - val_mean_squared_error: 0.6776\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 4.3723 - mean_squared_error: 0.8209 - val_loss: 4.3535 - val_mean_squared_error: 0.8419\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.4996 - mean_squared_error: 0.9880 - val_loss: 4.4775 - val_mean_squared_error: 0.9990\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.6190 - mean_squared_error: 1.1405 - val_loss: 4.3532 - val_mean_squared_error: 0.9018\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.4927 - mean_squared_error: 1.0413 - val_loss: 4.1231 - val_mean_squared_error: 0.6936\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 4.2602 - mean_squared_error: 0.8308 - val_loss: 4.0584 - val_mean_squared_error: 0.6465\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.1859 - mean_squared_error: 0.7740 - val_loss: 4.1593 - val_mean_squared_error: 0.7666\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.2735 - mean_squared_error: 0.8808 - val_loss: 4.1950 - val_mean_squared_error: 0.8280\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.3033 - mean_squared_error: 0.9363 - val_loss: 4.0606 - val_mean_squared_error: 0.7267\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.1743 - mean_squared_error: 0.8404 - val_loss: 3.9076 - val_mean_squared_error: 0.6110\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.0289 - mean_squared_error: 0.7323 - val_loss: 3.8877 - val_mean_squared_error: 0.6266\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.0103 - mean_squared_error: 0.7492 - val_loss: 3.9381 - val_mean_squared_error: 0.7090\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 4.0570 - mean_squared_error: 0.8280 - val_loss: 3.9092 - val_mean_squared_error: 0.7093\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 4.0256 - mean_squared_error: 0.8257 - val_loss: 3.7968 - val_mean_squared_error: 0.6215\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.9130 - mean_squared_error: 0.7377 - val_loss: 3.7209 - val_mean_squared_error: 0.5661\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.8356 - mean_squared_error: 0.6808 - val_loss: 3.7297 - val_mean_squared_error: 0.5943\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.8404 - mean_squared_error: 0.7050 - val_loss: 3.7375 - val_mean_squared_error: 0.6261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8451 - mean_squared_error: 0.7337 - val_loss: 3.6753 - val_mean_squared_error: 0.5930\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.7829 - mean_squared_error: 0.7006 - val_loss: 3.5932 - val_mean_squared_error: 0.5430\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.7010 - mean_squared_error: 0.6509 - val_loss: 3.5650 - val_mean_squared_error: 0.5466\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 3.6700 - mean_squared_error: 0.6516 - val_loss: 3.5710 - val_mean_squared_error: 0.5819\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.6714 - mean_squared_error: 0.6823 - val_loss: 3.5430 - val_mean_squared_error: 0.5794\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 3.6410 - mean_squared_error: 0.6774 - val_loss: 3.4777 - val_mean_squared_error: 0.5357\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.5761 - mean_squared_error: 0.6341 - val_loss: 3.4303 - val_mean_squared_error: 0.5078\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.5294 - mean_squared_error: 0.6068 - val_loss: 3.4187 - val_mean_squared_error: 0.5155\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.5172 - mean_squared_error: 0.6140 - val_loss: 3.4010 - val_mean_squared_error: 0.5208\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.4982 - mean_squared_error: 0.6180 - val_loss: 3.3561 - val_mean_squared_error: 0.5017\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 8.4567 - mean_squared_error: 0.8034 - val_loss: 86.2766 - val_mean_squared_error: 78.5597\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 82.8028 - mean_squared_error: 75.0860 - val_loss: 7.7222 - val_mean_squared_error: 0.0883\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 7.7231 - mean_squared_error: 0.0892 - val_loss: 53.1727 - val_mean_squared_error: 45.5965\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 50.8832 - mean_squared_error: 43.3069 - val_loss: 52.5493 - val_mean_squared_error: 45.0101\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 50.2890 - mean_squared_error: 42.7498 - val_loss: 17.2777 - val_mean_squared_error: 9.7518\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 16.7537 - mean_squared_error: 9.2278 - val_loss: 9.8161 - val_mean_squared_error: 2.2853\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 9.7484 - mean_squared_error: 2.2177 - val_loss: 30.0334 - val_mean_squared_error: 22.5050\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 29.0936 - mean_squared_error: 21.5652 - val_loss: 34.7482 - val_mean_squared_error: 27.2506\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 33.6041 - mean_squared_error: 26.1065 - val_loss: 18.9763 - val_mean_squared_error: 11.5294\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 18.5288 - mean_squared_error: 11.0819 - val_loss: 7.6484 - val_mean_squared_error: 0.2589\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 7.6533 - mean_squared_error: 0.2638 - val_loss: 13.2323 - val_mean_squared_error: 5.8960\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 12.8944 - mean_squared_error: 5.5582 - val_loss: 22.8367 - val_mean_squared_error: 15.5467\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 22.0044 - mean_squared_error: 14.7144 - val_loss: 21.5289 - val_mean_squared_error: 14.2758\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 20.7626 - mean_squared_error: 13.5096 - val_loss: 12.3770 - val_mean_squared_error: 5.1503\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 12.0813 - mean_squared_error: 4.8546 - val_loss: 7.3013 - val_mean_squared_error: 0.0936\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.3008 - mean_squared_error: 0.0931 - val_loss: 10.8191 - val_mean_squared_error: 3.6294\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 10.7041 - mean_squared_error: 3.5143 - val_loss: 15.9594 - val_mean_squared_error: 8.7941\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 15.6291 - mean_squared_error: 8.4638 - val_loss: 15.1943 - val_mean_squared_error: 8.0635\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 14.8941 - mean_squared_error: 7.7634 - val_loss: 9.9975 - val_mean_squared_error: 2.9096\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 9.9093 - mean_squared_error: 2.8214 - val_loss: 7.1285 - val_mean_squared_error: 0.0864\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 7.1316 - mean_squared_error: 0.0895 - val_loss: 9.2466 - val_mean_squared_error: 2.2480\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 9.1126 - mean_squared_error: 2.1140 - val_loss: 12.3187 - val_mean_squared_error: 5.3564\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 12.0210 - mean_squared_error: 5.0587 - val_loss: 11.9690 - val_mean_squared_error: 5.0349\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 7us/step - loss: 11.6891 - mean_squared_error: 4.7550 - val_loss: 8.8771 - val_mean_squared_error: 1.9636\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.7609 - mean_squared_error: 1.8474 - val_loss: 6.9925 - val_mean_squared_error: 0.0945\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.9921 - mean_squared_error: 0.0941 - val_loss: 8.1286 - val_mean_squared_error: 1.2459\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.1001 - mean_squared_error: 1.2173 - val_loss: 10.0005 - val_mean_squared_error: 3.1368\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 9.8974 - mean_squared_error: 3.0337 - val_loss: 9.7881 - val_mean_squared_error: 2.9495\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.6919 - mean_squared_error: 2.8533 - val_loss: 7.8919 - val_mean_squared_error: 1.0846\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 7.8680 - mean_squared_error: 1.0607 - val_loss: 6.8544 - val_mean_squared_error: 0.0819\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 6.8566 - mean_squared_error: 0.0841 - val_loss: 7.6978 - val_mean_squared_error: 0.9590\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 7.6415 - mean_squared_error: 0.9027 - val_loss: 8.7895 - val_mean_squared_error: 2.0810\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 9us/step - loss: 8.6725 - mean_squared_error: 1.9640 - val_loss: 8.4730 - val_mean_squared_error: 1.7899\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 8.3723 - mean_squared_error: 1.6891 - val_loss: 7.2468 - val_mean_squared_error: 0.5841\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 7.2134 - mean_squared_error: 0.5507 - val_loss: 6.7353 - val_mean_squared_error: 0.0910\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 6.7393 - mean_squared_error: 0.0950 - val_loss: 7.3609 - val_mean_squared_error: 0.7360\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 7.3469 - mean_squared_error: 0.7219 - val_loss: 7.9152 - val_mean_squared_error: 1.3127\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.8791 - mean_squared_error: 1.2765 - val_loss: 7.5116 - val_mean_squared_error: 0.9364\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 7.4896 - mean_squared_error: 0.9143 - val_loss: 6.7625 - val_mean_squared_error: 0.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.7648 - mean_squared_error: 0.2203 - val_loss: 6.6732 - val_mean_squared_error: 0.1599\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 6.6677 - mean_squared_error: 0.1545 - val_loss: 7.1659 - val_mean_squared_error: 0.6821\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 7.1289 - mean_squared_error: 0.6451 - val_loss: 7.3435 - val_mean_squared_error: 0.8851\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 7.2955 - mean_squared_error: 0.8371 - val_loss: 6.9169 - val_mean_squared_error: 0.4809\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 6.8917 - mean_squared_error: 0.4558 - val_loss: 6.5095 - val_mean_squared_error: 0.0938\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.5097 - mean_squared_error: 0.0940 - val_loss: 6.6147 - val_mean_squared_error: 0.2191\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.6163 - mean_squared_error: 0.2207 - val_loss: 6.8999 - val_mean_squared_error: 0.5265\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 6.8913 - mean_squared_error: 0.5178 - val_loss: 6.8300 - val_mean_squared_error: 0.4817\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.8229 - mean_squared_error: 0.4746 - val_loss: 6.4979 - val_mean_squared_error: 0.1771\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 6.5004 - mean_squared_error: 0.1797 - val_loss: 6.3814 - val_mean_squared_error: 0.0895\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.3821 - mean_squared_error: 0.0902 - val_loss: 6.5601 - val_mean_squared_error: 0.2959\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 16ms/step - loss: 5.2561 - mean_squared_error: 0.9638 - val_loss: 18.6977 - val_mean_squared_error: 14.2192\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 18.1760 - mean_squared_error: 13.6976 - val_loss: 6.5386 - val_mean_squared_error: 2.1831\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 6.6012 - mean_squared_error: 2.2458 - val_loss: 7.8594 - val_mean_squared_error: 3.5991\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 50us/step - loss: 7.9611 - mean_squared_error: 3.7008 - val_loss: 12.7619 - val_mean_squared_error: 8.5537\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 12.7062 - mean_squared_error: 8.4980 - val_loss: 10.4281 - val_mean_squared_error: 6.2401\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 10.4623 - mean_squared_error: 6.2743 - val_loss: 6.1410 - val_mean_squared_error: 1.9348\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 51us/step - loss: 6.3059 - mean_squared_error: 2.0996 - val_loss: 5.2436 - val_mean_squared_error: 0.9859\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 44us/step - loss: 5.3753 - mean_squared_error: 1.1176 - val_loss: 7.7659 - val_mean_squared_error: 3.4633\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.7332 - mean_squared_error: 3.4307 - val_loss: 8.6565 - val_mean_squared_error: 4.3587\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.5744 - mean_squared_error: 4.2766 - val_loss: 7.0489 - val_mean_squared_error: 2.7963\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 12us/step - loss: 7.0570 - mean_squared_error: 2.8044 - val_loss: 5.2599 - val_mean_squared_error: 1.0775\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.3822 - mean_squared_error: 1.1999 - val_loss: 4.9968 - val_mean_squared_error: 0.8863\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 5.1676 - mean_squared_error: 1.0571 - val_loss: 5.9152 - val_mean_squared_error: 1.8638\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.0722 - mean_squared_error: 2.0208 - val_loss: 6.6212 - val_mean_squared_error: 2.6098\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 6.7564 - mean_squared_error: 2.7449 - val_loss: 6.3408 - val_mean_squared_error: 2.3493\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 6.4796 - mean_squared_error: 2.4881 - val_loss: 5.4463 - val_mean_squared_error: 1.4575\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 11us/step - loss: 5.6036 - mean_squared_error: 1.6148 - val_loss: 4.7938 - val_mean_squared_error: 0.7951\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 15us/step - loss: 4.9538 - mean_squared_error: 0.9551 - val_loss: 4.8740 - val_mean_squared_error: 0.8626\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 5.0078 - mean_squared_error: 0.9964 - val_loss: 5.3969 - val_mean_squared_error: 1.3815\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.4930 - mean_squared_error: 1.4776 - val_loss: 5.6987 - val_mean_squared_error: 1.6948\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.7756 - mean_squared_error: 1.7718 - val_loss: 5.4553 - val_mean_squared_error: 1.4793\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.5447 - mean_squared_error: 1.5687 - val_loss: 4.9317 - val_mean_squared_error: 0.9966\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 5.0507 - mean_squared_error: 1.1155 - val_loss: 4.6003 - val_mean_squared_error: 0.7127\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.7423 - mean_squared_error: 0.8548 - val_loss: 4.6597 - val_mean_squared_error: 0.8189\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 4.8065 - mean_squared_error: 0.9657 - val_loss: 4.9115 - val_mean_squared_error: 1.1085\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 5.0512 - mean_squared_error: 1.2482 - val_loss: 5.0200 - val_mean_squared_error: 1.2433\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1537 - mean_squared_error: 1.3770 - val_loss: 4.8554 - val_mean_squared_error: 1.0948\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.9902 - mean_squared_error: 1.2295 - val_loss: 4.5758 - val_mean_squared_error: 0.8223\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.7133 - mean_squared_error: 0.9598 - val_loss: 4.4209 - val_mean_squared_error: 0.6684\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 4.5560 - mean_squared_error: 0.8036 - val_loss: 4.4823 - val_mean_squared_error: 0.7298\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.6072 - mean_squared_error: 0.8546 - val_loss: 4.6286 - val_mean_squared_error: 0.8803\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7415 - mean_squared_error: 0.9932 - val_loss: 4.6547 - val_mean_squared_error: 0.9199\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7634 - mean_squared_error: 1.0285 - val_loss: 4.5086 - val_mean_squared_error: 0.7986\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 4.6228 - mean_squared_error: 0.9128 - val_loss: 4.3327 - val_mean_squared_error: 0.6554\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.4549 - mean_squared_error: 0.7776 - val_loss: 4.2748 - val_mean_squared_error: 0.6308\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.3997 - mean_squared_error: 0.7557 - val_loss: 4.3310 - val_mean_squared_error: 0.7172\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.4524 - mean_squared_error: 0.8386 - val_loss: 4.3792 - val_mean_squared_error: 0.7898\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4960 - mean_squared_error: 0.9065 - val_loss: 4.3285 - val_mean_squared_error: 0.7554\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 4.4437 - mean_squared_error: 0.8706 - val_loss: 4.2161 - val_mean_squared_error: 0.6525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.3319 - mean_squared_error: 0.7683 - val_loss: 4.1430 - val_mean_squared_error: 0.5843\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.2578 - mean_squared_error: 0.6991 - val_loss: 4.1520 - val_mean_squared_error: 0.5989\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 4.2628 - mean_squared_error: 0.7096 - val_loss: 4.1854 - val_mean_squared_error: 0.6425\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.2915 - mean_squared_error: 0.7487 - val_loss: 4.1640 - val_mean_squared_error: 0.6384\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 4.2683 - mean_squared_error: 0.7427 - val_loss: 4.0871 - val_mean_squared_error: 0.5845\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.1921 - mean_squared_error: 0.6895 - val_loss: 4.0203 - val_mean_squared_error: 0.5452\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 4.1253 - mean_squared_error: 0.6502 - val_loss: 4.0077 - val_mean_squared_error: 0.5591\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.1101 - mean_squared_error: 0.6615 - val_loss: 4.0185 - val_mean_squared_error: 0.5929\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.1169 - mean_squared_error: 0.6913 - val_loss: 3.9989 - val_mean_squared_error: 0.5908\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.0948 - mean_squared_error: 0.6867 - val_loss: 3.9412 - val_mean_squared_error: 0.5463\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.0362 - mean_squared_error: 0.6414 - val_loss: 3.8889 - val_mean_squared_error: 0.5028\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 16ms/step - loss: 4.4905 - mean_squared_error: 0.5560 - val_loss: 16.8442 - val_mean_squared_error: 13.0605\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 16.6976 - mean_squared_error: 12.9139 - val_loss: 4.3501 - val_mean_squared_error: 0.5098\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.4734 - mean_squared_error: 0.6332 - val_loss: 11.3466 - val_mean_squared_error: 7.4248\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 10.8941 - mean_squared_error: 6.9723 - val_loss: 12.4879 - val_mean_squared_error: 8.5884\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 11.9638 - mean_squared_error: 8.0643 - val_loss: 6.2265 - val_mean_squared_error: 2.3993\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.1159 - mean_squared_error: 2.2888 - val_loss: 4.4654 - val_mean_squared_error: 0.6980\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.6040 - mean_squared_error: 0.8366 - val_loss: 7.6992 - val_mean_squared_error: 3.9766\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 7.8094 - mean_squared_error: 4.0868 - val_loss: 8.3753 - val_mean_squared_error: 4.6904\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 8.4699 - mean_squared_error: 4.7850 - val_loss: 5.8715 - val_mean_squared_error: 2.2136\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 6.0160 - mean_squared_error: 2.3582 - val_loss: 4.1061 - val_mean_squared_error: 0.4633\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.2291 - mean_squared_error: 0.5864 - val_loss: 4.9151 - val_mean_squared_error: 1.2825\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.9049 - mean_squared_error: 1.2723 - val_loss: 6.4173 - val_mean_squared_error: 2.8016\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 6.2854 - mean_squared_error: 2.6698 - val_loss: 6.2922 - val_mean_squared_error: 2.7099\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 6.1704 - mean_squared_error: 2.5881 - val_loss: 4.8698 - val_mean_squared_error: 1.3319\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 4.8602 - mean_squared_error: 1.3224 - val_loss: 3.9397 - val_mean_squared_error: 0.4459\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 4.0395 - mean_squared_error: 0.5457 - val_loss: 4.3062 - val_mean_squared_error: 0.8515\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.4480 - mean_squared_error: 0.9933 - val_loss: 5.0799 - val_mean_squared_error: 1.6580\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 5.2171 - mean_squared_error: 1.7953 - val_loss: 5.0841 - val_mean_squared_error: 1.6899\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.2174 - mean_squared_error: 1.8231 - val_loss: 4.3411 - val_mean_squared_error: 0.9694\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.4762 - mean_squared_error: 1.1044 - val_loss: 3.7814 - val_mean_squared_error: 0.4272\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.8964 - mean_squared_error: 0.5422 - val_loss: 3.9682 - val_mean_squared_error: 0.6285\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.0320 - mean_squared_error: 0.6924 - val_loss: 4.4779 - val_mean_squared_error: 1.1562\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 4.4925 - mean_squared_error: 1.1708 - val_loss: 4.5396 - val_mean_squared_error: 1.2433\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.5484 - mean_squared_error: 1.2522 - val_loss: 4.0663 - val_mean_squared_error: 0.8041\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.1119 - mean_squared_error: 0.8497 - val_loss: 3.6307 - val_mean_squared_error: 0.4054\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.7183 - mean_squared_error: 0.4929 - val_loss: 3.6560 - val_mean_squared_error: 0.4667\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.7609 - mean_squared_error: 0.5717 - val_loss: 3.9285 - val_mean_squared_error: 0.7712\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.0291 - mean_squared_error: 0.8718 - val_loss: 3.9712 - val_mean_squared_error: 0.8412\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.0660 - mean_squared_error: 0.9360 - val_loss: 3.6915 - val_mean_squared_error: 0.5832\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 3.7860 - mean_squared_error: 0.6777 - val_loss: 3.4434 - val_mean_squared_error: 0.3504\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.5333 - mean_squared_error: 0.4403 - val_loss: 3.4827 - val_mean_squared_error: 0.4021\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 45us/step - loss: 3.5575 - mean_squared_error: 0.4770 - val_loss: 3.6511 - val_mean_squared_error: 0.5867\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.7105 - mean_squared_error: 0.6462 - val_loss: 3.6410 - val_mean_squared_error: 0.6002\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.6989 - mean_squared_error: 0.6581 - val_loss: 3.4339 - val_mean_squared_error: 0.4215\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.5021 - mean_squared_error: 0.4897 - val_loss: 3.2806 - val_mean_squared_error: 0.2995\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 43us/step - loss: 3.3562 - mean_squared_error: 0.3750 - val_loss: 3.3218 - val_mean_squared_error: 0.3699\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.3937 - mean_squared_error: 0.4418 - val_loss: 3.4068 - val_mean_squared_error: 0.4814\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.4714 - mean_squared_error: 0.5459 - val_loss: 3.3504 - val_mean_squared_error: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 3.4129 - mean_squared_error: 0.5108 - val_loss: 3.2001 - val_mean_squared_error: 0.3178\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 12us/step - loss: 3.2656 - mean_squared_error: 0.3832 - val_loss: 3.1333 - val_mean_squared_error: 0.2668\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.1995 - mean_squared_error: 0.3329 - val_loss: 3.1781 - val_mean_squared_error: 0.3269\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.2408 - mean_squared_error: 0.3896 - val_loss: 3.1952 - val_mean_squared_error: 0.3629\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.2554 - mean_squared_error: 0.4232 - val_loss: 3.1124 - val_mean_squared_error: 0.3031\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.1730 - mean_squared_error: 0.3637 - val_loss: 3.0239 - val_mean_squared_error: 0.2396\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.0830 - mean_squared_error: 0.2987 - val_loss: 3.0205 - val_mean_squared_error: 0.2612\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.0732 - mean_squared_error: 0.3139 - val_loss: 3.0477 - val_mean_squared_error: 0.3117\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.0937 - mean_squared_error: 0.3578 - val_loss: 3.0096 - val_mean_squared_error: 0.2955\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.0543 - mean_squared_error: 0.3402 - val_loss: 2.9275 - val_mean_squared_error: 0.2323\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 41us/step - loss: 2.9758 - mean_squared_error: 0.2806 - val_loss: 2.8879 - val_mean_squared_error: 0.2093\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 2.9395 - mean_squared_error: 0.2608 - val_loss: 2.8952 - val_mean_squared_error: 0.2327\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 4.7269 - mean_squared_error: 0.4235 - val_loss: 5.2334 - val_mean_squared_error: 0.9621\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 5.2512 - mean_squared_error: 0.9798 - val_loss: 4.6687 - val_mean_squared_error: 0.3929\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 4.7236 - mean_squared_error: 0.4477 - val_loss: 4.6851 - val_mean_squared_error: 0.4030\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.7566 - mean_squared_error: 0.4744 - val_loss: 4.8579 - val_mean_squared_error: 0.5835\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 42us/step - loss: 4.9292 - mean_squared_error: 0.6548 - val_loss: 4.7259 - val_mean_squared_error: 0.4714\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 15us/step - loss: 4.7977 - mean_squared_error: 0.5432 - val_loss: 4.5593 - val_mean_squared_error: 0.3265\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.6274 - mean_squared_error: 0.3946 - val_loss: 4.5619 - val_mean_squared_error: 0.3490\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.6188 - mean_squared_error: 0.4060 - val_loss: 4.6606 - val_mean_squared_error: 0.4665\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 4.7061 - mean_squared_error: 0.5120 - val_loss: 4.6659 - val_mean_squared_error: 0.4882\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 4.7092 - mean_squared_error: 0.5315 - val_loss: 4.5637 - val_mean_squared_error: 0.3998\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 4.6141 - mean_squared_error: 0.4501 - val_loss: 4.4717 - val_mean_squared_error: 0.3179\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.5317 - mean_squared_error: 0.3780 - val_loss: 4.4642 - val_mean_squared_error: 0.3190\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.5310 - mean_squared_error: 0.3858 - val_loss: 4.4980 - val_mean_squared_error: 0.3638\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.5674 - mean_squared_error: 0.4332 - val_loss: 4.4908 - val_mean_squared_error: 0.3721\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 15us/step - loss: 4.5604 - mean_squared_error: 0.4417 - val_loss: 4.4333 - val_mean_squared_error: 0.3344\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.5008 - mean_squared_error: 0.4020 - val_loss: 4.3810 - val_mean_squared_error: 0.3042\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.4437 - mean_squared_error: 0.3669 - val_loss: 4.3747 - val_mean_squared_error: 0.3195\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.4302 - mean_squared_error: 0.3750 - val_loss: 4.3934 - val_mean_squared_error: 0.3585\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 44us/step - loss: 4.4424 - mean_squared_error: 0.4074 - val_loss: 4.3879 - val_mean_squared_error: 0.3707\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4346 - mean_squared_error: 0.4174 - val_loss: 4.3447 - val_mean_squared_error: 0.3434\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.3941 - mean_squared_error: 0.3927 - val_loss: 4.2952 - val_mean_squared_error: 0.3082\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 41us/step - loss: 4.3500 - mean_squared_error: 0.3629 - val_loss: 4.2710 - val_mean_squared_error: 0.2972\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 4.3309 - mean_squared_error: 0.3571 - val_loss: 4.2668 - val_mean_squared_error: 0.3073\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 4.3298 - mean_squared_error: 0.3703 - val_loss: 4.2555 - val_mean_squared_error: 0.3126\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.3191 - mean_squared_error: 0.3763 - val_loss: 4.2266 - val_mean_squared_error: 0.3027\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 4.2884 - mean_squared_error: 0.3645 - val_loss: 4.1959 - val_mean_squared_error: 0.2925\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.2536 - mean_squared_error: 0.3502 - val_loss: 4.1812 - val_mean_squared_error: 0.2979\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 4.2334 - mean_squared_error: 0.3502 - val_loss: 4.1773 - val_mean_squared_error: 0.3133\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.2247 - mean_squared_error: 0.3607 - val_loss: 4.1649 - val_mean_squared_error: 0.3194\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 4.2102 - mean_squared_error: 0.3648 - val_loss: 4.1369 - val_mean_squared_error: 0.3089\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.1835 - mean_squared_error: 0.3556 - val_loss: 4.1046 - val_mean_squared_error: 0.2931\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.1547 - mean_squared_error: 0.3432 - val_loss: 4.0813 - val_mean_squared_error: 0.2855\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.1350 - mean_squared_error: 0.3392 - val_loss: 4.0656 - val_mean_squared_error: 0.2862\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.1216 - mean_squared_error: 0.3422 - val_loss: 4.0473 - val_mean_squared_error: 0.2863\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.1034 - mean_squared_error: 0.3425 - val_loss: 4.0242 - val_mean_squared_error: 0.2831\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.0782 - mean_squared_error: 0.3371 - val_loss: 4.0030 - val_mean_squared_error: 0.2825\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.0531 - mean_squared_error: 0.3327 - val_loss: 3.9884 - val_mean_squared_error: 0.2882\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.0342 - mean_squared_error: 0.3340 - val_loss: 3.9750 - val_mean_squared_error: 0.2946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.0176 - mean_squared_error: 0.3372 - val_loss: 3.9552 - val_mean_squared_error: 0.2941\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.9969 - mean_squared_error: 0.3359 - val_loss: 3.9293 - val_mean_squared_error: 0.2868\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.9725 - mean_squared_error: 0.3301 - val_loss: 3.9044 - val_mean_squared_error: 0.2795\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.9502 - mean_squared_error: 0.3253 - val_loss: 3.8838 - val_mean_squared_error: 0.2763\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.9317 - mean_squared_error: 0.3242 - val_loss: 3.8644 - val_mean_squared_error: 0.2754\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.9130 - mean_squared_error: 0.3239 - val_loss: 3.8442 - val_mean_squared_error: 0.2745\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.8915 - mean_squared_error: 0.3218 - val_loss: 3.8245 - val_mean_squared_error: 0.2749\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.8688 - mean_squared_error: 0.3192 - val_loss: 3.8075 - val_mean_squared_error: 0.2780\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.8483 - mean_squared_error: 0.3188 - val_loss: 3.7914 - val_mean_squared_error: 0.2815\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 16us/step - loss: 3.8294 - mean_squared_error: 0.3195 - val_loss: 3.7720 - val_mean_squared_error: 0.2817\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.8089 - mean_squared_error: 0.3185 - val_loss: 3.7497 - val_mean_squared_error: 0.2778\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.7873 - mean_squared_error: 0.3154 - val_loss: 3.7270 - val_mean_squared_error: 0.2730\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 3.4513 - mean_squared_error: 0.5968 - val_loss: 3.7669 - val_mean_squared_error: 0.9384\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.8337 - mean_squared_error: 1.0052 - val_loss: 3.3523 - val_mean_squared_error: 0.5159\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 3.4424 - mean_squared_error: 0.6060 - val_loss: 3.3979 - val_mean_squared_error: 0.5550\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.4930 - mean_squared_error: 0.6501 - val_loss: 3.5118 - val_mean_squared_error: 0.6752\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.6049 - mean_squared_error: 0.7684 - val_loss: 3.4051 - val_mean_squared_error: 0.5849\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.4993 - mean_squared_error: 0.6790 - val_loss: 3.2858 - val_mean_squared_error: 0.4845\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.3780 - mean_squared_error: 0.5767 - val_loss: 3.2986 - val_mean_squared_error: 0.5145\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.3828 - mean_squared_error: 0.5987 - val_loss: 3.3647 - val_mean_squared_error: 0.5943\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.4410 - mean_squared_error: 0.6706 - val_loss: 3.3551 - val_mean_squared_error: 0.5960\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 3.4300 - mean_squared_error: 0.6709 - val_loss: 3.2763 - val_mean_squared_error: 0.5271\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.3560 - mean_squared_error: 0.6067 - val_loss: 3.2164 - val_mean_squared_error: 0.4748\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.3022 - mean_squared_error: 0.5606 - val_loss: 3.2182 - val_mean_squared_error: 0.4830\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 3.3078 - mean_squared_error: 0.5726 - val_loss: 3.2399 - val_mean_squared_error: 0.5131\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.3306 - mean_squared_error: 0.6038 - val_loss: 3.2263 - val_mean_squared_error: 0.5114\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.3167 - mean_squared_error: 0.6017 - val_loss: 3.1804 - val_mean_squared_error: 0.4808\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.2687 - mean_squared_error: 0.5691 - val_loss: 3.1459 - val_mean_squared_error: 0.4628\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 3.2300 - mean_squared_error: 0.5469 - val_loss: 3.1461 - val_mean_squared_error: 0.4784\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.2246 - mean_squared_error: 0.5568 - val_loss: 3.1572 - val_mean_squared_error: 0.5034\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 3.2311 - mean_squared_error: 0.5773 - val_loss: 3.1457 - val_mean_squared_error: 0.5045\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2183 - mean_squared_error: 0.5772 - val_loss: 3.1105 - val_mean_squared_error: 0.4803\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 3.1853 - mean_squared_error: 0.5550 - val_loss: 3.0773 - val_mean_squared_error: 0.4560\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.1558 - mean_squared_error: 0.5344 - val_loss: 3.0637 - val_mean_squared_error: 0.4506\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.1451 - mean_squared_error: 0.5320 - val_loss: 3.0594 - val_mean_squared_error: 0.4563\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.1423 - mean_squared_error: 0.5392 - val_loss: 3.0460 - val_mean_squared_error: 0.4556\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 3.1284 - mean_squared_error: 0.5381 - val_loss: 3.0222 - val_mean_squared_error: 0.4464\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1022 - mean_squared_error: 0.5264 - val_loss: 3.0019 - val_mean_squared_error: 0.4412\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.0780 - mean_squared_error: 0.5173 - val_loss: 2.9938 - val_mean_squared_error: 0.4475\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.0651 - mean_squared_error: 0.5188 - val_loss: 2.9892 - val_mean_squared_error: 0.4563\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 3.0570 - mean_squared_error: 0.5241 - val_loss: 2.9746 - val_mean_squared_error: 0.4551\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 3.0413 - mean_squared_error: 0.5218 - val_loss: 2.9503 - val_mean_squared_error: 0.4432\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 3.0183 - mean_squared_error: 0.5112 - val_loss: 2.9275 - val_mean_squared_error: 0.4317\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.9980 - mean_squared_error: 0.5021 - val_loss: 2.9122 - val_mean_squared_error: 0.4271\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.9848 - mean_squared_error: 0.4997 - val_loss: 2.8993 - val_mean_squared_error: 0.4262\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 2.9726 - mean_squared_error: 0.4995 - val_loss: 2.8835 - val_mean_squared_error: 0.4236\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 2.9557 - mean_squared_error: 0.4959 - val_loss: 2.8659 - val_mean_squared_error: 0.4204\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.9354 - mean_squared_error: 0.4899 - val_loss: 2.8520 - val_mean_squared_error: 0.4208\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 2.9179 - mean_squared_error: 0.4867 - val_loss: 2.8413 - val_mean_squared_error: 0.4242\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 35us/step - loss: 2.9039 - mean_squared_error: 0.4868 - val_loss: 2.8286 - val_mean_squared_error: 0.4250\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 2.8893 - mean_squared_error: 0.4857 - val_loss: 2.8110 - val_mean_squared_error: 0.4204\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.8716 - mean_squared_error: 0.4809 - val_loss: 2.7912 - val_mean_squared_error: 0.4129\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.8530 - mean_squared_error: 0.4747 - val_loss: 2.7737 - val_mean_squared_error: 0.4073\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.8370 - mean_squared_error: 0.4706 - val_loss: 2.7582 - val_mean_squared_error: 0.4043\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.8221 - mean_squared_error: 0.4682 - val_loss: 2.7427 - val_mean_squared_error: 0.4021\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.8059 - mean_squared_error: 0.4652 - val_loss: 2.7269 - val_mean_squared_error: 0.4003\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.7881 - mean_squared_error: 0.4614 - val_loss: 2.7126 - val_mean_squared_error: 0.4002\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 41us/step - loss: 2.7709 - mean_squared_error: 0.4585 - val_loss: 2.6995 - val_mean_squared_error: 0.4011\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.7552 - mean_squared_error: 0.4569 - val_loss: 2.6851 - val_mean_squared_error: 0.4006\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 2.7393 - mean_squared_error: 0.4547 - val_loss: 2.6682 - val_mean_squared_error: 0.3970\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 2.7222 - mean_squared_error: 0.4510 - val_loss: 2.6507 - val_mean_squared_error: 0.3921\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 2.7053 - mean_squared_error: 0.4467 - val_loss: 2.6338 - val_mean_squared_error: 0.3880\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 6.5468 - mean_squared_error: 0.2826 - val_loss: 8.1299 - val_mean_squared_error: 1.8533\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 8.0687 - mean_squared_error: 1.7921 - val_loss: 6.4332 - val_mean_squared_error: 0.1754\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.4357 - mean_squared_error: 0.1779 - val_loss: 6.9593 - val_mean_squared_error: 0.7221\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 6.9225 - mean_squared_error: 0.6853 - val_loss: 7.3425 - val_mean_squared_error: 1.1224\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.2848 - mean_squared_error: 1.0647 - val_loss: 6.5580 - val_mean_squared_error: 0.3476\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 6.5420 - mean_squared_error: 0.3316 - val_loss: 6.3317 - val_mean_squared_error: 0.1277\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 6.3352 - mean_squared_error: 0.1312 - val_loss: 6.8001 - val_mean_squared_error: 0.6050\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.7881 - mean_squared_error: 0.5930 - val_loss: 6.7986 - val_mean_squared_error: 0.6186\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.7862 - mean_squared_error: 0.6062 - val_loss: 6.3636 - val_mean_squared_error: 0.2024\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 6.3653 - mean_squared_error: 0.2042 - val_loss: 6.2402 - val_mean_squared_error: 0.0989\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 6.2402 - mean_squared_error: 0.0988 - val_loss: 6.4966 - val_mean_squared_error: 0.3747\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 6.4791 - mean_squared_error: 0.3572 - val_loss: 6.5730 - val_mean_squared_error: 0.4683\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 6.5503 - mean_squared_error: 0.4456 - val_loss: 6.3292 - val_mean_squared_error: 0.2391\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 6.3197 - mean_squared_error: 0.2296 - val_loss: 6.1501 - val_mean_squared_error: 0.0732\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.1530 - mean_squared_error: 0.0761 - val_loss: 6.2426 - val_mean_squared_error: 0.1793\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 6.2451 - mean_squared_error: 0.1818 - val_loss: 6.3548 - val_mean_squared_error: 0.3070\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.3534 - mean_squared_error: 0.3057 - val_loss: 6.2587 - val_mean_squared_error: 0.2289\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 6.2598 - mean_squared_error: 0.2300 - val_loss: 6.0989 - val_mean_squared_error: 0.0886\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 6.1030 - mean_squared_error: 0.0928 - val_loss: 6.0927 - val_mean_squared_error: 0.1022\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 6.0925 - mean_squared_error: 0.1020 - val_loss: 6.1840 - val_mean_squared_error: 0.2128\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 6.1764 - mean_squared_error: 0.2052 - val_loss: 6.1742 - val_mean_squared_error: 0.2210\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 6.1661 - mean_squared_error: 0.2129 - val_loss: 6.0560 - val_mean_squared_error: 0.1194\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 6.0545 - mean_squared_error: 0.1180 - val_loss: 5.9917 - val_mean_squared_error: 0.0711\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 5.9953 - mean_squared_error: 0.0747 - val_loss: 6.0291 - val_mean_squared_error: 0.1248\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 6.0327 - mean_squared_error: 0.1284 - val_loss: 6.0495 - val_mean_squared_error: 0.1633\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 6.0522 - mean_squared_error: 0.1660 - val_loss: 5.9838 - val_mean_squared_error: 0.1173\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.9876 - mean_squared_error: 0.1210 - val_loss: 5.9157 - val_mean_squared_error: 0.0701\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.9194 - mean_squared_error: 0.0738 - val_loss: 5.9213 - val_mean_squared_error: 0.0961\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.9216 - mean_squared_error: 0.0965 - val_loss: 5.9428 - val_mean_squared_error: 0.1374\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 5.9401 - mean_squared_error: 0.1348 - val_loss: 5.9062 - val_mean_squared_error: 0.1197\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 5.9047 - mean_squared_error: 0.1183 - val_loss: 5.8441 - val_mean_squared_error: 0.0759\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 5.8463 - mean_squared_error: 0.0781 - val_loss: 5.8250 - val_mean_squared_error: 0.0748\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.8291 - mean_squared_error: 0.0789 - val_loss: 5.8335 - val_mean_squared_error: 0.1019\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.8376 - mean_squared_error: 0.1060 - val_loss: 5.8112 - val_mean_squared_error: 0.0993\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.8154 - mean_squared_error: 0.1035 - val_loss: 5.7642 - val_mean_squared_error: 0.0730\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 13us/step - loss: 5.7684 - mean_squared_error: 0.0772 - val_loss: 5.7416 - val_mean_squared_error: 0.0716\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.7443 - mean_squared_error: 0.0743 - val_loss: 5.7429 - val_mean_squared_error: 0.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.7435 - mean_squared_error: 0.0941 - val_loss: 5.7248 - val_mean_squared_error: 0.0956\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 5.7252 - mean_squared_error: 0.0960 - val_loss: 5.6847 - val_mean_squared_error: 0.0748\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6870 - mean_squared_error: 0.0770 - val_loss: 5.6579 - val_mean_squared_error: 0.0670\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.6619 - mean_squared_error: 0.0710 - val_loss: 5.6498 - val_mean_squared_error: 0.0785\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.6542 - mean_squared_error: 0.0829 - val_loss: 5.6316 - val_mean_squared_error: 0.0803\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 5.6361 - mean_squared_error: 0.0848 - val_loss: 5.5990 - val_mean_squared_error: 0.0687\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 5.6032 - mean_squared_error: 0.0729 - val_loss: 5.5760 - val_mean_squared_error: 0.0670\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.5792 - mean_squared_error: 0.0703 - val_loss: 5.5652 - val_mean_squared_error: 0.0776\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 46us/step - loss: 5.5672 - mean_squared_error: 0.0796 - val_loss: 5.5458 - val_mean_squared_error: 0.0788\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.5477 - mean_squared_error: 0.0807 - val_loss: 5.5152 - val_mean_squared_error: 0.0684\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.5182 - mean_squared_error: 0.0714 - val_loss: 5.4918 - val_mean_squared_error: 0.0647\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.4959 - mean_squared_error: 0.0688 - val_loss: 5.4767 - val_mean_squared_error: 0.0696\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 5.4812 - mean_squared_error: 0.0742 - val_loss: 5.4556 - val_mean_squared_error: 0.0694\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 3.9831 - mean_squared_error: 0.5970 - val_loss: 3.8690 - val_mean_squared_error: 0.5134\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.9596 - mean_squared_error: 0.6040 - val_loss: 3.8444 - val_mean_squared_error: 0.5204\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.9274 - mean_squared_error: 0.6034 - val_loss: 3.7898 - val_mean_squared_error: 0.4785\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 3.8726 - mean_squared_error: 0.5613 - val_loss: 3.7590 - val_mean_squared_error: 0.4545\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.8424 - mean_squared_error: 0.5378 - val_loss: 3.7441 - val_mean_squared_error: 0.4569\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 3.8260 - mean_squared_error: 0.5388 - val_loss: 3.6979 - val_mean_squared_error: 0.4352\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.7768 - mean_squared_error: 0.5141 - val_loss: 3.6827 - val_mean_squared_error: 0.4453\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.7565 - mean_squared_error: 0.5191 - val_loss: 3.6652 - val_mean_squared_error: 0.4480\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 3.7358 - mean_squared_error: 0.5187 - val_loss: 3.6253 - val_mean_squared_error: 0.4219\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.6961 - mean_squared_error: 0.4928 - val_loss: 3.5991 - val_mean_squared_error: 0.4090\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 15us/step - loss: 3.6706 - mean_squared_error: 0.4805 - val_loss: 3.5787 - val_mean_squared_error: 0.4061\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.6492 - mean_squared_error: 0.4766 - val_loss: 3.5450 - val_mean_squared_error: 0.3949\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.6124 - mean_squared_error: 0.4623 - val_loss: 3.5187 - val_mean_squared_error: 0.3922\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.5810 - mean_squared_error: 0.4546 - val_loss: 3.5014 - val_mean_squared_error: 0.3963\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.5592 - mean_squared_error: 0.4541 - val_loss: 3.4727 - val_mean_squared_error: 0.3852\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.5289 - mean_squared_error: 0.4414 - val_loss: 3.4389 - val_mean_squared_error: 0.3675\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 3.4958 - mean_squared_error: 0.4243 - val_loss: 3.4132 - val_mean_squared_error: 0.3591\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.4703 - mean_squared_error: 0.4162 - val_loss: 3.3869 - val_mean_squared_error: 0.3522\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.4422 - mean_squared_error: 0.4075 - val_loss: 3.3585 - val_mean_squared_error: 0.3454\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.4095 - mean_squared_error: 0.3964 - val_loss: 3.3364 - val_mean_squared_error: 0.3455\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.3821 - mean_squared_error: 0.3912 - val_loss: 3.3124 - val_mean_squared_error: 0.3425\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 3.3548 - mean_squared_error: 0.3848 - val_loss: 3.2812 - val_mean_squared_error: 0.3294\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.3233 - mean_squared_error: 0.3715 - val_loss: 3.2517 - val_mean_squared_error: 0.3172\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.2947 - mean_squared_error: 0.3602 - val_loss: 3.2257 - val_mean_squared_error: 0.3097\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 3.2681 - mean_squared_error: 0.3522 - val_loss: 3.1983 - val_mean_squared_error: 0.3033\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 3.2376 - mean_squared_error: 0.3425 - val_loss: 3.1741 - val_mean_squared_error: 0.3006\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 3.2085 - mean_squared_error: 0.3350 - val_loss: 3.1516 - val_mean_squared_error: 0.2984\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.1822 - mean_squared_error: 0.3290 - val_loss: 3.1237 - val_mean_squared_error: 0.2892\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.1533 - mean_squared_error: 0.3188 - val_loss: 3.0944 - val_mean_squared_error: 0.2779\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.1248 - mean_squared_error: 0.3083 - val_loss: 3.0679 - val_mean_squared_error: 0.2702\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.0982 - mean_squared_error: 0.3004 - val_loss: 3.0425 - val_mean_squared_error: 0.2646\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 53us/step - loss: 3.0702 - mean_squared_error: 0.2923 - val_loss: 3.0191 - val_mean_squared_error: 0.2619\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.0426 - mean_squared_error: 0.2854 - val_loss: 2.9962 - val_mean_squared_error: 0.2593\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.0164 - mean_squared_error: 0.2795 - val_loss: 2.9699 - val_mean_squared_error: 0.2520\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.9893 - mean_squared_error: 0.2713 - val_loss: 2.9420 - val_mean_squared_error: 0.2430\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 2.9621 - mean_squared_error: 0.2630 - val_loss: 2.9165 - val_mean_squared_error: 0.2365\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 30us/step - loss: 2.9363 - mean_squared_error: 0.2563 - val_loss: 2.8925 - val_mean_squared_error: 0.2325\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.9097 - mean_squared_error: 0.2497 - val_loss: 2.8703 - val_mean_squared_error: 0.2305\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 2.8839 - mean_squared_error: 0.2442 - val_loss: 2.8470 - val_mean_squared_error: 0.2271\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 2.8585 - mean_squared_error: 0.2386 - val_loss: 2.8207 - val_mean_squared_error: 0.2201\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.8323 - mean_squared_error: 0.2318 - val_loss: 2.7950 - val_mean_squared_error: 0.2135\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 43us/step - loss: 2.8072 - mean_squared_error: 0.2257 - val_loss: 2.7711 - val_mean_squared_error: 0.2093\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.7824 - mean_squared_error: 0.2205 - val_loss: 2.7488 - val_mean_squared_error: 0.2072\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.7573 - mean_squared_error: 0.2157 - val_loss: 2.7266 - val_mean_squared_error: 0.2056\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 44us/step - loss: 2.7326 - mean_squared_error: 0.2116 - val_loss: 2.7023 - val_mean_squared_error: 0.2010\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 2.7078 - mean_squared_error: 0.2065 - val_loss: 2.6771 - val_mean_squared_error: 0.1952\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.6834 - mean_squared_error: 0.2015 - val_loss: 2.6535 - val_mean_squared_error: 0.1912\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.6594 - mean_squared_error: 0.1971 - val_loss: 2.6312 - val_mean_squared_error: 0.1891\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.6352 - mean_squared_error: 0.1931 - val_loss: 2.6090 - val_mean_squared_error: 0.1877\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.6110 - mean_squared_error: 0.1897 - val_loss: 2.5853 - val_mean_squared_error: 0.1841\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 5s 16ms/step - loss: 2.9473 - mean_squared_error: 0.2848 - val_loss: 3.1479 - val_mean_squared_error: 0.5073\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 3.1723 - mean_squared_error: 0.5318 - val_loss: 2.8668 - val_mean_squared_error: 0.2274\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.9104 - mean_squared_error: 0.2711 - val_loss: 2.9386 - val_mean_squared_error: 0.2978\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 2.9898 - mean_squared_error: 0.3490 - val_loss: 2.9622 - val_mean_squared_error: 0.3326\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.0127 - mean_squared_error: 0.3831 - val_loss: 2.8234 - val_mean_squared_error: 0.2116\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.8726 - mean_squared_error: 0.2608 - val_loss: 2.8072 - val_mean_squared_error: 0.2119\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.8478 - mean_squared_error: 0.2526 - val_loss: 2.8756 - val_mean_squared_error: 0.2953\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.9069 - mean_squared_error: 0.3266 - val_loss: 2.8445 - val_mean_squared_error: 0.2776\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 2.8762 - mean_squared_error: 0.3093 - val_loss: 2.7566 - val_mean_squared_error: 0.2002\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.7953 - mean_squared_error: 0.2389 - val_loss: 2.7319 - val_mean_squared_error: 0.1830\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 41us/step - loss: 2.7763 - mean_squared_error: 0.2274 - val_loss: 2.7565 - val_mean_squared_error: 0.2162\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 43us/step - loss: 2.8026 - mean_squared_error: 0.2623 - val_loss: 2.7412 - val_mean_squared_error: 0.2141\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.7867 - mean_squared_error: 0.2597 - val_loss: 2.6886 - val_mean_squared_error: 0.1783\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 2.7314 - mean_squared_error: 0.2211 - val_loss: 2.6649 - val_mean_squared_error: 0.1716\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 2.7019 - mean_squared_error: 0.2085 - val_loss: 2.6783 - val_mean_squared_error: 0.2010\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 2.7088 - mean_squared_error: 0.2315 - val_loss: 2.6744 - val_mean_squared_error: 0.2118\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.7023 - mean_squared_error: 0.2396 - val_loss: 2.6338 - val_mean_squared_error: 0.1840\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 2.6640 - mean_squared_error: 0.2142 - val_loss: 2.5958 - val_mean_squared_error: 0.1572\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6304 - mean_squared_error: 0.1918 - val_loss: 2.5861 - val_mean_squared_error: 0.1582\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.6240 - mean_squared_error: 0.1961 - val_loss: 2.5802 - val_mean_squared_error: 0.1651\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 2.6189 - mean_squared_error: 0.2038 - val_loss: 2.5551 - val_mean_squared_error: 0.1552\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.5921 - mean_squared_error: 0.1922 - val_loss: 2.5280 - val_mean_squared_error: 0.1444\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.5607 - mean_squared_error: 0.1771 - val_loss: 2.5192 - val_mean_squared_error: 0.1517\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 2.5466 - mean_squared_error: 0.1791 - val_loss: 2.5146 - val_mean_squared_error: 0.1627\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 2.5383 - mean_squared_error: 0.1864 - val_loss: 2.4931 - val_mean_squared_error: 0.1559\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.5168 - mean_squared_error: 0.1796 - val_loss: 2.4624 - val_mean_squared_error: 0.1387\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.4890 - mean_squared_error: 0.1653 - val_loss: 2.4418 - val_mean_squared_error: 0.1311\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 2.4716 - mean_squared_error: 0.1608 - val_loss: 2.4294 - val_mean_squared_error: 0.1322\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.4606 - mean_squared_error: 0.1634 - val_loss: 2.4106 - val_mean_squared_error: 0.1290\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.4409 - mean_squared_error: 0.1593 - val_loss: 2.3888 - val_mean_squared_error: 0.1238\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.4160 - mean_squared_error: 0.1510 - val_loss: 2.3749 - val_mean_squared_error: 0.1265\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.3981 - mean_squared_error: 0.1496 - val_loss: 2.3651 - val_mean_squared_error: 0.1321\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 2.3853 - mean_squared_error: 0.1522 - val_loss: 2.3467 - val_mean_squared_error: 0.1285\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 16us/step - loss: 2.3666 - mean_squared_error: 0.1484 - val_loss: 2.3221 - val_mean_squared_error: 0.1183\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 2.3440 - mean_squared_error: 0.1402 - val_loss: 2.3021 - val_mean_squared_error: 0.1125\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3263 - mean_squared_error: 0.1367 - val_loss: 2.2863 - val_mean_squared_error: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 2.3115 - mean_squared_error: 0.1363 - val_loss: 2.2685 - val_mean_squared_error: 0.1085\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.2927 - mean_squared_error: 0.1327 - val_loss: 2.2507 - val_mean_squared_error: 0.1068\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.2722 - mean_squared_error: 0.1283 - val_loss: 2.2370 - val_mean_squared_error: 0.1093\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.2555 - mean_squared_error: 0.1278 - val_loss: 2.2228 - val_mean_squared_error: 0.1108\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.2397 - mean_squared_error: 0.1276 - val_loss: 2.2031 - val_mean_squared_error: 0.1062\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.2204 - mean_squared_error: 0.1235 - val_loss: 2.1826 - val_mean_squared_error: 0.1001\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 2.2015 - mean_squared_error: 0.1190 - val_loss: 2.1657 - val_mean_squared_error: 0.0972\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 2.1860 - mean_squared_error: 0.1175 - val_loss: 2.1494 - val_mean_squared_error: 0.0956\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.1697 - mean_squared_error: 0.1159 - val_loss: 2.1321 - val_mean_squared_error: 0.0942\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 2.1508 - mean_squared_error: 0.1129 - val_loss: 2.1171 - val_mean_squared_error: 0.0950\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 43us/step - loss: 2.1335 - mean_squared_error: 0.1114 - val_loss: 2.1030 - val_mean_squared_error: 0.0965\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 2.1175 - mean_squared_error: 0.1111 - val_loss: 2.0858 - val_mean_squared_error: 0.0945\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 2.1002 - mean_squared_error: 0.1089 - val_loss: 2.0668 - val_mean_squared_error: 0.0902\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.0823 - mean_squared_error: 0.1057 - val_loss: 2.0495 - val_mean_squared_error: 0.0873\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.5, 0.1, 0.05, 0.01]:\n",
    "    for i in range(N_MODELS):\n",
    "        histories[i] = train(models[i], [x_train, y_train], (x_val, y_val), lr, 500, history=histories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict target feature using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = []\n",
    "y_val_preds = []\n",
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(x_train))\n",
    "    y_val_preds.append(model.predict(x_val))\n",
    "    y_test_preds.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble variance to predict diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_var = np.var(y_train_preds, axis=0)\n",
    "y_val_preds_var = np.var(y_val_preds, axis=0)\n",
    "y_test_preds_var = np.var(y_test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAJCCAYAAACxozTkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndOb/A42DNNt7Sb33AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(y_train_preds_var, color='b',  bins=50, label='train')\n",
    "plt.hist(y_val_preds_var, fc=(1, 0, 0, 0.5), bins=50, label='val')\n",
    "plt.hist(y_test_preds_var, fc=(0, 1, 0, 0.5), bins=50, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_var = 1.5 * y_train_preds_var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859649122807018\n"
     ]
    }
   ],
   "source": [
    "train_acc = (y_train_preds_var < threshold_var).mean()\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "val_acc = (y_val_preds_var < threshold_var).mean()\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679245283018868\n"
     ]
    }
   ],
   "source": [
    "test_acc = (y_test_preds_var >= threshold_var).mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But best single predictive variable is not known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "c:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "x_healthy.loc[:, TARGET] = y_healthy\n",
    "x_unhealthy.loc[:, TARGET] = y_unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x288ce4b67f0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKyCAYAAAADycwvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREVWlII2IiIiIqlKQRkRERERV/w9dJzAh1FcqwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = len(FEATURES + [TARGET])\n",
    "f, ax = plt.subplots(figsize=(width, width))\n",
    "sns.heatmap(x_healthy.corr(), annot=True, linewidths=.5, fmt= '.1f', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "basis = pca.fit(x_healthy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x288cf1e9ef0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAJCCAYAAACBJrCpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW7AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_healthy_transformed = basis.transform(x_healthy)\n",
    "x_unhealthy_transformed = basis.transform(x_unhealthy)\n",
    "\n",
    "plt.figure(figsize=(width, width))\n",
    "plt.scatter(x_healthy_transformed[:, 0], x_healthy_transformed[:, 1])\n",
    "plt.scatter(x_unhealthy_transformed[:, 0], x_unhealthy_transformed[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the fewer dimentions for ensembling variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for training: 285\n",
      "# Examples for validation: 72\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(x_healthy_transformed))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(x_healthy_transformed)\n",
    "x_train_transformed = x_healthy_transformed[:TRAIN_SIZE, :-1]\n",
    "y_train_transformed = x_healthy_transformed[:TRAIN_SIZE, -1]\n",
    "print('# Examples for training:',  len(x_train_transformed))\n",
    "\n",
    "x_val_transformed = x_healthy_transformed[TRAIN_SIZE:, :-1]\n",
    "y_val_transformed = x_healthy_transformed[TRAIN_SIZE:, -1]\n",
    "print('# Examples for validation:',  len(x_val_transformed))\n",
    "\n",
    "N_FEATURES_TRANSFORMED = x_val_transformed.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "N_MODELS = 5\n",
    "n_hidden_neurons = 32\n",
    "for _ in range(N_MODELS):\n",
    "    models.append(create_base_model(N_FEATURES_TRANSFORMED, n_hidden_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.0464 - mean_squared_error: 0.0085 - val_loss: 39.6574 - val_mean_squared_error: 39.0028\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 27.6676 - mean_squared_error: 27.0130 - val_loss: 41.1289 - val_mean_squared_error: 40.4262\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 50.0969 - mean_squared_error: 49.3942 - val_loss: 6.3552 - val_mean_squared_error: 5.7358\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.5124 - mean_squared_error: 4.8930 - val_loss: 2.5036 - val_mean_squared_error: 1.8561\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.3777 - mean_squared_error: 1.7302 - val_loss: 11.1268 - val_mean_squared_error: 10.5168\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.1582 - mean_squared_error: 8.5482 - val_loss: 7.8746 - val_mean_squared_error: 7.3080\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 7.0174 - mean_squared_error: 6.4508 - val_loss: 4.0621 - val_mean_squared_error: 3.5112\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.8538 - mean_squared_error: 4.3030 - val_loss: 12.0774 - val_mean_squared_error: 11.5409\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.3819 - mean_squared_error: 9.8454 - val_loss: 11.2353 - val_mean_squared_error: 10.7326\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 7.8696 - mean_squared_error: 7.3669 - val_loss: 3.8523 - val_mean_squared_error: 3.3684\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.6849 - mean_squared_error: 2.2011 - val_loss: 2.0225 - val_mean_squared_error: 1.5391\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.6770 - mean_squared_error: 2.1936 - val_loss: 4.6262 - val_mean_squared_error: 4.1612\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.1427 - mean_squared_error: 4.6776 - val_loss: 6.1243 - val_mean_squared_error: 5.6819\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 5.8189 - mean_squared_error: 5.3764 - val_loss: 3.6933 - val_mean_squared_error: 3.2519\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.3596 - mean_squared_error: 2.9182 - val_loss: 1.2637 - val_mean_squared_error: 0.7861\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.8277 - mean_squared_error: 0.3501 - val_loss: 3.2034 - val_mean_squared_error: 2.6791\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.4684 - mean_squared_error: 1.9440 - val_loss: 4.4351 - val_mean_squared_error: 3.8766\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 3.1120 - mean_squared_error: 2.5534 - val_loss: 3.8721 - val_mean_squared_error: 3.3020\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.0842 - mean_squared_error: 1.5140 - val_loss: 4.1314 - val_mean_squared_error: 3.5588\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 2.6416 - mean_squared_error: 2.0691 - val_loss: 2.2450 - val_mean_squared_error: 1.6725\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 1.5254 - mean_squared_error: 0.9528 - val_loss: 0.8667 - val_mean_squared_error: 0.2855\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.8091 - mean_squared_error: 0.2278 - val_loss: 2.0209 - val_mean_squared_error: 1.4155\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.1166 - mean_squared_error: 1.5113 - val_loss: 1.5949 - val_mean_squared_error: 0.9764\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.4474 - mean_squared_error: 0.8289 - val_loss: 1.7605 - val_mean_squared_error: 1.1454\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.7270 - mean_squared_error: 1.1119 - val_loss: 1.4596 - val_mean_squared_error: 0.8573\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 10us/step - loss: 1.4836 - mean_squared_error: 0.8813 - val_loss: 0.6422 - val_mean_squared_error: 0.0558\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.6434 - mean_squared_error: 0.0570 - val_loss: 1.2633 - val_mean_squared_error: 0.6847\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.3683 - mean_squared_error: 0.7896 - val_loss: 0.9963 - val_mean_squared_error: 0.4195\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.9173 - mean_squared_error: 0.3404 - val_loss: 1.4742 - val_mean_squared_error: 0.8997\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.1777 - mean_squared_error: 0.6031 - val_loss: 1.4771 - val_mean_squared_error: 0.9008\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.2326 - mean_squared_error: 0.6563 - val_loss: 0.7713 - val_mean_squared_error: 0.2030\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.7173 - mean_squared_error: 0.1489 - val_loss: 0.9934 - val_mean_squared_error: 0.4303\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.0444 - mean_squared_error: 0.4813 - val_loss: 0.6127 - val_mean_squared_error: 0.0500\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.6086 - mean_squared_error: 0.0459 - val_loss: 0.8803 - val_mean_squared_error: 0.3207\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.9025 - mean_squared_error: 0.3430 - val_loss: 0.8614 - val_mean_squared_error: 0.3123\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.8343 - mean_squared_error: 0.2852 - val_loss: 0.8693 - val_mean_squared_error: 0.3374\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.7409 - mean_squared_error: 0.2090 - val_loss: 0.9921 - val_mean_squared_error: 0.4664\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.8775 - mean_squared_error: 0.3518 - val_loss: 0.6181 - val_mean_squared_error: 0.0965\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.5704 - mean_squared_error: 0.0487 - val_loss: 0.7290 - val_mean_squared_error: 0.2173\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.7533 - mean_squared_error: 0.2416 - val_loss: 0.5300 - val_mean_squared_error: 0.0290\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.5361 - mean_squared_error: 0.0351 - val_loss: 0.6396 - val_mean_squared_error: 0.1508\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.6522 - mean_squared_error: 0.1634 - val_loss: 0.6209 - val_mean_squared_error: 0.1335\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.6248 - mean_squared_error: 0.1373 - val_loss: 0.5911 - val_mean_squared_error: 0.1075\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.5871 - mean_squared_error: 0.1034 - val_loss: 0.6348 - val_mean_squared_error: 0.1654\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.6430 - mean_squared_error: 0.1735 - val_loss: 0.4893 - val_mean_squared_error: 0.0358\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.4887 - mean_squared_error: 0.0352 - val_loss: 0.5563 - val_mean_squared_error: 0.1170\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.5659 - mean_squared_error: 0.1266 - val_loss: 0.4478 - val_mean_squared_error: 0.0149\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.4456 - mean_squared_error: 0.0127 - val_loss: 0.5190 - val_mean_squared_error: 0.0856\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.5204 - mean_squared_error: 0.0870 - val_loss: 0.4957 - val_mean_squared_error: 0.0662\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.4802 - mean_squared_error: 0.0508 - val_loss: 0.5048 - val_mean_squared_error: 0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 0.0461 - mean_squared_error: 0.0081 - val_loss: 38.1050 - val_mean_squared_error: 37.4513\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 31.0141 - mean_squared_error: 30.3603 - val_loss: 1.0192 - val_mean_squared_error: 0.6199\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.9888 - mean_squared_error: 0.5894 - val_loss: 2.8305 - val_mean_squared_error: 2.6499\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.3592 - mean_squared_error: 3.1786 - val_loss: 6.8395 - val_mean_squared_error: 6.5479\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 5.6181 - mean_squared_error: 5.3265 - val_loss: 4.2013 - val_mean_squared_error: 3.8252\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.8878 - mean_squared_error: 3.5117 - val_loss: 5.6403 - val_mean_squared_error: 5.2072\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.1588 - mean_squared_error: 2.7257 - val_loss: 10.6776 - val_mean_squared_error: 10.2322\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 5.9567 - mean_squared_error: 5.5113 - val_loss: 4.7202 - val_mean_squared_error: 4.2919\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 3.9208 - mean_squared_error: 3.4925 - val_loss: 5.4265 - val_mean_squared_error: 4.9651\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.4722 - mean_squared_error: 5.0109 - val_loss: 3.0123 - val_mean_squared_error: 2.5537\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 2.4218 - mean_squared_error: 1.9632 - val_loss: 3.4173 - val_mean_squared_error: 3.0002\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.7211 - mean_squared_error: 1.3039 - val_loss: 4.4534 - val_mean_squared_error: 4.0918\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 2.7528 - mean_squared_error: 2.3911 - val_loss: 1.2566 - val_mean_squared_error: 0.9570\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.8027 - mean_squared_error: 0.5031 - val_loss: 0.6836 - val_mean_squared_error: 0.4115\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.6645 - mean_squared_error: 0.3925 - val_loss: 1.3903 - val_mean_squared_error: 1.1159\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 1.2415 - mean_squared_error: 0.9671 - val_loss: 0.7859 - val_mean_squared_error: 0.5173\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.7430 - mean_squared_error: 0.4744 - val_loss: 0.9028 - val_mean_squared_error: 0.6506\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.0075 - mean_squared_error: 0.7552 - val_loss: 0.5040 - val_mean_squared_error: 0.2784\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.5149 - mean_squared_error: 0.2894 - val_loss: 0.3482 - val_mean_squared_error: 0.1402\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.4116 - mean_squared_error: 0.2035 - val_loss: 0.6868 - val_mean_squared_error: 0.4810\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.8703 - mean_squared_error: 0.6645 - val_loss: 0.3883 - val_mean_squared_error: 0.1815\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3978 - mean_squared_error: 0.1910 - val_loss: 0.6699 - val_mean_squared_error: 0.4735\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.6076 - mean_squared_error: 0.4112 - val_loss: 0.2953 - val_mean_squared_error: 0.1192\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2835 - mean_squared_error: 0.1075 - val_loss: 0.3369 - val_mean_squared_error: 0.1686\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.3330 - mean_squared_error: 0.1647 - val_loss: 0.4794 - val_mean_squared_error: 0.3107\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.4641 - mean_squared_error: 0.2954 - val_loss: 0.1931 - val_mean_squared_error: 0.0282\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.2011 - mean_squared_error: 0.0362 - val_loss: 0.4161 - val_mean_squared_error: 0.2510\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.4330 - mean_squared_error: 0.2679 - val_loss: 0.2236 - val_mean_squared_error: 0.0616\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2185 - mean_squared_error: 0.0565 - val_loss: 0.2831 - val_mean_squared_error: 0.1245\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.2826 - mean_squared_error: 0.1240 - val_loss: 0.3089 - val_mean_squared_error: 0.1508\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3072 - mean_squared_error: 0.1491 - val_loss: 0.2704 - val_mean_squared_error: 0.1154\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 44us/step - loss: 0.2086 - mean_squared_error: 0.0537 - val_loss: 0.4504 - val_mean_squared_error: 0.2969\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.3519 - mean_squared_error: 0.1984 - val_loss: 0.2351 - val_mean_squared_error: 0.0866\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1830 - mean_squared_error: 0.0345 - val_loss: 0.2900 - val_mean_squared_error: 0.1441\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.2857 - mean_squared_error: 0.1398 - val_loss: 0.2015 - val_mean_squared_error: 0.0503\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1915 - mean_squared_error: 0.0403 - val_loss: 0.2428 - val_mean_squared_error: 0.0909\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2235 - mean_squared_error: 0.0716 - val_loss: 0.2406 - val_mean_squared_error: 0.0920\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2317 - mean_squared_error: 0.0832 - val_loss: 0.1813 - val_mean_squared_error: 0.0447\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1801 - mean_squared_error: 0.0435 - val_loss: 0.2328 - val_mean_squared_error: 0.0944\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2335 - mean_squared_error: 0.0951 - val_loss: 0.1641 - val_mean_squared_error: 0.0189\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1588 - mean_squared_error: 0.0136 - val_loss: 0.2372 - val_mean_squared_error: 0.0963\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.2167 - mean_squared_error: 0.0758 - val_loss: 0.1554 - val_mean_squared_error: 0.0262\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1397 - mean_squared_error: 0.0105 - val_loss: 0.1877 - val_mean_squared_error: 0.0654\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1868 - mean_squared_error: 0.0646 - val_loss: 0.1567 - val_mean_squared_error: 0.0326\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.1473 - mean_squared_error: 0.0232 - val_loss: 0.1973 - val_mean_squared_error: 0.0723\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1714 - mean_squared_error: 0.0463 - val_loss: 0.1580 - val_mean_squared_error: 0.0390\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.1439 - mean_squared_error: 0.0249 - val_loss: 0.1356 - val_mean_squared_error: 0.0235\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1374 - mean_squared_error: 0.0253 - val_loss: 0.1304 - val_mean_squared_error: 0.0243\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.1326 - mean_squared_error: 0.0266 - val_loss: 0.1178 - val_mean_squared_error: 0.0163\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.1188 - mean_squared_error: 0.0174 - val_loss: 0.1316 - val_mean_squared_error: 0.0283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.0491 - mean_squared_error: 0.0127 - val_loss: 3.5906 - val_mean_squared_error: 3.1485\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.2756 - mean_squared_error: 3.8335 - val_loss: 83.4410 - val_mean_squared_error: 82.9952\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 96.4828 - mean_squared_error: 96.0370 - val_loss: 2.7900 - val_mean_squared_error: 2.3731\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.4179 - mean_squared_error: 3.0010 - val_loss: 6.8792 - val_mean_squared_error: 6.4077\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.1142 - mean_squared_error: 4.6427 - val_loss: 1.2047 - val_mean_squared_error: 0.7045\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.0935 - mean_squared_error: 0.5933 - val_loss: 17.9735 - val_mean_squared_error: 17.4399\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 20.2383 - mean_squared_error: 19.7048 - val_loss: 7.5430 - val_mean_squared_error: 7.0262\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.1211 - mean_squared_error: 6.6043 - val_loss: 4.1841 - val_mean_squared_error: 3.6301\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.6167 - mean_squared_error: 4.0627 - val_loss: 9.4621 - val_mean_squared_error: 8.8939\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 9.3500 - mean_squared_error: 8.7818 - val_loss: 1.4910 - val_mean_squared_error: 0.9406\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 1.5762 - mean_squared_error: 1.0258 - val_loss: 8.0159 - val_mean_squared_error: 7.4919\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 6.0281 - mean_squared_error: 5.5040 - val_loss: 13.4546 - val_mean_squared_error: 12.9580\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 9.6403 - mean_squared_error: 9.1436 - val_loss: 2.9986 - val_mean_squared_error: 2.5277\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.8687 - mean_squared_error: 1.3979 - val_loss: 3.6904 - val_mean_squared_error: 3.2204\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.0447 - mean_squared_error: 3.5747 - val_loss: 4.9107 - val_mean_squared_error: 4.4289\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.8435 - mean_squared_error: 5.3618 - val_loss: 3.2145 - val_mean_squared_error: 2.7310\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2308 - mean_squared_error: 1.7473 - val_loss: 7.0452 - val_mean_squared_error: 6.5719\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 11us/step - loss: 3.1940 - mean_squared_error: 2.7207 - val_loss: 4.8722 - val_mean_squared_error: 4.4060\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.5569 - mean_squared_error: 3.0907 - val_loss: 3.0201 - val_mean_squared_error: 2.5582\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 20us/step - loss: 3.1943 - mean_squared_error: 2.7324 - val_loss: 2.2293 - val_mean_squared_error: 1.7738\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.8764 - mean_squared_error: 1.4209 - val_loss: 1.5340 - val_mean_squared_error: 1.0743\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 1.6433 - mean_squared_error: 1.1836 - val_loss: 3.7911 - val_mean_squared_error: 3.3294\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.3022 - mean_squared_error: 2.8405 - val_loss: 1.6868 - val_mean_squared_error: 1.2392\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 1.3218 - mean_squared_error: 0.8742 - val_loss: 0.8829 - val_mean_squared_error: 0.4348\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9316 - mean_squared_error: 0.4836 - val_loss: 2.7480 - val_mean_squared_error: 2.2973\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 2.6146 - mean_squared_error: 2.1639 - val_loss: 1.2330 - val_mean_squared_error: 0.7946\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.3065 - mean_squared_error: 0.8682 - val_loss: 0.8384 - val_mean_squared_error: 0.4063\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.7254 - mean_squared_error: 0.2933 - val_loss: 1.8018 - val_mean_squared_error: 1.3722\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 1.6675 - mean_squared_error: 1.2379 - val_loss: 1.2391 - val_mean_squared_error: 0.8204\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.3213 - mean_squared_error: 0.9026 - val_loss: 1.0021 - val_mean_squared_error: 0.5897\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.7305 - mean_squared_error: 0.3181 - val_loss: 1.2102 - val_mean_squared_error: 0.8019\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.0143 - mean_squared_error: 0.6060 - val_loss: 1.1309 - val_mean_squared_error: 0.7300\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 1.2280 - mean_squared_error: 0.8271 - val_loss: 0.8805 - val_mean_squared_error: 0.4900\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.8007 - mean_squared_error: 0.4101 - val_loss: 0.7130 - val_mean_squared_error: 0.3261\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.6212 - mean_squared_error: 0.2343 - val_loss: 0.9552 - val_mean_squared_error: 0.5735\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.0237 - mean_squared_error: 0.6420 - val_loss: 0.7988 - val_mean_squared_error: 0.4275\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.8053 - mean_squared_error: 0.4340 - val_loss: 0.4591 - val_mean_squared_error: 0.0919\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.4504 - mean_squared_error: 0.0832 - val_loss: 0.8144 - val_mean_squared_error: 0.4501\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.8225 - mean_squared_error: 0.4581 - val_loss: 0.8152 - val_mean_squared_error: 0.4567\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.7631 - mean_squared_error: 0.4046 - val_loss: 0.4168 - val_mean_squared_error: 0.0669\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.3796 - mean_squared_error: 0.0297 - val_loss: 0.5943 - val_mean_squared_error: 0.2502\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.6434 - mean_squared_error: 0.2993 - val_loss: 0.6189 - val_mean_squared_error: 0.2791\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.6739 - mean_squared_error: 0.3341 - val_loss: 0.3556 - val_mean_squared_error: 0.0165\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.3595 - mean_squared_error: 0.0203 - val_loss: 0.5432 - val_mean_squared_error: 0.2088\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.5309 - mean_squared_error: 0.1965 - val_loss: 0.5977 - val_mean_squared_error: 0.2720\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.5928 - mean_squared_error: 0.2672 - val_loss: 0.3494 - val_mean_squared_error: 0.0286\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.3469 - mean_squared_error: 0.0262 - val_loss: 0.4291 - val_mean_squared_error: 0.1114\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.4489 - mean_squared_error: 0.1312 - val_loss: 0.4911 - val_mean_squared_error: 0.1758\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.5194 - mean_squared_error: 0.2040 - val_loss: 0.3470 - val_mean_squared_error: 0.0374\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.3383 - mean_squared_error: 0.0287 - val_loss: 0.4208 - val_mean_squared_error: 0.1170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.0501 - mean_squared_error: 0.0125 - val_loss: 15.5612 - val_mean_squared_error: 15.1166\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 13.3319 - mean_squared_error: 12.8873 - val_loss: 86.3172 - val_mean_squared_error: 85.7782\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 70.7438 - mean_squared_error: 70.2047 - val_loss: 7.1734 - val_mean_squared_error: 6.7181\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 5.7824 - mean_squared_error: 5.3271 - val_loss: 1.3694 - val_mean_squared_error: 0.9218\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.1184 - mean_squared_error: 0.6707 - val_loss: 2.7993 - val_mean_squared_error: 2.3655\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2186 - mean_squared_error: 1.7848 - val_loss: 0.7140 - val_mean_squared_error: 0.2482\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.6666 - mean_squared_error: 0.2008 - val_loss: 8.1352 - val_mean_squared_error: 7.6410\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.4549 - mean_squared_error: 5.9607 - val_loss: 7.9014 - val_mean_squared_error: 7.4122\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 6.8672 - mean_squared_error: 6.3780 - val_loss: 1.2428 - val_mean_squared_error: 0.7533\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.2491 - mean_squared_error: 0.7597 - val_loss: 6.3343 - val_mean_squared_error: 5.8203\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.5504 - mean_squared_error: 6.0364 - val_loss: 1.5831 - val_mean_squared_error: 1.0711\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.9065 - mean_squared_error: 1.3945 - val_loss: 4.4457 - val_mean_squared_error: 3.9225\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 3.7176 - mean_squared_error: 3.1944 - val_loss: 5.3653 - val_mean_squared_error: 4.8394\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 5.0371 - mean_squared_error: 4.5111 - val_loss: 0.8833 - val_mean_squared_error: 0.3411\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.7805 - mean_squared_error: 0.2383 - val_loss: 4.6154 - val_mean_squared_error: 4.0559\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 4.3559 - mean_squared_error: 3.7964 - val_loss: 2.3040 - val_mean_squared_error: 1.7608\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.1589 - mean_squared_error: 1.6156 - val_loss: 1.4766 - val_mean_squared_error: 0.9544\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 1.4324 - mean_squared_error: 0.9102 - val_loss: 3.7092 - val_mean_squared_error: 3.2052\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.5220 - mean_squared_error: 3.0179 - val_loss: 1.1962 - val_mean_squared_error: 0.7153\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.1049 - mean_squared_error: 0.6241 - val_loss: 1.7552 - val_mean_squared_error: 1.2901\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 16us/step - loss: 1.6432 - mean_squared_error: 1.1782 - val_loss: 2.9279 - val_mean_squared_error: 2.4689\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 2.4846 - mean_squared_error: 2.0256 - val_loss: 0.7822 - val_mean_squared_error: 0.3335\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.6997 - mean_squared_error: 0.2511 - val_loss: 1.7067 - val_mean_squared_error: 1.2611\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.4794 - mean_squared_error: 1.0338 - val_loss: 2.1040 - val_mean_squared_error: 1.6593\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.8124 - mean_squared_error: 1.3677 - val_loss: 0.5939 - val_mean_squared_error: 0.1607\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.5801 - mean_squared_error: 0.1468 - val_loss: 1.5727 - val_mean_squared_error: 1.1595\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.2322 - mean_squared_error: 0.8190 - val_loss: 1.6301 - val_mean_squared_error: 1.2411\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.3309 - mean_squared_error: 0.9419 - val_loss: 0.5500 - val_mean_squared_error: 0.1692\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5057 - mean_squared_error: 0.1250 - val_loss: 0.8713 - val_mean_squared_error: 0.4890\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.9510 - mean_squared_error: 0.5687 - val_loss: 1.0182 - val_mean_squared_error: 0.6430\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.0632 - mean_squared_error: 0.6880 - val_loss: 0.4732 - val_mean_squared_error: 0.1108\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.4561 - mean_squared_error: 0.0936 - val_loss: 0.7998 - val_mean_squared_error: 0.4494\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.7188 - mean_squared_error: 0.3684 - val_loss: 1.0660 - val_mean_squared_error: 0.7222\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.8877 - mean_squared_error: 0.5440 - val_loss: 0.4462 - val_mean_squared_error: 0.1122\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.4085 - mean_squared_error: 0.0745 - val_loss: 0.5991 - val_mean_squared_error: 0.2704\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.5606 - mean_squared_error: 0.2319 - val_loss: 0.7339 - val_mean_squared_error: 0.4068\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.7148 - mean_squared_error: 0.3878 - val_loss: 0.4223 - val_mean_squared_error: 0.1056\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.4185 - mean_squared_error: 0.1018 - val_loss: 0.4158 - val_mean_squared_error: 0.1068\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.4209 - mean_squared_error: 0.1119 - val_loss: 0.5897 - val_mean_squared_error: 0.2859\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.5941 - mean_squared_error: 0.2903 - val_loss: 0.4277 - val_mean_squared_error: 0.1351\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.4042 - mean_squared_error: 0.1116 - val_loss: 0.3376 - val_mean_squared_error: 0.0546\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.3264 - mean_squared_error: 0.0434 - val_loss: 0.5229 - val_mean_squared_error: 0.2465\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.4817 - mean_squared_error: 0.2053 - val_loss: 0.3830 - val_mean_squared_error: 0.1091\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3807 - mean_squared_error: 0.1068 - val_loss: 0.2924 - val_mean_squared_error: 0.0212\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2876 - mean_squared_error: 0.0164 - val_loss: 0.3999 - val_mean_squared_error: 0.1309\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.4002 - mean_squared_error: 0.1312 - val_loss: 0.3878 - val_mean_squared_error: 0.1241\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3640 - mean_squared_error: 0.1002 - val_loss: 0.2728 - val_mean_squared_error: 0.0184\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2688 - mean_squared_error: 0.0144 - val_loss: 0.3277 - val_mean_squared_error: 0.0786\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.3245 - mean_squared_error: 0.0754 - val_loss: 0.3334 - val_mean_squared_error: 0.0874\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.3343 - mean_squared_error: 0.0882 - val_loss: 0.2626 - val_mean_squared_error: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.0452 - mean_squared_error: 0.0091 - val_loss: 2.9913 - val_mean_squared_error: 2.5465\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 2.7450 - mean_squared_error: 2.3002 - val_loss: 120.1102 - val_mean_squared_error: 119.6597\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 94.1666 - mean_squared_error: 93.7161 - val_loss: 1.6004 - val_mean_squared_error: 1.2578\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.1227 - mean_squared_error: 0.7802 - val_loss: 16.7762 - val_mean_squared_error: 16.4053\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 11us/step - loss: 14.2632 - mean_squared_error: 13.8923 - val_loss: 4.4904 - val_mean_squared_error: 4.0878\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 22us/step - loss: 3.7480 - mean_squared_error: 3.3454 - val_loss: 12.3010 - val_mean_squared_error: 11.8258\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 10.0181 - mean_squared_error: 9.5428 - val_loss: 28.5729 - val_mean_squared_error: 28.0994\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 23.5326 - mean_squared_error: 23.0591 - val_loss: 11.4508 - val_mean_squared_error: 11.0435\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.5918 - mean_squared_error: 9.1845 - val_loss: 0.8450 - val_mean_squared_error: 0.4677\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.7083 - mean_squared_error: 0.3310 - val_loss: 3.9051 - val_mean_squared_error: 3.5382\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 4.9215 - mean_squared_error: 4.5545 - val_loss: 3.7368 - val_mean_squared_error: 3.3584\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 29us/step - loss: 3.9222 - mean_squared_error: 3.5438 - val_loss: 1.5913 - val_mean_squared_error: 1.1766\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.3038 - mean_squared_error: 0.8891 - val_loss: 2.2022 - val_mean_squared_error: 1.7659\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6653 - mean_squared_error: 2.2290 - val_loss: 3.5406 - val_mean_squared_error: 3.1254\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 3.8069 - mean_squared_error: 3.3916 - val_loss: 2.9408 - val_mean_squared_error: 2.5643\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.4698 - mean_squared_error: 2.0933 - val_loss: 1.6244 - val_mean_squared_error: 1.2665\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.5199 - mean_squared_error: 1.1620 - val_loss: 1.2359 - val_mean_squared_error: 0.8820\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.6823 - mean_squared_error: 1.3284 - val_loss: 1.8907 - val_mean_squared_error: 1.5572\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.0544 - mean_squared_error: 1.7210 - val_loss: 1.9463 - val_mean_squared_error: 1.6220\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.7178 - mean_squared_error: 1.3935 - val_loss: 0.8413 - val_mean_squared_error: 0.4954\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.7768 - mean_squared_error: 0.4309 - val_loss: 1.0308 - val_mean_squared_error: 0.6569\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8908 - mean_squared_error: 0.5169 - val_loss: 2.4693 - val_mean_squared_error: 2.0821\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8846 - mean_squared_error: 1.4974 - val_loss: 1.9024 - val_mean_squared_error: 1.5279\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.4289 - mean_squared_error: 1.0544 - val_loss: 0.5332 - val_mean_squared_error: 0.1887\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.4906 - mean_squared_error: 0.1462 - val_loss: 0.8217 - val_mean_squared_error: 0.5051\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.7650 - mean_squared_error: 0.4485 - val_loss: 1.1261 - val_mean_squared_error: 0.8253\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.9848 - mean_squared_error: 0.6839 - val_loss: 0.8551 - val_mean_squared_error: 0.5621\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.8614 - mean_squared_error: 0.5685 - val_loss: 0.7929 - val_mean_squared_error: 0.4993\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.8338 - mean_squared_error: 0.5402 - val_loss: 0.4473 - val_mean_squared_error: 0.1445\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.4289 - mean_squared_error: 0.1261 - val_loss: 0.4736 - val_mean_squared_error: 0.1735\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.5014 - mean_squared_error: 0.2013 - val_loss: 0.7706 - val_mean_squared_error: 0.4770\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.8473 - mean_squared_error: 0.5537 - val_loss: 0.5696 - val_mean_squared_error: 0.2861\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.5588 - mean_squared_error: 0.2753 - val_loss: 0.5836 - val_mean_squared_error: 0.3155\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.4937 - mean_squared_error: 0.2256 - val_loss: 0.4247 - val_mean_squared_error: 0.1748\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.3981 - mean_squared_error: 0.1482 - val_loss: 0.3668 - val_mean_squared_error: 0.1272\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.3606 - mean_squared_error: 0.1210 - val_loss: 0.6555 - val_mean_squared_error: 0.4156\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.5983 - mean_squared_error: 0.3584 - val_loss: 0.4108 - val_mean_squared_error: 0.1689\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.4007 - mean_squared_error: 0.1588 - val_loss: 0.3458 - val_mean_squared_error: 0.1030\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.3551 - mean_squared_error: 0.1122 - val_loss: 0.3640 - val_mean_squared_error: 0.1279\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.3339 - mean_squared_error: 0.0977 - val_loss: 0.3276 - val_mean_squared_error: 0.1035\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.3256 - mean_squared_error: 0.1015 - val_loss: 0.4128 - val_mean_squared_error: 0.1924\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.4437 - mean_squared_error: 0.2233 - val_loss: 0.2899 - val_mean_squared_error: 0.0725\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2853 - mean_squared_error: 0.0679 - val_loss: 0.3194 - val_mean_squared_error: 0.1032\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 46us/step - loss: 0.2986 - mean_squared_error: 0.0824 - val_loss: 0.2566 - val_mean_squared_error: 0.0472\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2635 - mean_squared_error: 0.0541 - val_loss: 0.3021 - val_mean_squared_error: 0.1051\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2948 - mean_squared_error: 0.0979 - val_loss: 0.3246 - val_mean_squared_error: 0.1343\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.3134 - mean_squared_error: 0.1232 - val_loss: 0.2163 - val_mean_squared_error: 0.0256\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2260 - mean_squared_error: 0.0354 - val_loss: 0.2504 - val_mean_squared_error: 0.0657\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2442 - mean_squared_error: 0.0595 - val_loss: 0.2143 - val_mean_squared_error: 0.0328\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2072 - mean_squared_error: 0.0257 - val_loss: 0.2538 - val_mean_squared_error: 0.0759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 5s 16ms/step - loss: 0.4819 - mean_squared_error: 0.0635 - val_loss: 8.5275 - val_mean_squared_error: 8.1553\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 9.6796 - mean_squared_error: 9.3074 - val_loss: 0.9164 - val_mean_squared_error: 0.5799\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.9888 - mean_squared_error: 0.6523 - val_loss: 1.7421 - val_mean_squared_error: 1.4467\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.9534 - mean_squared_error: 1.6580 - val_loss: 4.3856 - val_mean_squared_error: 4.1179\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 4.9688 - mean_squared_error: 4.7012 - val_loss: 3.6710 - val_mean_squared_error: 3.4323\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.1398 - mean_squared_error: 3.9011 - val_loss: 1.4954 - val_mean_squared_error: 1.2907\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 1.6614 - mean_squared_error: 1.4567 - val_loss: 0.2352 - val_mean_squared_error: 0.0580\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.2411 - mean_squared_error: 0.0638 - val_loss: 0.5373 - val_mean_squared_error: 0.3778\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.5871 - mean_squared_error: 0.4275 - val_loss: 1.5164 - val_mean_squared_error: 1.3610\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.6768 - mean_squared_error: 1.5214 - val_loss: 1.9880 - val_mean_squared_error: 1.8424\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 2.1880 - mean_squared_error: 2.0424 - val_loss: 1.5998 - val_mean_squared_error: 1.4685\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 1.7462 - mean_squared_error: 1.6150 - val_loss: 0.8123 - val_mean_squared_error: 0.6925\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.8742 - mean_squared_error: 0.7543 - val_loss: 0.2299 - val_mean_squared_error: 0.1159\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2381 - mean_squared_error: 0.1241 - val_loss: 0.1423 - val_mean_squared_error: 0.0365\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1456 - mean_squared_error: 0.0399 - val_loss: 0.4452 - val_mean_squared_error: 0.3461\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.4728 - mean_squared_error: 0.3736 - val_loss: 0.8028 - val_mean_squared_error: 0.7043\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.8561 - mean_squared_error: 0.7577 - val_loss: 0.9252 - val_mean_squared_error: 0.8281\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.9906 - mean_squared_error: 0.8934 - val_loss: 0.7485 - val_mean_squared_error: 0.6573\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.8091 - mean_squared_error: 0.7179 - val_loss: 0.4336 - val_mean_squared_error: 0.3450\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.4759 - mean_squared_error: 0.3872 - val_loss: 0.1848 - val_mean_squared_error: 0.0971\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2008 - mean_squared_error: 0.1131 - val_loss: 0.1297 - val_mean_squared_error: 0.0411\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 46us/step - loss: 0.1182 - mean_squared_error: 0.0297 - val_loss: 0.2545 - val_mean_squared_error: 0.1632\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2221 - mean_squared_error: 0.1308 - val_loss: 0.4257 - val_mean_squared_error: 0.3340\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.3858 - mean_squared_error: 0.2941 - val_loss: 0.5097 - val_mean_squared_error: 0.4190\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.4762 - mean_squared_error: 0.3855 - val_loss: 0.4546 - val_mean_squared_error: 0.3637\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.4363 - mean_squared_error: 0.3454 - val_loss: 0.3069 - val_mean_squared_error: 0.2169\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3034 - mean_squared_error: 0.2134 - val_loss: 0.1620 - val_mean_squared_error: 0.0742\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1662 - mean_squared_error: 0.0784 - val_loss: 0.1002 - val_mean_squared_error: 0.0152\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1035 - mean_squared_error: 0.0185 - val_loss: 0.1292 - val_mean_squared_error: 0.0487\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1269 - mean_squared_error: 0.0464 - val_loss: 0.2031 - val_mean_squared_error: 0.1283\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1958 - mean_squared_error: 0.1210 - val_loss: 0.2562 - val_mean_squared_error: 0.1864\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.2483 - mean_squared_error: 0.1786 - val_loss: 0.2473 - val_mean_squared_error: 0.1823\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.2434 - mean_squared_error: 0.1784 - val_loss: 0.1822 - val_mean_squared_error: 0.1234\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1835 - mean_squared_error: 0.1247 - val_loss: 0.1055 - val_mean_squared_error: 0.0520\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1090 - mean_squared_error: 0.0555 - val_loss: 0.0593 - val_mean_squared_error: 0.0126\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0598 - mean_squared_error: 0.0131 - val_loss: 0.0626 - val_mean_squared_error: 0.0217\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0560 - mean_squared_error: 0.0151 - val_loss: 0.1006 - val_mean_squared_error: 0.0633\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0861 - mean_squared_error: 0.0487 - val_loss: 0.1361 - val_mean_squared_error: 0.1029\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1165 - mean_squared_error: 0.0833 - val_loss: 0.1425 - val_mean_squared_error: 0.1130\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1227 - mean_squared_error: 0.0932 - val_loss: 0.1178 - val_mean_squared_error: 0.0888\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1019 - mean_squared_error: 0.0729 - val_loss: 0.0757 - val_mean_squared_error: 0.0483\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0658 - mean_squared_error: 0.0384 - val_loss: 0.0421 - val_mean_squared_error: 0.0165\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0378 - mean_squared_error: 0.0122 - val_loss: 0.0339 - val_mean_squared_error: 0.0078\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0335 - mean_squared_error: 0.0075 - val_loss: 0.0470 - val_mean_squared_error: 0.0196\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0486 - mean_squared_error: 0.0213 - val_loss: 0.0639 - val_mean_squared_error: 0.0367\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0661 - mean_squared_error: 0.0388 - val_loss: 0.0713 - val_mean_squared_error: 0.0442\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0732 - mean_squared_error: 0.0461 - val_loss: 0.0626 - val_mean_squared_error: 0.0372\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0640 - mean_squared_error: 0.0386 - val_loss: 0.0460 - val_mean_squared_error: 0.0220\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0471 - mean_squared_error: 0.0230 - val_loss: 0.0338 - val_mean_squared_error: 0.0095\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0346 - mean_squared_error: 0.0103 - val_loss: 0.0317 - val_mean_squared_error: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.1338 - mean_squared_error: 0.0305 - val_loss: 4.4890 - val_mean_squared_error: 4.3744\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 4.7479 - mean_squared_error: 4.6333 - val_loss: 0.3877 - val_mean_squared_error: 0.2875\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.4005 - mean_squared_error: 0.3003 - val_loss: 0.9879 - val_mean_squared_error: 0.9084\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.0315 - mean_squared_error: 0.9520 - val_loss: 2.4546 - val_mean_squared_error: 2.3707\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 12us/step - loss: 2.5212 - mean_squared_error: 2.4373 - val_loss: 1.8887 - val_mean_squared_error: 1.8010\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.8983 - mean_squared_error: 1.8105 - val_loss: 0.6092 - val_mean_squared_error: 0.5251\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.5843 - mean_squared_error: 0.5002 - val_loss: 0.1032 - val_mean_squared_error: 0.0261\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1091 - mean_squared_error: 0.0319 - val_loss: 0.5723 - val_mean_squared_error: 0.5037\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.6300 - mean_squared_error: 0.5614 - val_loss: 1.0994 - val_mean_squared_error: 1.0306\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 1.1433 - mean_squared_error: 1.0746 - val_loss: 1.0437 - val_mean_squared_error: 0.9824\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.0336 - mean_squared_error: 0.9723 - val_loss: 0.5805 - val_mean_squared_error: 0.5307\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.5431 - mean_squared_error: 0.4934 - val_loss: 0.1789 - val_mean_squared_error: 0.1321\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1586 - mean_squared_error: 0.1118 - val_loss: 0.1069 - val_mean_squared_error: 0.0604\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1168 - mean_squared_error: 0.0704 - val_loss: 0.3010 - val_mean_squared_error: 0.2574\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.3200 - mean_squared_error: 0.2764 - val_loss: 0.5066 - val_mean_squared_error: 0.4686\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.5061 - mean_squared_error: 0.4681 - val_loss: 0.5479 - val_mean_squared_error: 0.5050\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.5176 - mean_squared_error: 0.4747 - val_loss: 0.4087 - val_mean_squared_error: 0.3617\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.3632 - mean_squared_error: 0.3163 - val_loss: 0.2101 - val_mean_squared_error: 0.1650\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1742 - mean_squared_error: 0.1291 - val_loss: 0.0871 - val_mean_squared_error: 0.0477\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0761 - mean_squared_error: 0.0367 - val_loss: 0.0958 - val_mean_squared_error: 0.0600\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1057 - mean_squared_error: 0.0699 - val_loss: 0.1827 - val_mean_squared_error: 0.1484\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.1966 - mean_squared_error: 0.1623 - val_loss: 0.2521 - val_mean_squared_error: 0.2222\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2549 - mean_squared_error: 0.2250 - val_loss: 0.2438 - val_mean_squared_error: 0.2205\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.2336 - mean_squared_error: 0.2103 - val_loss: 0.1750 - val_mean_squared_error: 0.1503\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1617 - mean_squared_error: 0.1371 - val_loss: 0.0916 - val_mean_squared_error: 0.0642\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0862 - mean_squared_error: 0.0588 - val_loss: 0.0462 - val_mean_squared_error: 0.0213\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0496 - mean_squared_error: 0.0247 - val_loss: 0.0556 - val_mean_squared_error: 0.0384\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0597 - mean_squared_error: 0.0425 - val_loss: 0.1036 - val_mean_squared_error: 0.0885\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.0989 - mean_squared_error: 0.0837 - val_loss: 0.1459 - val_mean_squared_error: 0.1263\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1294 - mean_squared_error: 0.1097 - val_loss: 0.1436 - val_mean_squared_error: 0.1238\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1202 - mean_squared_error: 0.1003 - val_loss: 0.1024 - val_mean_squared_error: 0.0856\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0812 - mean_squared_error: 0.0643 - val_loss: 0.0593 - val_mean_squared_error: 0.0399\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0471 - mean_squared_error: 0.0277 - val_loss: 0.0352 - val_mean_squared_error: 0.0155\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0325 - mean_squared_error: 0.0128 - val_loss: 0.0399 - val_mean_squared_error: 0.0214\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0422 - mean_squared_error: 0.0236 - val_loss: 0.0586 - val_mean_squared_error: 0.0430\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0606 - mean_squared_error: 0.0450 - val_loss: 0.0749 - val_mean_squared_error: 0.0569\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0747 - mean_squared_error: 0.0566 - val_loss: 0.0730 - val_mean_squared_error: 0.0502\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0718 - mean_squared_error: 0.0490 - val_loss: 0.0505 - val_mean_squared_error: 0.0289\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0504 - mean_squared_error: 0.0288 - val_loss: 0.0260 - val_mean_squared_error: 0.0107\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0270 - mean_squared_error: 0.0117 - val_loss: 0.0232 - val_mean_squared_error: 0.0082\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.0233 - mean_squared_error: 0.0083 - val_loss: 0.0381 - val_mean_squared_error: 0.0208\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0345 - mean_squared_error: 0.0173 - val_loss: 0.0535 - val_mean_squared_error: 0.0363\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0458 - mean_squared_error: 0.0286 - val_loss: 0.0555 - val_mean_squared_error: 0.0413\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.0459 - mean_squared_error: 0.0317 - val_loss: 0.0482 - val_mean_squared_error: 0.0328\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0398 - mean_squared_error: 0.0244 - val_loss: 0.0351 - val_mean_squared_error: 0.0181\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.0301 - mean_squared_error: 0.0131 - val_loss: 0.0228 - val_mean_squared_error: 0.0079\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0214 - mean_squared_error: 0.0065 - val_loss: 0.0179 - val_mean_squared_error: 0.0077\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0186 - mean_squared_error: 0.0084 - val_loss: 0.0260 - val_mean_squared_error: 0.0143\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0270 - mean_squared_error: 0.0153 - val_loss: 0.0321 - val_mean_squared_error: 0.0190\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0328 - mean_squared_error: 0.0197 - val_loss: 0.0307 - val_mean_squared_error: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.3997 - mean_squared_error: 0.0959 - val_loss: 6.1888 - val_mean_squared_error: 5.8863\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 6.0100 - mean_squared_error: 5.7075 - val_loss: 0.4312 - val_mean_squared_error: 0.1279\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.4427 - mean_squared_error: 0.1395 - val_loss: 3.0743 - val_mean_squared_error: 2.7783\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.8451 - mean_squared_error: 2.5491 - val_loss: 4.1472 - val_mean_squared_error: 3.8535\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8756 - mean_squared_error: 3.5819 - val_loss: 1.5258 - val_mean_squared_error: 1.2365\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 1.4044 - mean_squared_error: 1.1151 - val_loss: 0.3061 - val_mean_squared_error: 0.0230\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.3080 - mean_squared_error: 0.0249 - val_loss: 1.3959 - val_mean_squared_error: 1.1149\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 1.4385 - mean_squared_error: 1.1575 - val_loss: 2.2414 - val_mean_squared_error: 1.9668\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2752 - mean_squared_error: 2.0005 - val_loss: 1.5297 - val_mean_squared_error: 1.2544\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 13us/step - loss: 1.5458 - mean_squared_error: 1.2705 - val_loss: 0.4832 - val_mean_squared_error: 0.2103\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.4857 - mean_squared_error: 0.2129 - val_loss: 0.3788 - val_mean_squared_error: 0.1121\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.3762 - mean_squared_error: 0.1096 - val_loss: 1.0405 - val_mean_squared_error: 0.7814\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.0249 - mean_squared_error: 0.7659 - val_loss: 1.3877 - val_mean_squared_error: 1.1344\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.3483 - mean_squared_error: 1.0951 - val_loss: 1.0015 - val_mean_squared_error: 0.7539\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.9483 - mean_squared_error: 0.7007 - val_loss: 0.4285 - val_mean_squared_error: 0.1821\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.3927 - mean_squared_error: 0.1462 - val_loss: 0.2914 - val_mean_squared_error: 0.0460\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2924 - mean_squared_error: 0.0470 - val_loss: 0.5991 - val_mean_squared_error: 0.3545\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.6263 - mean_squared_error: 0.3816 - val_loss: 0.8357 - val_mean_squared_error: 0.5947\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.8594 - mean_squared_error: 0.6184 - val_loss: 0.6969 - val_mean_squared_error: 0.4592\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.6991 - mean_squared_error: 0.4614 - val_loss: 0.3793 - val_mean_squared_error: 0.1457\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.3719 - mean_squared_error: 0.1383 - val_loss: 0.2516 - val_mean_squared_error: 0.0205\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2537 - mean_squared_error: 0.0226 - val_loss: 0.3921 - val_mean_squared_error: 0.1632\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.4043 - mean_squared_error: 0.1754 - val_loss: 0.5674 - val_mean_squared_error: 0.3424\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.5678 - mean_squared_error: 0.3428 - val_loss: 0.5541 - val_mean_squared_error: 0.3323\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.5288 - mean_squared_error: 0.3070 - val_loss: 0.3875 - val_mean_squared_error: 0.1681\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.3512 - mean_squared_error: 0.1318 - val_loss: 0.2631 - val_mean_squared_error: 0.0458\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2425 - mean_squared_error: 0.0252 - val_loss: 0.2889 - val_mean_squared_error: 0.0726\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.2924 - mean_squared_error: 0.0762 - val_loss: 0.3804 - val_mean_squared_error: 0.1670\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.3913 - mean_squared_error: 0.1779 - val_loss: 0.4025 - val_mean_squared_error: 0.1917\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.4010 - mean_squared_error: 0.1901 - val_loss: 0.3259 - val_mean_squared_error: 0.1188\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.3137 - mean_squared_error: 0.1066 - val_loss: 0.2424 - val_mean_squared_error: 0.0384\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.2363 - mean_squared_error: 0.0323 - val_loss: 0.2358 - val_mean_squared_error: 0.0347\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2409 - mean_squared_error: 0.0397 - val_loss: 0.2894 - val_mean_squared_error: 0.0911\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.2902 - mean_squared_error: 0.0918 - val_loss: 0.3290 - val_mean_squared_error: 0.1314\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3100 - mean_squared_error: 0.1124 - val_loss: 0.3070 - val_mean_squared_error: 0.1114\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2743 - mean_squared_error: 0.0787 - val_loss: 0.2516 - val_mean_squared_error: 0.0596\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.2259 - mean_squared_error: 0.0338 - val_loss: 0.2211 - val_mean_squared_error: 0.0320\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2131 - mean_squared_error: 0.0240 - val_loss: 0.2336 - val_mean_squared_error: 0.0465\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.2342 - mean_squared_error: 0.0471 - val_loss: 0.2571 - val_mean_squared_error: 0.0699\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.2526 - mean_squared_error: 0.0654 - val_loss: 0.2498 - val_mean_squared_error: 0.0646\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.2404 - mean_squared_error: 0.0552 - val_loss: 0.2164 - val_mean_squared_error: 0.0347\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.2116 - mean_squared_error: 0.0299 - val_loss: 0.1951 - val_mean_squared_error: 0.0162\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1962 - mean_squared_error: 0.0173 - val_loss: 0.2078 - val_mean_squared_error: 0.0308\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2040 - mean_squared_error: 0.0270 - val_loss: 0.2347 - val_mean_squared_error: 0.0579\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.2176 - mean_squared_error: 0.0408 - val_loss: 0.2393 - val_mean_squared_error: 0.0633\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2151 - mean_squared_error: 0.0391 - val_loss: 0.2159 - val_mean_squared_error: 0.0412\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1980 - mean_squared_error: 0.0233 - val_loss: 0.1918 - val_mean_squared_error: 0.0187\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.1854 - mean_squared_error: 0.0123 - val_loss: 0.1898 - val_mean_squared_error: 0.0180\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1888 - mean_squared_error: 0.0170 - val_loss: 0.1996 - val_mean_squared_error: 0.0292\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1976 - mean_squared_error: 0.0272 - val_loss: 0.1982 - val_mean_squared_error: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.2650 - mean_squared_error: 0.0214 - val_loss: 11.1345 - val_mean_squared_error: 10.8844\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 13.6551 - mean_squared_error: 13.4050 - val_loss: 1.1261 - val_mean_squared_error: 0.8731\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 1.2156 - mean_squared_error: 0.9625 - val_loss: 2.5225 - val_mean_squared_error: 2.2801\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.8081 - mean_squared_error: 2.5657 - val_loss: 5.7468 - val_mean_squared_error: 5.5021\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.9271 - mean_squared_error: 6.6824 - val_loss: 4.5660 - val_mean_squared_error: 4.3174\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.4324 - mean_squared_error: 5.1838 - val_loss: 1.9726 - val_mean_squared_error: 1.7239\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.0681 - mean_squared_error: 1.8194 - val_loss: 0.9845 - val_mean_squared_error: 0.7400\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.7849 - mean_squared_error: 0.5404 - val_loss: 1.6708 - val_mean_squared_error: 1.4259\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 1.8304 - mean_squared_error: 1.5855 - val_loss: 2.4217 - val_mean_squared_error: 2.1719\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 2.9901 - mean_squared_error: 2.7403 - val_loss: 2.2560 - val_mean_squared_error: 2.0003\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 2.7609 - mean_squared_error: 2.5051 - val_loss: 1.5850 - val_mean_squared_error: 1.3297\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.7130 - mean_squared_error: 1.4578 - val_loss: 1.0916 - val_mean_squared_error: 0.8407\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.9462 - mean_squared_error: 0.6953 - val_loss: 0.9407 - val_mean_squared_error: 0.6944\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8124 - mean_squared_error: 0.5661 - val_loss: 0.9486 - val_mean_squared_error: 0.7068\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.0178 - mean_squared_error: 0.7760 - val_loss: 0.9973 - val_mean_squared_error: 0.7602\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.1873 - mean_squared_error: 0.9502 - val_loss: 1.0567 - val_mean_squared_error: 0.8222\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 1.1653 - mean_squared_error: 0.9308 - val_loss: 1.0715 - val_mean_squared_error: 0.8395\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.0121 - mean_squared_error: 0.7801 - val_loss: 0.9570 - val_mean_squared_error: 0.7281\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.8135 - mean_squared_error: 0.5846 - val_loss: 0.6943 - val_mean_squared_error: 0.4709\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.6050 - mean_squared_error: 0.3816 - val_loss: 0.4477 - val_mean_squared_error: 0.2290\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.4563 - mean_squared_error: 0.2377 - val_loss: 0.4311 - val_mean_squared_error: 0.2186\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.4569 - mean_squared_error: 0.2443 - val_loss: 0.6714 - val_mean_squared_error: 0.4622\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.6075 - mean_squared_error: 0.3983 - val_loss: 0.9164 - val_mean_squared_error: 0.7103\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.7450 - mean_squared_error: 0.5389 - val_loss: 0.8937 - val_mean_squared_error: 0.6891\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.6993 - mean_squared_error: 0.4946 - val_loss: 0.5969 - val_mean_squared_error: 0.3959\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.4742 - mean_squared_error: 0.2732 - val_loss: 0.2883 - val_mean_squared_error: 0.0903\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2581 - mean_squared_error: 0.0601 - val_loss: 0.2175 - val_mean_squared_error: 0.0212\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.2250 - mean_squared_error: 0.0287 - val_loss: 0.3794 - val_mean_squared_error: 0.1853\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.3619 - mean_squared_error: 0.1678 - val_loss: 0.5496 - val_mean_squared_error: 0.3596\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.4950 - mean_squared_error: 0.3050 - val_loss: 0.5439 - val_mean_squared_error: 0.3564\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.4872 - mean_squared_error: 0.2998 - val_loss: 0.3870 - val_mean_squared_error: 0.2008\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.3622 - mean_squared_error: 0.1759 - val_loss: 0.2414 - val_mean_squared_error: 0.0569\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.2447 - mean_squared_error: 0.0602 - val_loss: 0.2232 - val_mean_squared_error: 0.0393\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.2206 - mean_squared_error: 0.0367 - val_loss: 0.2944 - val_mean_squared_error: 0.1113\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.2617 - mean_squared_error: 0.0786 - val_loss: 0.3548 - val_mean_squared_error: 0.1742\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2995 - mean_squared_error: 0.1189 - val_loss: 0.3532 - val_mean_squared_error: 0.1759\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3026 - mean_squared_error: 0.1253 - val_loss: 0.3121 - val_mean_squared_error: 0.1371\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2853 - mean_squared_error: 0.1103 - val_loss: 0.2645 - val_mean_squared_error: 0.0921\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2596 - mean_squared_error: 0.0871 - val_loss: 0.2252 - val_mean_squared_error: 0.0538\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.2278 - mean_squared_error: 0.0565 - val_loss: 0.1976 - val_mean_squared_error: 0.0274\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1987 - mean_squared_error: 0.0284 - val_loss: 0.1915 - val_mean_squared_error: 0.0236\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1939 - mean_squared_error: 0.0260 - val_loss: 0.2073 - val_mean_squared_error: 0.0443\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2167 - mean_squared_error: 0.0536 - val_loss: 0.2252 - val_mean_squared_error: 0.0643\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2410 - mean_squared_error: 0.0801 - val_loss: 0.2153 - val_mean_squared_error: 0.0571\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2301 - mean_squared_error: 0.0719 - val_loss: 0.1865 - val_mean_squared_error: 0.0281\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1942 - mean_squared_error: 0.0358 - val_loss: 0.1657 - val_mean_squared_error: 0.0083\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1665 - mean_squared_error: 0.0091 - val_loss: 0.1718 - val_mean_squared_error: 0.0155\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1703 - mean_squared_error: 0.0141 - val_loss: 0.1914 - val_mean_squared_error: 0.0368\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1897 - mean_squared_error: 0.0351 - val_loss: 0.2007 - val_mean_squared_error: 0.0487\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.1963 - mean_squared_error: 0.0444 - val_loss: 0.1945 - val_mean_squared_error: 0.0458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.2661 - mean_squared_error: 0.0881 - val_loss: 9.3429 - val_mean_squared_error: 9.1564\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 16us/step - loss: 10.0827 - mean_squared_error: 9.8962 - val_loss: 0.7909 - val_mean_squared_error: 0.6043\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8492 - mean_squared_error: 0.6626 - val_loss: 2.1221 - val_mean_squared_error: 1.9492\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 2.2914 - mean_squared_error: 2.1185 - val_loss: 5.1938 - val_mean_squared_error: 5.0219\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6379 - mean_squared_error: 5.4660 - val_loss: 3.8237 - val_mean_squared_error: 3.6442\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 4.1493 - mean_squared_error: 3.9698 - val_loss: 1.1957 - val_mean_squared_error: 1.0190\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 1.2817 - mean_squared_error: 1.1050 - val_loss: 0.1865 - val_mean_squared_error: 0.0176\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.1884 - mean_squared_error: 0.0194 - val_loss: 1.2668 - val_mean_squared_error: 1.1038\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 1.3503 - mean_squared_error: 1.1874 - val_loss: 2.5431 - val_mean_squared_error: 2.3773\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7150 - mean_squared_error: 2.5492 - val_loss: 2.4276 - val_mean_squared_error: 2.2638\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.5863 - mean_squared_error: 2.4225 - val_loss: 1.2824 - val_mean_squared_error: 1.1227\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3555 - mean_squared_error: 1.1957 - val_loss: 0.3233 - val_mean_squared_error: 0.1633\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.3303 - mean_squared_error: 0.1703 - val_loss: 0.2764 - val_mean_squared_error: 0.1141\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.2825 - mean_squared_error: 0.1203 - val_loss: 0.8839 - val_mean_squared_error: 0.7233\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.9415 - mean_squared_error: 0.7808 - val_loss: 1.3662 - val_mean_squared_error: 1.2054\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.4798 - mean_squared_error: 1.3190 - val_loss: 1.2510 - val_mean_squared_error: 1.0914\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 1.3793 - mean_squared_error: 1.2197 - val_loss: 0.7124 - val_mean_squared_error: 0.5595\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.8026 - mean_squared_error: 0.6497 - val_loss: 0.2551 - val_mean_squared_error: 0.1077\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.2831 - mean_squared_error: 0.1357 - val_loss: 0.2050 - val_mean_squared_error: 0.0644\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1949 - mean_squared_error: 0.0542 - val_loss: 0.4866 - val_mean_squared_error: 0.3540\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.4866 - mean_squared_error: 0.3539 - val_loss: 0.7581 - val_mean_squared_error: 0.6316\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.7933 - mean_squared_error: 0.6669 - val_loss: 0.7506 - val_mean_squared_error: 0.6286\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.8025 - mean_squared_error: 0.6805 - val_loss: 0.4868 - val_mean_squared_error: 0.3704\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.5204 - mean_squared_error: 0.4040 - val_loss: 0.2153 - val_mean_squared_error: 0.1024\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.2196 - mean_squared_error: 0.1067 - val_loss: 0.1439 - val_mean_squared_error: 0.0304\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.1412 - mean_squared_error: 0.0277 - val_loss: 0.2623 - val_mean_squared_error: 0.1506\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.2825 - mean_squared_error: 0.1708 - val_loss: 0.4036 - val_mean_squared_error: 0.2954\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.4532 - mean_squared_error: 0.3450 - val_loss: 0.4192 - val_mean_squared_error: 0.3121\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.4773 - mean_squared_error: 0.3703 - val_loss: 0.2960 - val_mean_squared_error: 0.1913\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3354 - mean_squared_error: 0.2306 - val_loss: 0.1541 - val_mean_squared_error: 0.0542\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1656 - mean_squared_error: 0.0657 - val_loss: 0.1111 - val_mean_squared_error: 0.0175\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.1084 - mean_squared_error: 0.0149 - val_loss: 0.1797 - val_mean_squared_error: 0.0916\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1837 - mean_squared_error: 0.0956 - val_loss: 0.2656 - val_mean_squared_error: 0.1811\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.2838 - mean_squared_error: 0.1994 - val_loss: 0.2707 - val_mean_squared_error: 0.1887\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 44us/step - loss: 0.2929 - mean_squared_error: 0.2109 - val_loss: 0.1890 - val_mean_squared_error: 0.1103\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2016 - mean_squared_error: 0.1229 - val_loss: 0.1045 - val_mean_squared_error: 0.0283\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1059 - mean_squared_error: 0.0298 - val_loss: 0.0873 - val_mean_squared_error: 0.0137\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0874 - mean_squared_error: 0.0138 - val_loss: 0.1311 - val_mean_squared_error: 0.0609\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1391 - mean_squared_error: 0.0689 - val_loss: 0.1715 - val_mean_squared_error: 0.1051\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.1859 - mean_squared_error: 0.1195 - val_loss: 0.1618 - val_mean_squared_error: 0.0962\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1736 - mean_squared_error: 0.1080 - val_loss: 0.1091 - val_mean_squared_error: 0.0467\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.1130 - mean_squared_error: 0.0506 - val_loss: 0.0675 - val_mean_squared_error: 0.0108\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0672 - mean_squared_error: 0.0105 - val_loss: 0.0701 - val_mean_squared_error: 0.0189\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0732 - mean_squared_error: 0.0219 - val_loss: 0.0992 - val_mean_squared_error: 0.0511\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1088 - mean_squared_error: 0.0607 - val_loss: 0.1115 - val_mean_squared_error: 0.0648\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.1228 - mean_squared_error: 0.0761 - val_loss: 0.0921 - val_mean_squared_error: 0.0461\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0980 - mean_squared_error: 0.0519 - val_loss: 0.0619 - val_mean_squared_error: 0.0186\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0610 - mean_squared_error: 0.0177 - val_loss: 0.0541 - val_mean_squared_error: 0.0118\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0512 - mean_squared_error: 0.0089 - val_loss: 0.0678 - val_mean_squared_error: 0.0257\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0682 - mean_squared_error: 0.0261 - val_loss: 0.0785 - val_mean_squared_error: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.0321 - mean_squared_error: 0.0077 - val_loss: 0.5303 - val_mean_squared_error: 0.5076\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.5661 - mean_squared_error: 0.5434 - val_loss: 0.0301 - val_mean_squared_error: 0.0064\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0298 - mean_squared_error: 0.0061 - val_loss: 0.3370 - val_mean_squared_error: 0.3187\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3381 - mean_squared_error: 0.3198 - val_loss: 0.3519 - val_mean_squared_error: 0.3289\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.3450 - mean_squared_error: 0.3219 - val_loss: 0.1224 - val_mean_squared_error: 0.0980\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1117 - mean_squared_error: 0.0873 - val_loss: 0.0326 - val_mean_squared_error: 0.0124\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0324 - mean_squared_error: 0.0122 - val_loss: 0.1265 - val_mean_squared_error: 0.1131\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1361 - mean_squared_error: 0.1227 - val_loss: 0.1973 - val_mean_squared_error: 0.1880\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.2054 - mean_squared_error: 0.1961 - val_loss: 0.1467 - val_mean_squared_error: 0.1335\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1480 - mean_squared_error: 0.1349 - val_loss: 0.0531 - val_mean_squared_error: 0.0389\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0529 - mean_squared_error: 0.0387 - val_loss: 0.0224 - val_mean_squared_error: 0.0105\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0240 - mean_squared_error: 0.0122 - val_loss: 0.0734 - val_mean_squared_error: 0.0619\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0715 - mean_squared_error: 0.0601 - val_loss: 0.1259 - val_mean_squared_error: 0.1147\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1152 - mean_squared_error: 0.1041 - val_loss: 0.1156 - val_mean_squared_error: 0.1049\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1003 - mean_squared_error: 0.0896 - val_loss: 0.0603 - val_mean_squared_error: 0.0496\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0495 - mean_squared_error: 0.0388 - val_loss: 0.0212 - val_mean_squared_error: 0.0104\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0185 - mean_squared_error: 0.0077 - val_loss: 0.0303 - val_mean_squared_error: 0.0194\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0321 - mean_squared_error: 0.0211 - val_loss: 0.0608 - val_mean_squared_error: 0.0508\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0623 - mean_squared_error: 0.0523 - val_loss: 0.0700 - val_mean_squared_error: 0.0607\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0703 - mean_squared_error: 0.0611 - val_loss: 0.0476 - val_mean_squared_error: 0.0387\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0482 - mean_squared_error: 0.0393 - val_loss: 0.0206 - val_mean_squared_error: 0.0118\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0215 - mean_squared_error: 0.0127 - val_loss: 0.0176 - val_mean_squared_error: 0.0088\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 44us/step - loss: 0.0161 - mean_squared_error: 0.0073 - val_loss: 0.0374 - val_mean_squared_error: 0.0288\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0316 - mean_squared_error: 0.0231 - val_loss: 0.0550 - val_mean_squared_error: 0.0457\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0464 - mean_squared_error: 0.0371 - val_loss: 0.0489 - val_mean_squared_error: 0.0398\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0416 - mean_squared_error: 0.0326 - val_loss: 0.0267 - val_mean_squared_error: 0.0195\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0233 - mean_squared_error: 0.0161 - val_loss: 0.0137 - val_mean_squared_error: 0.0066\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0136 - mean_squared_error: 0.0065 - val_loss: 0.0177 - val_mean_squared_error: 0.0104\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0187 - mean_squared_error: 0.0114 - val_loss: 0.0280 - val_mean_squared_error: 0.0200\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0293 - mean_squared_error: 0.0212 - val_loss: 0.0290 - val_mean_squared_error: 0.0219\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0305 - mean_squared_error: 0.0234 - val_loss: 0.0212 - val_mean_squared_error: 0.0148\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0224 - mean_squared_error: 0.0160 - val_loss: 0.0153 - val_mean_squared_error: 0.0080\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0151 - mean_squared_error: 0.0078 - val_loss: 0.0168 - val_mean_squared_error: 0.0087\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0151 - mean_squared_error: 0.0070 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0206 - mean_squared_error: 0.0126 - val_loss: 0.0248 - val_mean_squared_error: 0.0185\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.0228 - mean_squared_error: 0.0165 - val_loss: 0.0212 - val_mean_squared_error: 0.0152\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0199 - mean_squared_error: 0.0139 - val_loss: 0.0159 - val_mean_squared_error: 0.0091\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0150 - mean_squared_error: 0.0081 - val_loss: 0.0128 - val_mean_squared_error: 0.0066\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0123 - mean_squared_error: 0.0061 - val_loss: 0.0145 - val_mean_squared_error: 0.0087\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0148 - mean_squared_error: 0.0091 - val_loss: 0.0179 - val_mean_squared_error: 0.0112\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0187 - mean_squared_error: 0.0121 - val_loss: 0.0178 - val_mean_squared_error: 0.0103\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0186 - mean_squared_error: 0.0111 - val_loss: 0.0143 - val_mean_squared_error: 0.0074\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0147 - mean_squared_error: 0.0078 - val_loss: 0.0127 - val_mean_squared_error: 0.0064\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0124 - mean_squared_error: 0.0061 - val_loss: 0.0148 - val_mean_squared_error: 0.0089\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0135 - mean_squared_error: 0.0075 - val_loss: 0.0187 - val_mean_squared_error: 0.0117\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0166 - mean_squared_error: 0.0095 - val_loss: 0.0182 - val_mean_squared_error: 0.0113\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0162 - mean_squared_error: 0.0092 - val_loss: 0.0141 - val_mean_squared_error: 0.0084\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0129 - mean_squared_error: 0.0071 - val_loss: 0.0124 - val_mean_squared_error: 0.0064\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.0121 - mean_squared_error: 0.0061 - val_loss: 0.0138 - val_mean_squared_error: 0.0069\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 21us/step - loss: 0.0140 - mean_squared_error: 0.0070 - val_loss: 0.0141 - val_mean_squared_error: 0.0079\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.0316 - mean_squared_error: 0.0177 - val_loss: 0.5769 - val_mean_squared_error: 0.5411\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.5314 - mean_squared_error: 0.4956 - val_loss: 0.1261 - val_mean_squared_error: 0.0941\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1096 - mean_squared_error: 0.0777 - val_loss: 0.0702 - val_mean_squared_error: 0.0569\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0745 - mean_squared_error: 0.0613 - val_loss: 0.2729 - val_mean_squared_error: 0.2593\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2698 - mean_squared_error: 0.2561 - val_loss: 0.2528 - val_mean_squared_error: 0.2297\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.2460 - mean_squared_error: 0.2229 - val_loss: 0.0917 - val_mean_squared_error: 0.0716\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0910 - mean_squared_error: 0.0709 - val_loss: 0.0179 - val_mean_squared_error: 0.0067\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0177 - mean_squared_error: 0.0065 - val_loss: 0.0843 - val_mean_squared_error: 0.0731\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0755 - mean_squared_error: 0.0642 - val_loss: 0.1633 - val_mean_squared_error: 0.1478\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1466 - mean_squared_error: 0.1310 - val_loss: 0.1530 - val_mean_squared_error: 0.1374\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1363 - mean_squared_error: 0.1207 - val_loss: 0.0781 - val_mean_squared_error: 0.0683\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0679 - mean_squared_error: 0.0581 - val_loss: 0.0234 - val_mean_squared_error: 0.0134\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0207 - mean_squared_error: 0.0107 - val_loss: 0.0270 - val_mean_squared_error: 0.0137\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0281 - mean_squared_error: 0.0148 - val_loss: 0.0615 - val_mean_squared_error: 0.0494\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0628 - mean_squared_error: 0.0506 - val_loss: 0.0773 - val_mean_squared_error: 0.0703\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0782 - mean_squared_error: 0.0713 - val_loss: 0.0637 - val_mean_squared_error: 0.0551\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0653 - mean_squared_error: 0.0567 - val_loss: 0.0343 - val_mean_squared_error: 0.0233\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0361 - mean_squared_error: 0.0251 - val_loss: 0.0182 - val_mean_squared_error: 0.0074\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0177 - mean_squared_error: 0.0069 - val_loss: 0.0247 - val_mean_squared_error: 0.0177\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0206 - mean_squared_error: 0.0136 - val_loss: 0.0455 - val_mean_squared_error: 0.0379\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0395 - mean_squared_error: 0.0318 - val_loss: 0.0560 - val_mean_squared_error: 0.0464\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0507 - mean_squared_error: 0.0410 - val_loss: 0.0454 - val_mean_squared_error: 0.0361\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.0421 - mean_squared_error: 0.0328 - val_loss: 0.0232 - val_mean_squared_error: 0.0176\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0219 - mean_squared_error: 0.0163 - val_loss: 0.0138 - val_mean_squared_error: 0.0067\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0137 - mean_squared_error: 0.0066 - val_loss: 0.0190 - val_mean_squared_error: 0.0096\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0197 - mean_squared_error: 0.0103 - val_loss: 0.0281 - val_mean_squared_error: 0.0190\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0298 - mean_squared_error: 0.0207 - val_loss: 0.0285 - val_mean_squared_error: 0.0232\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0307 - mean_squared_error: 0.0254 - val_loss: 0.0236 - val_mean_squared_error: 0.0181\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0252 - mean_squared_error: 0.0198 - val_loss: 0.0178 - val_mean_squared_error: 0.0096\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0185 - mean_squared_error: 0.0104 - val_loss: 0.0142 - val_mean_squared_error: 0.0063\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0142 - mean_squared_error: 0.0063 - val_loss: 0.0148 - val_mean_squared_error: 0.0103\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0140 - mean_squared_error: 0.0095 - val_loss: 0.0230 - val_mean_squared_error: 0.0170\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0211 - mean_squared_error: 0.0150 - val_loss: 0.0278 - val_mean_squared_error: 0.0193\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0249 - mean_squared_error: 0.0164 - val_loss: 0.0233 - val_mean_squared_error: 0.0154\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0140 - val_mean_squared_error: 0.0094\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 49us/step - loss: 0.0122 - mean_squared_error: 0.0076 - val_loss: 0.0121 - val_mean_squared_error: 0.0067\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 52us/step - loss: 0.0116 - mean_squared_error: 0.0062 - val_loss: 0.0159 - val_mean_squared_error: 0.0083\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0179 - val_mean_squared_error: 0.0108\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0188 - mean_squared_error: 0.0116 - val_loss: 0.0142 - val_mean_squared_error: 0.0106\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0151 - mean_squared_error: 0.0115 - val_loss: 0.0136 - val_mean_squared_error: 0.0082\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0141 - mean_squared_error: 0.0086 - val_loss: 0.0144 - val_mean_squared_error: 0.0064\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0142 - mean_squared_error: 0.0063 - val_loss: 0.0151 - val_mean_squared_error: 0.0076\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0146 - val_mean_squared_error: 0.0102\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0127 - mean_squared_error: 0.0084 - val_loss: 0.0170 - val_mean_squared_error: 0.0114\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0150 - mean_squared_error: 0.0094 - val_loss: 0.0176 - val_mean_squared_error: 0.0099\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0162 - mean_squared_error: 0.0085 - val_loss: 0.0149 - val_mean_squared_error: 0.0075\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0142 - mean_squared_error: 0.0068 - val_loss: 0.0108 - val_mean_squared_error: 0.0063\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0106 - mean_squared_error: 0.0061 - val_loss: 0.0127 - val_mean_squared_error: 0.0068\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0128 - mean_squared_error: 0.0069 - val_loss: 0.0157 - val_mean_squared_error: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0160 - mean_squared_error: 0.0079 - val_loss: 0.0152 - val_mean_squared_error: 0.0076\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 4s 16ms/step - loss: 0.1957 - mean_squared_error: 0.0274 - val_loss: 1.1347 - val_mean_squared_error: 0.9588\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.7793 - mean_squared_error: 0.6034 - val_loss: 0.3249 - val_mean_squared_error: 0.1512\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.3483 - mean_squared_error: 0.1746 - val_loss: 0.4616 - val_mean_squared_error: 0.2943\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3806 - mean_squared_error: 0.2134 - val_loss: 0.6082 - val_mean_squared_error: 0.4386\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 44us/step - loss: 0.5459 - mean_squared_error: 0.3763 - val_loss: 0.3490 - val_mean_squared_error: 0.1781\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.3382 - mean_squared_error: 0.1673 - val_loss: 0.1777 - val_mean_squared_error: 0.0109\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1767 - mean_squared_error: 0.0099 - val_loss: 0.3329 - val_mean_squared_error: 0.1720\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.3100 - mean_squared_error: 0.1492 - val_loss: 0.4355 - val_mean_squared_error: 0.2796\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.3760 - mean_squared_error: 0.2200 - val_loss: 0.3515 - val_mean_squared_error: 0.1939\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.2841 - mean_squared_error: 0.1264 - val_loss: 0.2411 - val_mean_squared_error: 0.0847\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2093 - mean_squared_error: 0.0528 - val_loss: 0.2004 - val_mean_squared_error: 0.0459\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2021 - mean_squared_error: 0.0476 - val_loss: 0.2360 - val_mean_squared_error: 0.0822\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2263 - mean_squared_error: 0.0725 - val_loss: 0.2952 - val_mean_squared_error: 0.1408\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.2588 - mean_squared_error: 0.1045 - val_loss: 0.2828 - val_mean_squared_error: 0.1301\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.2510 - mean_squared_error: 0.0983 - val_loss: 0.1967 - val_mean_squared_error: 0.0477\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1904 - mean_squared_error: 0.0414 - val_loss: 0.1584 - val_mean_squared_error: 0.0103\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1571 - mean_squared_error: 0.0091 - val_loss: 0.2153 - val_mean_squared_error: 0.0681\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1900 - mean_squared_error: 0.0429 - val_loss: 0.2669 - val_mean_squared_error: 0.1218\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.2211 - mean_squared_error: 0.0760 - val_loss: 0.2380 - val_mean_squared_error: 0.0947\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.2011 - mean_squared_error: 0.0578 - val_loss: 0.1798 - val_mean_squared_error: 0.0380\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.1682 - mean_squared_error: 0.0264 - val_loss: 0.1572 - val_mean_squared_error: 0.0160\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1591 - mean_squared_error: 0.0179 - val_loss: 0.1659 - val_mean_squared_error: 0.0256\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1642 - mean_squared_error: 0.0240 - val_loss: 0.1802 - val_mean_squared_error: 0.0404\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1734 - mean_squared_error: 0.0336 - val_loss: 0.1830 - val_mean_squared_error: 0.0436\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1790 - mean_squared_error: 0.0396 - val_loss: 0.1660 - val_mean_squared_error: 0.0287\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1667 - mean_squared_error: 0.0293 - val_loss: 0.1452 - val_mean_squared_error: 0.0102\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1461 - mean_squared_error: 0.0110 - val_loss: 0.1452 - val_mean_squared_error: 0.0128\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1430 - mean_squared_error: 0.0105 - val_loss: 0.1627 - val_mean_squared_error: 0.0312\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1566 - mean_squared_error: 0.0251 - val_loss: 0.1691 - val_mean_squared_error: 0.0386\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1595 - mean_squared_error: 0.0289 - val_loss: 0.1576 - val_mean_squared_error: 0.0289\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1479 - mean_squared_error: 0.0192 - val_loss: 0.1450 - val_mean_squared_error: 0.0171\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1399 - mean_squared_error: 0.0121 - val_loss: 0.1387 - val_mean_squared_error: 0.0109\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1385 - mean_squared_error: 0.0108 - val_loss: 0.1390 - val_mean_squared_error: 0.0126\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.1391 - mean_squared_error: 0.0127 - val_loss: 0.1449 - val_mean_squared_error: 0.0196\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1423 - mean_squared_error: 0.0171 - val_loss: 0.1439 - val_mean_squared_error: 0.0199\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1411 - mean_squared_error: 0.0172 - val_loss: 0.1334 - val_mean_squared_error: 0.0107\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1329 - mean_squared_error: 0.0103 - val_loss: 0.1292 - val_mean_squared_error: 0.0075\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1285 - mean_squared_error: 0.0068 - val_loss: 0.1362 - val_mean_squared_error: 0.0155\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1315 - mean_squared_error: 0.0108 - val_loss: 0.1399 - val_mean_squared_error: 0.0211\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1325 - mean_squared_error: 0.0136 - val_loss: 0.1360 - val_mean_squared_error: 0.0176\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1303 - mean_squared_error: 0.0118 - val_loss: 0.1295 - val_mean_squared_error: 0.0116\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1274 - mean_squared_error: 0.0095 - val_loss: 0.1247 - val_mean_squared_error: 0.0080\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1244 - mean_squared_error: 0.0076 - val_loss: 0.1230 - val_mean_squared_error: 0.0079\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1225 - mean_squared_error: 0.0074 - val_loss: 0.1241 - val_mean_squared_error: 0.0104\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.1234 - mean_squared_error: 0.0097 - val_loss: 0.1233 - val_mean_squared_error: 0.0108\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1226 - mean_squared_error: 0.0102 - val_loss: 0.1202 - val_mean_squared_error: 0.0084\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1194 - mean_squared_error: 0.0075 - val_loss: 0.1183 - val_mean_squared_error: 0.0075\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.1173 - mean_squared_error: 0.0065 - val_loss: 0.1193 - val_mean_squared_error: 0.0094\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.1175 - mean_squared_error: 0.0076 - val_loss: 0.1202 - val_mean_squared_error: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1167 - mean_squared_error: 0.0081 - val_loss: 0.1196 - val_mean_squared_error: 0.0126\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.1848 - mean_squared_error: 0.0361 - val_loss: 2.1702 - val_mean_squared_error: 2.0022\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 9us/step - loss: 2.5115 - mean_squared_error: 2.3435 - val_loss: 0.3769 - val_mean_squared_error: 0.2135\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.4219 - mean_squared_error: 0.2585 - val_loss: 0.5923 - val_mean_squared_error: 0.4409\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6210 - mean_squared_error: 0.4695 - val_loss: 1.3690 - val_mean_squared_error: 1.2210\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 1.5475 - mean_squared_error: 1.3996 - val_loss: 1.0453 - val_mean_squared_error: 0.8933\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.1879 - mean_squared_error: 1.0359 - val_loss: 0.4212 - val_mean_squared_error: 0.2691\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.4364 - mean_squared_error: 0.2843 - val_loss: 0.2811 - val_mean_squared_error: 0.1340\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.2400 - mean_squared_error: 0.0929 - val_loss: 0.5608 - val_mean_squared_error: 0.4143\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.5732 - mean_squared_error: 0.4267 - val_loss: 0.7321 - val_mean_squared_error: 0.5847\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.8169 - mean_squared_error: 0.6694 - val_loss: 0.5904 - val_mean_squared_error: 0.4462\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6792 - mean_squared_error: 0.5351 - val_loss: 0.3391 - val_mean_squared_error: 0.1983\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3748 - mean_squared_error: 0.2340 - val_loss: 0.2338 - val_mean_squared_error: 0.0932\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.2252 - mean_squared_error: 0.0845 - val_loss: 0.3108 - val_mean_squared_error: 0.1708\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.3053 - mean_squared_error: 0.1653 - val_loss: 0.4089 - val_mean_squared_error: 0.2716\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.4363 - mean_squared_error: 0.2990 - val_loss: 0.4037 - val_mean_squared_error: 0.2705\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.4462 - mean_squared_error: 0.3129 - val_loss: 0.3240 - val_mean_squared_error: 0.1912\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.3424 - mean_squared_error: 0.2096 - val_loss: 0.2614 - val_mean_squared_error: 0.1293\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.2392 - mean_squared_error: 0.1070 - val_loss: 0.2652 - val_mean_squared_error: 0.1332\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.2240 - mean_squared_error: 0.0920 - val_loss: 0.2886 - val_mean_squared_error: 0.1586\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.2641 - mean_squared_error: 0.1342 - val_loss: 0.2769 - val_mean_squared_error: 0.1486\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.2834 - mean_squared_error: 0.1551 - val_loss: 0.2351 - val_mean_squared_error: 0.1067\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.2571 - mean_squared_error: 0.1287 - val_loss: 0.2037 - val_mean_squared_error: 0.0773\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.2154 - mean_squared_error: 0.0890 - val_loss: 0.2069 - val_mean_squared_error: 0.0834\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1995 - mean_squared_error: 0.0759 - val_loss: 0.2224 - val_mean_squared_error: 0.0989\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.2088 - mean_squared_error: 0.0853 - val_loss: 0.2116 - val_mean_squared_error: 0.0893\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.2084 - mean_squared_error: 0.0861 - val_loss: 0.1806 - val_mean_squared_error: 0.0604\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.1869 - mean_squared_error: 0.0668 - val_loss: 0.1653 - val_mean_squared_error: 0.0486\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.1649 - mean_squared_error: 0.0483 - val_loss: 0.1854 - val_mean_squared_error: 0.0715\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1655 - mean_squared_error: 0.0516 - val_loss: 0.2136 - val_mean_squared_error: 0.1002\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.1800 - mean_squared_error: 0.0667 - val_loss: 0.2079 - val_mean_squared_error: 0.0953\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1789 - mean_squared_error: 0.0663 - val_loss: 0.1654 - val_mean_squared_error: 0.0553\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1534 - mean_squared_error: 0.0433 - val_loss: 0.1287 - val_mean_squared_error: 0.0188\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1306 - mean_squared_error: 0.0207 - val_loss: 0.1289 - val_mean_squared_error: 0.0185\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.1324 - mean_squared_error: 0.0220 - val_loss: 0.1526 - val_mean_squared_error: 0.0433\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.1502 - mean_squared_error: 0.0409 - val_loss: 0.1616 - val_mean_squared_error: 0.0554\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.1564 - mean_squared_error: 0.0502 - val_loss: 0.1431 - val_mean_squared_error: 0.0380\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1412 - mean_squared_error: 0.0361 - val_loss: 0.1177 - val_mean_squared_error: 0.0135\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.1184 - mean_squared_error: 0.0142 - val_loss: 0.1152 - val_mean_squared_error: 0.0125\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.1113 - mean_squared_error: 0.0086 - val_loss: 0.1365 - val_mean_squared_error: 0.0359\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1230 - mean_squared_error: 0.0225 - val_loss: 0.1547 - val_mean_squared_error: 0.0547\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.1351 - mean_squared_error: 0.0352 - val_loss: 0.1464 - val_mean_squared_error: 0.0471\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1295 - mean_squared_error: 0.0302 - val_loss: 0.1208 - val_mean_squared_error: 0.0229\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.1122 - mean_squared_error: 0.0143 - val_loss: 0.1038 - val_mean_squared_error: 0.0078\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1024 - mean_squared_error: 0.0064 - val_loss: 0.1066 - val_mean_squared_error: 0.0114\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.1076 - mean_squared_error: 0.0125 - val_loss: 0.1156 - val_mean_squared_error: 0.0205\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1160 - mean_squared_error: 0.0210 - val_loss: 0.1136 - val_mean_squared_error: 0.0196\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.1140 - mean_squared_error: 0.0200 - val_loss: 0.1019 - val_mean_squared_error: 0.0109\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1031 - mean_squared_error: 0.0121 - val_loss: 0.0980 - val_mean_squared_error: 0.0071\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0985 - mean_squared_error: 0.0076 - val_loss: 0.1038 - val_mean_squared_error: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1011 - mean_squared_error: 0.0100 - val_loss: 0.1096 - val_mean_squared_error: 0.0203\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.0817 - mean_squared_error: 0.0416 - val_loss: 0.8483 - val_mean_squared_error: 0.8063\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.9278 - mean_squared_error: 0.8859 - val_loss: 0.0523 - val_mean_squared_error: 0.0075\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0530 - mean_squared_error: 0.0082 - val_loss: 0.4837 - val_mean_squared_error: 0.4449\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.5233 - mean_squared_error: 0.4846 - val_loss: 0.4530 - val_mean_squared_error: 0.4103\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.4886 - mean_squared_error: 0.4459 - val_loss: 0.1123 - val_mean_squared_error: 0.0717\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.1166 - mean_squared_error: 0.0760 - val_loss: 0.0908 - val_mean_squared_error: 0.0568\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0993 - mean_squared_error: 0.0653 - val_loss: 0.3043 - val_mean_squared_error: 0.2753\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.3310 - mean_squared_error: 0.3019 - val_loss: 0.2903 - val_mean_squared_error: 0.2651\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 11us/step - loss: 0.3069 - mean_squared_error: 0.2817 - val_loss: 0.1119 - val_mean_squared_error: 0.0831\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.1096 - mean_squared_error: 0.0808 - val_loss: 0.0456 - val_mean_squared_error: 0.0156\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0441 - mean_squared_error: 0.0140 - val_loss: 0.1401 - val_mean_squared_error: 0.1121\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.1522 - mean_squared_error: 0.1242 - val_loss: 0.2056 - val_mean_squared_error: 0.1791\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.2195 - mean_squared_error: 0.1930 - val_loss: 0.1385 - val_mean_squared_error: 0.1150\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1426 - mean_squared_error: 0.1191 - val_loss: 0.0454 - val_mean_squared_error: 0.0246\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0458 - mean_squared_error: 0.0250 - val_loss: 0.0448 - val_mean_squared_error: 0.0248\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0512 - mean_squared_error: 0.0312 - val_loss: 0.1115 - val_mean_squared_error: 0.0903\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.1195 - mean_squared_error: 0.0983 - val_loss: 0.1348 - val_mean_squared_error: 0.1131\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1337 - mean_squared_error: 0.1120 - val_loss: 0.0874 - val_mean_squared_error: 0.0655\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0786 - mean_squared_error: 0.0566 - val_loss: 0.0392 - val_mean_squared_error: 0.0180\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0338 - mean_squared_error: 0.0126 - val_loss: 0.0447 - val_mean_squared_error: 0.0254\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0475 - mean_squared_error: 0.0282 - val_loss: 0.0788 - val_mean_squared_error: 0.0603\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0837 - mean_squared_error: 0.0652 - val_loss: 0.0808 - val_mean_squared_error: 0.0637\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0822 - mean_squared_error: 0.0651 - val_loss: 0.0459 - val_mean_squared_error: 0.0311\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0460 - mean_squared_error: 0.0312 - val_loss: 0.0245 - val_mean_squared_error: 0.0090\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0261 - mean_squared_error: 0.0107 - val_loss: 0.0409 - val_mean_squared_error: 0.0257\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0404 - mean_squared_error: 0.0252 - val_loss: 0.0674 - val_mean_squared_error: 0.0528\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0602 - mean_squared_error: 0.0456 - val_loss: 0.0629 - val_mean_squared_error: 0.0487\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0526 - mean_squared_error: 0.0384 - val_loss: 0.0345 - val_mean_squared_error: 0.0208\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0285 - mean_squared_error: 0.0148 - val_loss: 0.0213 - val_mean_squared_error: 0.0087\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0211 - mean_squared_error: 0.0084 - val_loss: 0.0348 - val_mean_squared_error: 0.0224\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0361 - mean_squared_error: 0.0238 - val_loss: 0.0448 - val_mean_squared_error: 0.0324\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0453 - mean_squared_error: 0.0329 - val_loss: 0.0329 - val_mean_squared_error: 0.0200\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.0337 - mean_squared_error: 0.0207 - val_loss: 0.0190 - val_mean_squared_error: 0.0065\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0193 - mean_squared_error: 0.0068 - val_loss: 0.0270 - val_mean_squared_error: 0.0149\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0235 - mean_squared_error: 0.0114 - val_loss: 0.0412 - val_mean_squared_error: 0.0302\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 47us/step - loss: 0.0338 - mean_squared_error: 0.0227 - val_loss: 0.0379 - val_mean_squared_error: 0.0269\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0313 - mean_squared_error: 0.0204 - val_loss: 0.0227 - val_mean_squared_error: 0.0116\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0203 - mean_squared_error: 0.0092 - val_loss: 0.0175 - val_mean_squared_error: 0.0066\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0178 - mean_squared_error: 0.0069 - val_loss: 0.0233 - val_mean_squared_error: 0.0132\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0242 - mean_squared_error: 0.0141 - val_loss: 0.0250 - val_mean_squared_error: 0.0154\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0261 - mean_squared_error: 0.0165 - val_loss: 0.0198 - val_mean_squared_error: 0.0098\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0205 - mean_squared_error: 0.0105 - val_loss: 0.0178 - val_mean_squared_error: 0.0077\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0166 - mean_squared_error: 0.0065 - val_loss: 0.0224 - val_mean_squared_error: 0.0128\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0192 - mean_squared_error: 0.0096 - val_loss: 0.0246 - val_mean_squared_error: 0.0159\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0216 - mean_squared_error: 0.0129 - val_loss: 0.0200 - val_mean_squared_error: 0.0118\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0188 - mean_squared_error: 0.0106 - val_loss: 0.0147 - val_mean_squared_error: 0.0068\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0148 - mean_squared_error: 0.0068 - val_loss: 0.0142 - val_mean_squared_error: 0.0071\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0146 - mean_squared_error: 0.0075 - val_loss: 0.0179 - val_mean_squared_error: 0.0098\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0185 - mean_squared_error: 0.0104 - val_loss: 0.0182 - val_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0186 - mean_squared_error: 0.0096 - val_loss: 0.0147 - val_mean_squared_error: 0.0068\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.0144 - mean_squared_error: 0.0082 - val_loss: 0.0292 - val_mean_squared_error: 0.0241\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0271 - mean_squared_error: 0.0220 - val_loss: 0.0152 - val_mean_squared_error: 0.0097\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0136 - mean_squared_error: 0.0081 - val_loss: 0.0127 - val_mean_squared_error: 0.0084\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0129 - mean_squared_error: 0.0086 - val_loss: 0.0168 - val_mean_squared_error: 0.0128\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0179 - mean_squared_error: 0.0139 - val_loss: 0.0144 - val_mean_squared_error: 0.0102\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0152 - mean_squared_error: 0.0111 - val_loss: 0.0101 - val_mean_squared_error: 0.0066\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0103 - mean_squared_error: 0.0067 - val_loss: 0.0103 - val_mean_squared_error: 0.0077\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0095 - mean_squared_error: 0.0069 - val_loss: 0.0141 - val_mean_squared_error: 0.0115\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0125 - mean_squared_error: 0.0098 - val_loss: 0.0153 - val_mean_squared_error: 0.0121\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0132 - mean_squared_error: 0.0101 - val_loss: 0.0123 - val_mean_squared_error: 0.0094\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0107 - mean_squared_error: 0.0077 - val_loss: 0.0093 - val_mean_squared_error: 0.0069\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0085 - mean_squared_error: 0.0061 - val_loss: 0.0087 - val_mean_squared_error: 0.0069\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0087 - mean_squared_error: 0.0069 - val_loss: 0.0102 - val_mean_squared_error: 0.0079\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0106 - mean_squared_error: 0.0084 - val_loss: 0.0102 - val_mean_squared_error: 0.0079\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0107 - mean_squared_error: 0.0084 - val_loss: 0.0088 - val_mean_squared_error: 0.0068\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0090 - mean_squared_error: 0.0070 - val_loss: 0.0087 - val_mean_squared_error: 0.0064\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0083 - mean_squared_error: 0.0061 - val_loss: 0.0097 - val_mean_squared_error: 0.0075\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.0087 - mean_squared_error: 0.0065 - val_loss: 0.0107 - val_mean_squared_error: 0.0088\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0094 - mean_squared_error: 0.0074 - val_loss: 0.0105 - val_mean_squared_error: 0.0087\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0091 - mean_squared_error: 0.0074 - val_loss: 0.0094 - val_mean_squared_error: 0.0076\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.0084 - mean_squared_error: 0.0066 - val_loss: 0.0086 - val_mean_squared_error: 0.0066\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0081 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0065\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.0083 - mean_squared_error: 0.0064 - val_loss: 0.0083 - val_mean_squared_error: 0.0068\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0084 - mean_squared_error: 0.0069 - val_loss: 0.0083 - val_mean_squared_error: 0.0068\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0084 - mean_squared_error: 0.0069 - val_loss: 0.0082 - val_mean_squared_error: 0.0065\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0081 - mean_squared_error: 0.0064 - val_loss: 0.0082 - val_mean_squared_error: 0.0065\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0078 - mean_squared_error: 0.0061 - val_loss: 0.0085 - val_mean_squared_error: 0.0071\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0063 - val_loss: 0.0092 - val_mean_squared_error: 0.0076\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0082 - mean_squared_error: 0.0066 - val_loss: 0.0092 - val_mean_squared_error: 0.0074\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.0083 - mean_squared_error: 0.0065 - val_loss: 0.0085 - val_mean_squared_error: 0.0069\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0062 - val_loss: 0.0077 - val_mean_squared_error: 0.0064\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0078 - val_mean_squared_error: 0.0064\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0077 - mean_squared_error: 0.0062 - val_loss: 0.0082 - val_mean_squared_error: 0.0065\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0080 - mean_squared_error: 0.0064 - val_loss: 0.0083 - val_mean_squared_error: 0.0065\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0063 - val_loss: 0.0081 - val_mean_squared_error: 0.0065\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0080 - val_mean_squared_error: 0.0067\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0075 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0069\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0077 - mean_squared_error: 0.0062 - val_loss: 0.0084 - val_mean_squared_error: 0.0070\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0077 - mean_squared_error: 0.0063 - val_loss: 0.0081 - val_mean_squared_error: 0.0067\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0062 - val_loss: 0.0080 - val_mean_squared_error: 0.0064\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0079 - val_mean_squared_error: 0.0064\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0078 - val_mean_squared_error: 0.0065\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0075 - mean_squared_error: 0.0062 - val_loss: 0.0078 - val_mean_squared_error: 0.0065\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 45us/step - loss: 0.0074 - mean_squared_error: 0.0062 - val_loss: 0.0079 - val_mean_squared_error: 0.0065\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0081 - val_mean_squared_error: 0.0066\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0075 - mean_squared_error: 0.0061 - val_loss: 0.0081 - val_mean_squared_error: 0.0067\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0076 - mean_squared_error: 0.0061 - val_loss: 0.0079 - val_mean_squared_error: 0.0067\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0074 - mean_squared_error: 0.0062 - val_loss: 0.0080 - val_mean_squared_error: 0.0066\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 31us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0080 - val_mean_squared_error: 0.0065\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0075 - mean_squared_error: 0.0061 - val_loss: 0.0080 - val_mean_squared_error: 0.0065\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.0154 - mean_squared_error: 0.0078 - val_loss: 0.0140 - val_mean_squared_error: 0.0108\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0127 - mean_squared_error: 0.0095 - val_loss: 0.0134 - val_mean_squared_error: 0.0078\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0126 - mean_squared_error: 0.0070 - val_loss: 0.0130 - val_mean_squared_error: 0.0065\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0129 - mean_squared_error: 0.0064 - val_loss: 0.0139 - val_mean_squared_error: 0.0076\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0142 - mean_squared_error: 0.0079 - val_loss: 0.0113 - val_mean_squared_error: 0.0067\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0113 - mean_squared_error: 0.0067 - val_loss: 0.0087 - val_mean_squared_error: 0.0066\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0082 - mean_squared_error: 0.0061 - val_loss: 0.0113 - val_mean_squared_error: 0.0080\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0102 - mean_squared_error: 0.0070 - val_loss: 0.0123 - val_mean_squared_error: 0.0081\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0112 - mean_squared_error: 0.0070 - val_loss: 0.0115 - val_mean_squared_error: 0.0070\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0107 - mean_squared_error: 0.0062 - val_loss: 0.0110 - val_mean_squared_error: 0.0065\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0107 - mean_squared_error: 0.0062 - val_loss: 0.0104 - val_mean_squared_error: 0.0067\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0104 - mean_squared_error: 0.0067 - val_loss: 0.0087 - val_mean_squared_error: 0.0066\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0087 - mean_squared_error: 0.0066 - val_loss: 0.0082 - val_mean_squared_error: 0.0063\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.0080 - mean_squared_error: 0.0061 - val_loss: 0.0095 - val_mean_squared_error: 0.0067\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0089 - mean_squared_error: 0.0062 - val_loss: 0.0107 - val_mean_squared_error: 0.0073\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0099 - mean_squared_error: 0.0065 - val_loss: 0.0105 - val_mean_squared_error: 0.0072\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0096 - mean_squared_error: 0.0064 - val_loss: 0.0090 - val_mean_squared_error: 0.0067\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0084 - mean_squared_error: 0.0061 - val_loss: 0.0076 - val_mean_squared_error: 0.0065\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0073 - mean_squared_error: 0.0062 - val_loss: 0.0083 - val_mean_squared_error: 0.0065\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.0081 - mean_squared_error: 0.0064 - val_loss: 0.0088 - val_mean_squared_error: 0.0064\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0086 - mean_squared_error: 0.0063 - val_loss: 0.0088 - val_mean_squared_error: 0.0064\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0085 - mean_squared_error: 0.0061 - val_loss: 0.0091 - val_mean_squared_error: 0.0067\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0086 - mean_squared_error: 0.0062 - val_loss: 0.0089 - val_mean_squared_error: 0.0069\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0063 - val_loss: 0.0080 - val_mean_squared_error: 0.0068\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0074 - mean_squared_error: 0.0062 - val_loss: 0.0081 - val_mean_squared_error: 0.0065\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0085 - val_mean_squared_error: 0.0065\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0082 - mean_squared_error: 0.0061 - val_loss: 0.0087 - val_mean_squared_error: 0.0065\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0084 - mean_squared_error: 0.0062 - val_loss: 0.0085 - val_mean_squared_error: 0.0064\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0082 - mean_squared_error: 0.0061 - val_loss: 0.0082 - val_mean_squared_error: 0.0065\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0078 - val_mean_squared_error: 0.0067\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0072 - mean_squared_error: 0.0061 - val_loss: 0.0083 - val_mean_squared_error: 0.0067\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 44us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0065\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0080 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0064\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.0080 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0064\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0082 - mean_squared_error: 0.0061 - val_loss: 0.0082 - val_mean_squared_error: 0.0064\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0079 - mean_squared_error: 0.0061 - val_loss: 0.0075 - val_mean_squared_error: 0.0065\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0061 - val_loss: 0.0080 - val_mean_squared_error: 0.0066\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0067\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0078 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0066\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0079 - mean_squared_error: 0.0061 - val_loss: 0.0084 - val_mean_squared_error: 0.0064\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0080 - mean_squared_error: 0.0061 - val_loss: 0.0081 - val_mean_squared_error: 0.0064\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0075 - val_mean_squared_error: 0.0065\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0071 - mean_squared_error: 0.0061 - val_loss: 0.0078 - val_mean_squared_error: 0.0065\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0083 - val_mean_squared_error: 0.0066\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0078 - mean_squared_error: 0.0061 - val_loss: 0.0087 - val_mean_squared_error: 0.0066\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0081 - mean_squared_error: 0.0061 - val_loss: 0.0085 - val_mean_squared_error: 0.0065\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0081 - mean_squared_error: 0.0061 - val_loss: 0.0079 - val_mean_squared_error: 0.0064\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0075 - mean_squared_error: 0.0061 - val_loss: 0.0073 - val_mean_squared_error: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0070 - mean_squared_error: 0.0061 - val_loss: 0.0078 - val_mean_squared_error: 0.0064\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0075 - mean_squared_error: 0.0061 - val_loss: 0.0082 - val_mean_squared_error: 0.0066\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.1151 - mean_squared_error: 0.0081 - val_loss: 0.1596 - val_mean_squared_error: 0.0530\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1485 - mean_squared_error: 0.0419 - val_loss: 0.1227 - val_mean_squared_error: 0.0163\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.1197 - mean_squared_error: 0.0132 - val_loss: 0.1222 - val_mean_squared_error: 0.0174\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1190 - mean_squared_error: 0.0142 - val_loss: 0.1376 - val_mean_squared_error: 0.0331\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.1256 - mean_squared_error: 0.0210 - val_loss: 0.1374 - val_mean_squared_error: 0.0330\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.1244 - mean_squared_error: 0.0199 - val_loss: 0.1248 - val_mean_squared_error: 0.0217\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.1180 - mean_squared_error: 0.0148 - val_loss: 0.1140 - val_mean_squared_error: 0.0119\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 52us/step - loss: 0.1122 - mean_squared_error: 0.0101 - val_loss: 0.1110 - val_mean_squared_error: 0.0091\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.1103 - mean_squared_error: 0.0084 - val_loss: 0.1147 - val_mean_squared_error: 0.0125\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 55us/step - loss: 0.1133 - mean_squared_error: 0.0111 - val_loss: 0.1173 - val_mean_squared_error: 0.0156\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.1159 - mean_squared_error: 0.0142 - val_loss: 0.1144 - val_mean_squared_error: 0.0137\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.1135 - mean_squared_error: 0.0128 - val_loss: 0.1088 - val_mean_squared_error: 0.0092\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 50us/step - loss: 0.1080 - mean_squared_error: 0.0085 - val_loss: 0.1062 - val_mean_squared_error: 0.0075\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 60us/step - loss: 0.1047 - mean_squared_error: 0.0060 - val_loss: 0.1088 - val_mean_squared_error: 0.0107\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 63us/step - loss: 0.1058 - mean_squared_error: 0.0077 - val_loss: 0.1126 - val_mean_squared_error: 0.0148\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 57us/step - loss: 0.1082 - mean_squared_error: 0.0104 - val_loss: 0.1129 - val_mean_squared_error: 0.0157\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.1077 - mean_squared_error: 0.0105 - val_loss: 0.1096 - val_mean_squared_error: 0.0133\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.1049 - mean_squared_error: 0.0086 - val_loss: 0.1057 - val_mean_squared_error: 0.0101\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.1026 - mean_squared_error: 0.0070 - val_loss: 0.1034 - val_mean_squared_error: 0.0081\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.1019 - mean_squared_error: 0.0067 - val_loss: 0.1024 - val_mean_squared_error: 0.0077\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.1019 - mean_squared_error: 0.0071 - val_loss: 0.1023 - val_mean_squared_error: 0.0081\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.1019 - mean_squared_error: 0.0077 - val_loss: 0.1022 - val_mean_squared_error: 0.0085\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1018 - mean_squared_error: 0.0081 - val_loss: 0.1010 - val_mean_squared_error: 0.0080\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.1007 - mean_squared_error: 0.0076 - val_loss: 0.0993 - val_mean_squared_error: 0.0071\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0988 - mean_squared_error: 0.0065 - val_loss: 0.0989 - val_mean_squared_error: 0.0073\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0976 - mean_squared_error: 0.0061 - val_loss: 0.1001 - val_mean_squared_error: 0.0091\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0977 - mean_squared_error: 0.0067 - val_loss: 0.1011 - val_mean_squared_error: 0.0106\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0979 - mean_squared_error: 0.0074 - val_loss: 0.1003 - val_mean_squared_error: 0.0104\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0972 - mean_squared_error: 0.0073 - val_loss: 0.0980 - val_mean_squared_error: 0.0088\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0958 - mean_squared_error: 0.0066 - val_loss: 0.0957 - val_mean_squared_error: 0.0074\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0945 - mean_squared_error: 0.0062 - val_loss: 0.0947 - val_mean_squared_error: 0.0069\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0942 - mean_squared_error: 0.0063 - val_loss: 0.0943 - val_mean_squared_error: 0.0069\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0940 - mean_squared_error: 0.0066 - val_loss: 0.0938 - val_mean_squared_error: 0.0069\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0935 - mean_squared_error: 0.0066 - val_loss: 0.0931 - val_mean_squared_error: 0.0069\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0927 - mean_squared_error: 0.0065 - val_loss: 0.0923 - val_mean_squared_error: 0.0069\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0917 - mean_squared_error: 0.0063 - val_loss: 0.0919 - val_mean_squared_error: 0.0072\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0908 - mean_squared_error: 0.0061 - val_loss: 0.0919 - val_mean_squared_error: 0.0076\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0905 - mean_squared_error: 0.0062 - val_loss: 0.0918 - val_mean_squared_error: 0.0080\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0902 - mean_squared_error: 0.0064 - val_loss: 0.0912 - val_mean_squared_error: 0.0079\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0897 - mean_squared_error: 0.0064 - val_loss: 0.0900 - val_mean_squared_error: 0.0074\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0888 - mean_squared_error: 0.0062 - val_loss: 0.0889 - val_mean_squared_error: 0.0071\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0879 - mean_squared_error: 0.0061 - val_loss: 0.0881 - val_mean_squared_error: 0.0069\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.0874 - mean_squared_error: 0.0062 - val_loss: 0.0874 - val_mean_squared_error: 0.0068\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 45us/step - loss: 0.0870 - mean_squared_error: 0.0063 - val_loss: 0.0868 - val_mean_squared_error: 0.0067\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0864 - mean_squared_error: 0.0063 - val_loss: 0.0862 - val_mean_squared_error: 0.0066\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0857 - mean_squared_error: 0.0062 - val_loss: 0.0856 - val_mean_squared_error: 0.0067\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0850 - mean_squared_error: 0.0061 - val_loss: 0.0850 - val_mean_squared_error: 0.0069\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 23us/step - loss: 0.0843 - mean_squared_error: 0.0061 - val_loss: 0.0846 - val_mean_squared_error: 0.0071\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0836 - mean_squared_error: 0.0062 - val_loss: 0.0840 - val_mean_squared_error: 0.0071\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0831 - mean_squared_error: 0.0062 - val_loss: 0.0832 - val_mean_squared_error: 0.0069\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.1031 - mean_squared_error: 0.0138 - val_loss: 0.1224 - val_mean_squared_error: 0.0354\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.1222 - mean_squared_error: 0.0352 - val_loss: 0.0934 - val_mean_squared_error: 0.0078\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0941 - mean_squared_error: 0.0086 - val_loss: 0.1045 - val_mean_squared_error: 0.0201\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.1009 - mean_squared_error: 0.0165 - val_loss: 0.1103 - val_mean_squared_error: 0.0269\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.1030 - mean_squared_error: 0.0196 - val_loss: 0.0944 - val_mean_squared_error: 0.0129\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0902 - mean_squared_error: 0.0086 - val_loss: 0.0895 - val_mean_squared_error: 0.0096\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0890 - mean_squared_error: 0.0092 - val_loss: 0.0933 - val_mean_squared_error: 0.0143\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0939 - mean_squared_error: 0.0148 - val_loss: 0.0888 - val_mean_squared_error: 0.0108\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0894 - mean_squared_error: 0.0114 - val_loss: 0.0832 - val_mean_squared_error: 0.0064\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0834 - mean_squared_error: 0.0066 - val_loss: 0.0854 - val_mean_squared_error: 0.0102\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0839 - mean_squared_error: 0.0087 - val_loss: 0.0888 - val_mean_squared_error: 0.0152\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.0855 - mean_squared_error: 0.0119 - val_loss: 0.0853 - val_mean_squared_error: 0.0133\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0820 - mean_squared_error: 0.0099 - val_loss: 0.0794 - val_mean_squared_error: 0.0087\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0777 - mean_squared_error: 0.0070 - val_loss: 0.0773 - val_mean_squared_error: 0.0078\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0775 - mean_squared_error: 0.0079 - val_loss: 0.0773 - val_mean_squared_error: 0.0088\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0781 - mean_squared_error: 0.0097 - val_loss: 0.0750 - val_mean_squared_error: 0.0077\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0758 - mean_squared_error: 0.0084 - val_loss: 0.0724 - val_mean_squared_error: 0.0062\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0726 - mean_squared_error: 0.0065 - val_loss: 0.0726 - val_mean_squared_error: 0.0078\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 37us/step - loss: 0.0718 - mean_squared_error: 0.0070 - val_loss: 0.0738 - val_mean_squared_error: 0.0104\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0719 - mean_squared_error: 0.0085 - val_loss: 0.0724 - val_mean_squared_error: 0.0104\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0701 - mean_squared_error: 0.0081 - val_loss: 0.0691 - val_mean_squared_error: 0.0083\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.0676 - mean_squared_error: 0.0068 - val_loss: 0.0669 - val_mean_squared_error: 0.0071\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0665 - mean_squared_error: 0.0067 - val_loss: 0.0658 - val_mean_squared_error: 0.0073\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0660 - mean_squared_error: 0.0075 - val_loss: 0.0643 - val_mean_squared_error: 0.0068\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0646 - mean_squared_error: 0.0071 - val_loss: 0.0627 - val_mean_squared_error: 0.0063\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.0627 - mean_squared_error: 0.0062 - val_loss: 0.0622 - val_mean_squared_error: 0.0070\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0616 - mean_squared_error: 0.0063 - val_loss: 0.0625 - val_mean_squared_error: 0.0084\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0611 - mean_squared_error: 0.0071 - val_loss: 0.0616 - val_mean_squared_error: 0.0087\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0599 - mean_squared_error: 0.0071 - val_loss: 0.0595 - val_mean_squared_error: 0.0078\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0582 - mean_squared_error: 0.0065 - val_loss: 0.0577 - val_mean_squared_error: 0.0070\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.0571 - mean_squared_error: 0.0065 - val_loss: 0.0567 - val_mean_squared_error: 0.0068\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0566 - mean_squared_error: 0.0067 - val_loss: 0.0555 - val_mean_squared_error: 0.0065\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.0555 - mean_squared_error: 0.0065 - val_loss: 0.0544 - val_mean_squared_error: 0.0063\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0541 - mean_squared_error: 0.0061 - val_loss: 0.0540 - val_mean_squared_error: 0.0069\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0533 - mean_squared_error: 0.0062 - val_loss: 0.0536 - val_mean_squared_error: 0.0076\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0525 - mean_squared_error: 0.0065 - val_loss: 0.0524 - val_mean_squared_error: 0.0076\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0513 - mean_squared_error: 0.0065 - val_loss: 0.0509 - val_mean_squared_error: 0.0071\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0501 - mean_squared_error: 0.0063 - val_loss: 0.0497 - val_mean_squared_error: 0.0068\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0492 - mean_squared_error: 0.0064 - val_loss: 0.0487 - val_mean_squared_error: 0.0066\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0485 - mean_squared_error: 0.0064 - val_loss: 0.0476 - val_mean_squared_error: 0.0064\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.0473 - mean_squared_error: 0.0062 - val_loss: 0.0469 - val_mean_squared_error: 0.0065\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0464 - mean_squared_error: 0.0061 - val_loss: 0.0462 - val_mean_squared_error: 0.0069\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0455 - mean_squared_error: 0.0062 - val_loss: 0.0454 - val_mean_squared_error: 0.0071\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0446 - mean_squared_error: 0.0063 - val_loss: 0.0443 - val_mean_squared_error: 0.0070\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.0435 - mean_squared_error: 0.0062 - val_loss: 0.0434 - val_mean_squared_error: 0.0068\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0428 - mean_squared_error: 0.0062 - val_loss: 0.0424 - val_mean_squared_error: 0.0067\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0419 - mean_squared_error: 0.0063 - val_loss: 0.0414 - val_mean_squared_error: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0409 - mean_squared_error: 0.0061 - val_loss: 0.0406 - val_mean_squared_error: 0.0068\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.0399 - mean_squared_error: 0.0061 - val_loss: 0.0400 - val_mean_squared_error: 0.0070\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 0.0391 - mean_squared_error: 0.0061 - val_loss: 0.0393 - val_mean_squared_error: 0.0072\n",
      "Train on 285 samples, validate on 72 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.0145 - mean_squared_error: 0.0066 - val_loss: 0.0802 - val_mean_squared_error: 0.0734\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 66us/step - loss: 0.0802 - mean_squared_error: 0.0735 - val_loss: 0.0203 - val_mean_squared_error: 0.0135\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0174 - mean_squared_error: 0.0106 - val_loss: 0.0263 - val_mean_squared_error: 0.0202\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 0.0284 - mean_squared_error: 0.0223 - val_loss: 0.0448 - val_mean_squared_error: 0.0394\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0485 - mean_squared_error: 0.0430 - val_loss: 0.0345 - val_mean_squared_error: 0.0293\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0362 - mean_squared_error: 0.0311 - val_loss: 0.0162 - val_mean_squared_error: 0.0116\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0171 - mean_squared_error: 0.0124 - val_loss: 0.0112 - val_mean_squared_error: 0.0074\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0117 - mean_squared_error: 0.0079 - val_loss: 0.0216 - val_mean_squared_error: 0.0179\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0204 - mean_squared_error: 0.0167 - val_loss: 0.0319 - val_mean_squared_error: 0.0277\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0282 - mean_squared_error: 0.0240 - val_loss: 0.0297 - val_mean_squared_error: 0.0254\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0249 - mean_squared_error: 0.0206 - val_loss: 0.0194 - val_mean_squared_error: 0.0152\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.0157 - mean_squared_error: 0.0115 - val_loss: 0.0114 - val_mean_squared_error: 0.0078\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 42us/step - loss: 0.0100 - mean_squared_error: 0.0064 - val_loss: 0.0120 - val_mean_squared_error: 0.0085\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0124 - mean_squared_error: 0.0089 - val_loss: 0.0166 - val_mean_squared_error: 0.0134\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0177 - mean_squared_error: 0.0145 - val_loss: 0.0179 - val_mean_squared_error: 0.0149\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 41us/step - loss: 0.0190 - mean_squared_error: 0.0160 - val_loss: 0.0141 - val_mean_squared_error: 0.0112\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.0151 - mean_squared_error: 0.0121 - val_loss: 0.0097 - val_mean_squared_error: 0.0069\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0101 - mean_squared_error: 0.0073 - val_loss: 0.0093 - val_mean_squared_error: 0.0070\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 0.0086 - mean_squared_error: 0.0063 - val_loss: 0.0135 - val_mean_squared_error: 0.0111\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0112 - mean_squared_error: 0.0089 - val_loss: 0.0171 - val_mean_squared_error: 0.0146\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0140 - mean_squared_error: 0.0115 - val_loss: 0.0163 - val_mean_squared_error: 0.0138\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0134 - mean_squared_error: 0.0109 - val_loss: 0.0123 - val_mean_squared_error: 0.0099\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0105 - mean_squared_error: 0.0081 - val_loss: 0.0087 - val_mean_squared_error: 0.0068\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0081 - mean_squared_error: 0.0062 - val_loss: 0.0082 - val_mean_squared_error: 0.0065\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0084 - mean_squared_error: 0.0067 - val_loss: 0.0095 - val_mean_squared_error: 0.0080\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0101 - mean_squared_error: 0.0085 - val_loss: 0.0102 - val_mean_squared_error: 0.0086\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0108 - mean_squared_error: 0.0092 - val_loss: 0.0094 - val_mean_squared_error: 0.0079\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0097 - mean_squared_error: 0.0081 - val_loss: 0.0087 - val_mean_squared_error: 0.0070\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0083 - mean_squared_error: 0.0066 - val_loss: 0.0088 - val_mean_squared_error: 0.0072\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0062 - val_loss: 0.0098 - val_mean_squared_error: 0.0084\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.0085 - mean_squared_error: 0.0070 - val_loss: 0.0105 - val_mean_squared_error: 0.0092\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0093 - mean_squared_error: 0.0079 - val_loss: 0.0102 - val_mean_squared_error: 0.0087\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0091 - mean_squared_error: 0.0076 - val_loss: 0.0091 - val_mean_squared_error: 0.0075\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 26us/step - loss: 0.0082 - mean_squared_error: 0.0066 - val_loss: 0.0082 - val_mean_squared_error: 0.0066\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0077 - mean_squared_error: 0.0061 - val_loss: 0.0081 - val_mean_squared_error: 0.0067\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 33us/step - loss: 0.0079 - mean_squared_error: 0.0064 - val_loss: 0.0084 - val_mean_squared_error: 0.0070\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 0.0084 - mean_squared_error: 0.0071 - val_loss: 0.0084 - val_mean_squared_error: 0.0070\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0084 - mean_squared_error: 0.0071 - val_loss: 0.0079 - val_mean_squared_error: 0.0066\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0078 - mean_squared_error: 0.0065 - val_loss: 0.0078 - val_mean_squared_error: 0.0064\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0074 - mean_squared_error: 0.0061 - val_loss: 0.0082 - val_mean_squared_error: 0.0069\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0062 - val_loss: 0.0087 - val_mean_squared_error: 0.0075\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 34us/step - loss: 0.0078 - mean_squared_error: 0.0066 - val_loss: 0.0086 - val_mean_squared_error: 0.0076\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 39us/step - loss: 0.0077 - mean_squared_error: 0.0067 - val_loss: 0.0083 - val_mean_squared_error: 0.0072\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0063 - val_loss: 0.0079 - val_mean_squared_error: 0.0067\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 40us/step - loss: 0.0073 - mean_squared_error: 0.0061 - val_loss: 0.0079 - val_mean_squared_error: 0.0066\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 36us/step - loss: 0.0075 - mean_squared_error: 0.0062 - val_loss: 0.0079 - val_mean_squared_error: 0.0066\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 24us/step - loss: 0.0077 - mean_squared_error: 0.0064 - val_loss: 0.0077 - val_mean_squared_error: 0.0065\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 27us/step - loss: 0.0076 - mean_squared_error: 0.0064 - val_loss: 0.0076 - val_mean_squared_error: 0.0064\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0075 - mean_squared_error: 0.0062 - val_loss: 0.0077 - val_mean_squared_error: 0.0065\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.0073 - mean_squared_error: 0.0061 - val_loss: 0.0081 - val_mean_squared_error: 0.0068\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.5, 0.1, 0.05, 0.01]:\n",
    "    for i in range(N_MODELS):\n",
    "        histories[i] = train(models[i], [x_train_transformed, y_train_transformed], (x_val_transformed, y_val_transformed), lr, 500, history=histories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict target feature using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = []\n",
    "y_val_preds = []\n",
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(x_train_transformed))\n",
    "    y_val_preds.append(model.predict(x_val_transformed))\n",
    "    y_test_preds.append(model.predict(x_unhealthy_transformed[:, :-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble variance to predict diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_var = np.var(y_train_preds, axis=0)\n",
    "y_val_preds_var = np.var(y_val_preds, axis=0)\n",
    "y_test_preds_var = np.var(y_test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAJCCAYAAACBLyXFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(y_train_preds_var, color='b',  bins=50, label='train')\n",
    "plt.hist(y_val_preds_var, fc=(1, 0, 0, 0.5), bins=50, label='val')\n",
    "plt.hist(y_test_preds_var, fc=(0, 1, 0, 0.5), bins=500, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_var = 1.5 * y_train_preds_var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9017543859649123\n"
     ]
    }
   ],
   "source": [
    "train_acc = (y_train_preds_var < threshold_var).mean()\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "val_acc = (y_val_preds_var < threshold_var).mean()\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160377358490566\n"
     ]
    }
   ],
   "source": [
    "test_acc = (y_test_preds_var >= threshold_var).mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
