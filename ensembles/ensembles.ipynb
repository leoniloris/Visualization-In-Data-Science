{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import dataset as d; reload(d)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED_COLUMNS = ['radius_mean', 'diagnosis']\n",
    "FEATURES_PREFIX = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = d.create_xy(df, FEATURES_PREFIX, PREDICTED_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.preprocess_data(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train, Val & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = d.split_train_val_test(x, y, train_perc=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples for training: 285\n",
      "# Examples for validation: 142\n",
      "# Examples for test: 142\n"
     ]
    }
   ],
   "source": [
    "print('# Examples for training:', len(x_train))\n",
    "print('# Examples for validation:', len(x_val))\n",
    "print('# Examples for test:',  len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bearch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l1_l2\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_size, n_hidden):\n",
    "    i = Input((input_size, ))\n",
    "    h = Dense(n_hidden, kernel_initializer='normal', use_bias=True, kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(i)\n",
    "#     h = Dropout(0.6)(h)\n",
    "    h = LeakyReLU()(h)\n",
    "    o = Dense(1)(h)\n",
    "    return Model(i, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "N_MODELS = 5\n",
    "n_hidden_neurons = 64\n",
    "for _ in range(N_MODELS):\n",
    "    models.append(create_base_model(N_FEATURES, n_hidden_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, lr, batch_size, epochs=50, history=None):\n",
    "    current_epoch = 0 if history is None else len(history.history['loss'])\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    new_history = model.fit(\n",
    "        train_data[0], train_data[1], epochs=current_epoch+epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=val_data,\n",
    "        initial_epoch=current_epoch,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if history is not None:\n",
    "        for key in new_history.history:\n",
    "            history.history[key].extend(new_history.history[key])\n",
    "    else:\n",
    "        history = new_history\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 3s 9ms/step - loss: 151.3708 - mean_squared_error: 151.1178 - val_loss: 25.7273 - val_mean_squared_error: 22.7586\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 11.2205 - mean_squared_error: 8.2517 - val_loss: 3867.8242 - val_mean_squared_error: 3861.6946\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2450.0498 - mean_squared_error: 2443.9202 - val_loss: 41.5998 - val_mean_squared_error: 36.7887\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 35.7989 - mean_squared_error: 30.9878 - val_loss: 1117.1323 - val_mean_squared_error: 1112.3737\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 634.5375 - mean_squared_error: 629.7789 - val_loss: 995.9312 - val_mean_squared_error: 992.1730\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 568.3297 - mean_squared_error: 564.5715 - val_loss: 294.9832 - val_mean_squared_error: 291.6489\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 164.2027 - mean_squared_error: 160.8684 - val_loss: 26.1417 - val_mean_squared_error: 22.0832\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 19.3014 - mean_squared_error: 15.2429 - val_loss: 560.3562 - val_mean_squared_error: 555.1118\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 348.7170 - mean_squared_error: 343.4725 - val_loss: 628.0774 - val_mean_squared_error: 622.4828\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 394.2719 - mean_squared_error: 388.6773 - val_loss: 238.8905 - val_mean_squared_error: 233.5539\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 158.6828 - mean_squared_error: 153.3462 - val_loss: 20.9597 - val_mean_squared_error: 15.8976\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 18.1100 - mean_squared_error: 13.0480 - val_loss: 79.4568 - val_mean_squared_error: 74.3147\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 38.5200 - mean_squared_error: 33.3779 - val_loss: 208.3395 - val_mean_squared_error: 202.8975\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 106.4957 - mean_squared_error: 101.0537 - val_loss: 131.7983 - val_mean_squared_error: 125.9730\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 64.2473 - mean_squared_error: 58.4220 - val_loss: 16.6885 - val_mean_squared_error: 10.3837\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 9.9989 - mean_squared_error: 3.6941 - val_loss: 47.3966 - val_mean_squared_error: 40.5127\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 41.4365 - mean_squared_error: 34.5526 - val_loss: 95.6885 - val_mean_squared_error: 88.2538\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 76.6156 - mean_squared_error: 69.1809 - val_loss: 69.6803 - val_mean_squared_error: 61.8546\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 58.9536 - mean_squared_error: 51.1278 - val_loss: 16.2137 - val_mean_squared_error: 8.1145\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 16.0842 - mean_squared_error: 7.9850 - val_loss: 57.5252 - val_mean_squared_error: 49.1629\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 26.6469 - mean_squared_error: 18.2847 - val_loss: 128.8891 - val_mean_squared_error: 120.2522\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 61.7624 - mean_squared_error: 53.1256 - val_loss: 74.0365 - val_mean_squared_error: 65.1504\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 34.2831 - mean_squared_error: 25.3970 - val_loss: 15.1689 - val_mean_squared_error: 6.0340\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 12.9129 - mean_squared_error: 3.7780 - val_loss: 42.7452 - val_mean_squared_error: 33.3775\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 41.3318 - mean_squared_error: 31.9641 - val_loss: 46.8733 - val_mean_squared_error: 37.3608\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 44.8465 - mean_squared_error: 35.3340 - val_loss: 15.2940 - val_mean_squared_error: 5.7227\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 15.8997 - mean_squared_error: 6.3284 - val_loss: 46.2314 - val_mean_squared_error: 36.6148\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 21.3609 - mean_squared_error: 11.7443 - val_loss: 88.5559 - val_mean_squared_error: 78.8818\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 40.3353 - mean_squared_error: 30.6613 - val_loss: 44.4957 - val_mean_squared_error: 34.7627\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 20.5108 - mean_squared_error: 10.7777 - val_loss: 13.7066 - val_mean_squared_error: 3.9006\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 14.0619 - mean_squared_error: 4.2560 - val_loss: 27.8395 - val_mean_squared_error: 17.9773\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 29.9312 - mean_squared_error: 20.0690 - val_loss: 20.2622 - val_mean_squared_error: 10.4097\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 23.5375 - mean_squared_error: 13.6849 - val_loss: 17.0768 - val_mean_squared_error: 7.2801\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 11.4205 - mean_squared_error: 1.6238 - val_loss: 51.5050 - val_mean_squared_error: 41.7592\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 23.5934 - mean_squared_error: 13.8476 - val_loss: 45.2497 - val_mean_squared_error: 35.5321\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 21.1500 - mean_squared_error: 11.4323 - val_loss: 14.4748 - val_mean_squared_error: 4.7582\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.1090 - mean_squared_error: 1.3923 - val_loss: 15.6854 - val_mean_squared_error: 5.9666\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 17.9501 - mean_squared_error: 8.2313 - val_loss: 16.7242 - val_mean_squared_error: 7.0474\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 18.7025 - mean_squared_error: 9.0256 - val_loss: 11.8526 - val_mean_squared_error: 2.2670\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.3749 - mean_squared_error: 1.7893 - val_loss: 23.2443 - val_mean_squared_error: 13.7590\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 13.8286 - mean_squared_error: 4.3434 - val_loss: 30.7752 - val_mean_squared_error: 21.3618\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 17.2515 - mean_squared_error: 7.8381 - val_loss: 18.4241 - val_mean_squared_error: 9.0456\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 12.1066 - mean_squared_error: 2.7282 - val_loss: 10.9136 - val_mean_squared_error: 1.5520\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.2823 - mean_squared_error: 1.9206 - val_loss: 13.5693 - val_mean_squared_error: 4.2458\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 14.9343 - mean_squared_error: 5.6108 - val_loss: 11.3196 - val_mean_squared_error: 2.0814\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.3689 - mean_squared_error: 3.1307 - val_loss: 12.2820 - val_mean_squared_error: 3.1580\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 10.1461 - mean_squared_error: 1.0221 - val_loss: 19.6365 - val_mean_squared_error: 10.6177\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.8618 - mean_squared_error: 3.8431 - val_loss: 17.9204 - val_mean_squared_error: 8.9754\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.1789 - mean_squared_error: 3.2339 - val_loss: 10.7484 - val_mean_squared_error: 1.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.6689 - mean_squared_error: 0.7719 - val_loss: 10.3745 - val_mean_squared_error: 1.5274\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 152.1996 - mean_squared_error: 151.9642 - val_loss: 34.8669 - val_mean_squared_error: 31.9374\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 16.4698 - mean_squared_error: 13.5403 - val_loss: 3794.3083 - val_mean_squared_error: 3788.5520\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 2374.9111 - mean_squared_error: 2369.1548 - val_loss: 85.9140 - val_mean_squared_error: 81.3384\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 64.8205 - mean_squared_error: 60.2449 - val_loss: 747.6371 - val_mean_squared_error: 742.9677\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 421.0133 - mean_squared_error: 416.3439 - val_loss: 774.9991 - val_mean_squared_error: 770.9105\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 438.5966 - mean_squared_error: 434.5081 - val_loss: 139.0629 - val_mean_squared_error: 134.9767\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 72.6760 - mean_squared_error: 68.5898 - val_loss: 230.3905 - val_mean_squared_error: 225.2126\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 45us/step - loss: 156.9116 - mean_squared_error: 151.7337 - val_loss: 801.2176 - val_mean_squared_error: 795.3190\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 45us/step - loss: 514.3536 - mean_squared_error: 508.4550 - val_loss: 490.5711 - val_mean_squared_error: 484.8900\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 322.0544 - mean_squared_error: 316.3733 - val_loss: 104.2650 - val_mean_squared_error: 99.0279\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 74.9139 - mean_squared_error: 69.6768 - val_loss: 14.3466 - val_mean_squared_error: 9.3827\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.9701 - mean_squared_error: 4.0062 - val_loss: 109.8916 - val_mean_squared_error: 104.8547\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 59.1120 - mean_squared_error: 54.0752 - val_loss: 187.1253 - val_mean_squared_error: 181.8964\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 103.2774 - mean_squared_error: 98.0486 - val_loss: 132.1257 - val_mean_squared_error: 126.6798\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 72.3186 - mean_squared_error: 66.8727 - val_loss: 32.0543 - val_mean_squared_error: 26.3617\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 17.5551 - mean_squared_error: 11.8625 - val_loss: 24.3983 - val_mean_squared_error: 18.4032\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 20.4276 - mean_squared_error: 14.4325 - val_loss: 109.1944 - val_mean_squared_error: 102.8912\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 78.1965 - mean_squared_error: 71.8933 - val_loss: 152.0744 - val_mean_squared_error: 145.5492\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 106.7462 - mean_squared_error: 100.2211 - val_loss: 87.4424 - val_mean_squared_error: 80.7920\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 64.7358 - mean_squared_error: 58.0854 - val_loss: 13.6819 - val_mean_squared_error: 6.9114\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 39us/step - loss: 12.5228 - mean_squared_error: 5.7523 - val_loss: 61.2430 - val_mean_squared_error: 54.2928\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 32.4908 - mean_squared_error: 25.5405 - val_loss: 135.0389 - val_mean_squared_error: 127.9006\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 71.7515 - mean_squared_error: 64.6132 - val_loss: 69.3654 - val_mean_squared_error: 62.1264\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 36.6926 - mean_squared_error: 29.4537 - val_loss: 11.9739 - val_mean_squared_error: 4.6585\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 49us/step - loss: 10.3901 - mean_squared_error: 3.0747 - val_loss: 49.8833 - val_mean_squared_error: 42.4589\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 52us/step - loss: 38.9940 - mean_squared_error: 31.5696 - val_loss: 63.3346 - val_mean_squared_error: 55.8358\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 52us/step - loss: 49.1187 - mean_squared_error: 41.6199 - val_loss: 15.9395 - val_mean_squared_error: 8.4191\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 15.2015 - mean_squared_error: 7.6811 - val_loss: 33.9726 - val_mean_squared_error: 26.4307\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 18.9445 - mean_squared_error: 11.4026 - val_loss: 74.7954 - val_mean_squared_error: 67.2258\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 40.3545 - mean_squared_error: 32.7848 - val_loss: 40.2990 - val_mean_squared_error: 32.7236\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 22.1971 - mean_squared_error: 14.6217 - val_loss: 11.0180 - val_mean_squared_error: 3.4342\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 10.5198 - mean_squared_error: 2.9360 - val_loss: 32.6912 - val_mean_squared_error: 25.1002\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 28.2531 - mean_squared_error: 20.6621 - val_loss: 28.2126 - val_mean_squared_error: 20.6582\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 25.0501 - mean_squared_error: 17.4956 - val_loss: 10.2732 - val_mean_squared_error: 2.7918\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.5456 - mean_squared_error: 2.0641 - val_loss: 30.9217 - val_mean_squared_error: 23.5103\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 17.5025 - mean_squared_error: 10.0911 - val_loss: 42.7193 - val_mean_squared_error: 35.3678\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 23.5242 - mean_squared_error: 16.1728 - val_loss: 19.5084 - val_mean_squared_error: 12.2088\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 12.0409 - mean_squared_error: 4.7412 - val_loss: 10.2067 - val_mean_squared_error: 2.9476\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.5622 - mean_squared_error: 3.3031 - val_loss: 19.5002 - val_mean_squared_error: 12.2910\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 18.6914 - mean_squared_error: 11.4823 - val_loss: 14.0466 - val_mean_squared_error: 6.9205\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 14.2959 - mean_squared_error: 7.1699 - val_loss: 9.6020 - val_mean_squared_error: 2.5782\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 45us/step - loss: 8.2850 - mean_squared_error: 1.2611 - val_loss: 21.7839 - val_mean_squared_error: 14.8563\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 13.0369 - mean_squared_error: 6.1093 - val_loss: 24.7893 - val_mean_squared_error: 17.9429\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 14.5273 - mean_squared_error: 7.6808 - val_loss: 12.6694 - val_mean_squared_error: 5.8887\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.9510 - mean_squared_error: 2.1702 - val_loss: 8.4043 - val_mean_squared_error: 1.6794\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.8893 - mean_squared_error: 2.1644 - val_loss: 11.9672 - val_mean_squared_error: 5.3060\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.4262 - mean_squared_error: 5.7650 - val_loss: 9.5271 - val_mean_squared_error: 2.9542\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 10.1864 - mean_squared_error: 3.6135 - val_loss: 8.0943 - val_mean_squared_error: 1.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.3760 - mean_squared_error: 0.9067 - val_loss: 13.8768 - val_mean_squared_error: 7.5062\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 9.4299 - mean_squared_error: 3.0593 - val_loss: 15.5392 - val_mean_squared_error: 9.2526\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 152.0832 - mean_squared_error: 151.8567 - val_loss: 11.3862 - val_mean_squared_error: 8.4280\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 9.4137 - mean_squared_error: 6.4555 - val_loss: 1635.7289 - val_mean_squared_error: 1630.6459\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 944.1059 - mean_squared_error: 939.0228 - val_loss: 465.0486 - val_mean_squared_error: 459.3657\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 319.6348 - mean_squared_error: 313.9519 - val_loss: 589.4744 - val_mean_squared_error: 584.6943\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 403.0207 - mean_squared_error: 398.2407 - val_loss: 19.4073 - val_mean_squared_error: 16.1037\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 23us/step - loss: 19.1420 - mean_squared_error: 15.8385 - val_loss: 111.5421 - val_mean_squared_error: 109.2880\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 53.0015 - mean_squared_error: 50.7474 - val_loss: 196.8772 - val_mean_squared_error: 195.0924\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 100.8089 - mean_squared_error: 99.0240 - val_loss: 111.7921 - val_mean_squared_error: 110.0140\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 55.8933 - mean_squared_error: 54.1152 - val_loss: 9.6525 - val_mean_squared_error: 7.5343\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 7.0909 - mean_squared_error: 4.9726 - val_loss: 179.1530 - val_mean_squared_error: 176.5851\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 120.8016 - mean_squared_error: 118.2337 - val_loss: 82.3935 - val_mean_squared_error: 79.8592\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 59.0624 - mean_squared_error: 56.5281 - val_loss: 9.8445 - val_mean_squared_error: 7.4504\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.3734 - mean_squared_error: 4.9793 - val_loss: 34.3463 - val_mean_squared_error: 32.0184\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 15.3513 - mean_squared_error: 13.0234 - val_loss: 57.0016 - val_mean_squared_error: 54.6229\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 38us/step - loss: 26.0091 - mean_squared_error: 23.6305 - val_loss: 49.4848 - val_mean_squared_error: 46.9082\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 22.2351 - mean_squared_error: 19.6585 - val_loss: 26.0676 - val_mean_squared_error: 23.1868\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.4334 - mean_squared_error: 8.5527 - val_loss: 10.8547 - val_mean_squared_error: 7.6087\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.2944 - mean_squared_error: 4.0484 - val_loss: 19.5780 - val_mean_squared_error: 15.9674\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 17.6975 - mean_squared_error: 14.0868 - val_loss: 34.0062 - val_mean_squared_error: 30.1239\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 29.4787 - mean_squared_error: 25.5964 - val_loss: 27.7947 - val_mean_squared_error: 23.7827\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 25.1385 - mean_squared_error: 21.1265 - val_loss: 13.5103 - val_mean_squared_error: 9.4695\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 12.7572 - mean_squared_error: 8.7164 - val_loss: 13.5037 - val_mean_squared_error: 9.4605\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.6387 - mean_squared_error: 3.5955 - val_loss: 26.7123 - val_mean_squared_error: 22.6511\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 11.0866 - mean_squared_error: 7.0254 - val_loss: 36.1536 - val_mean_squared_error: 32.0445\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 14.6678 - mean_squared_error: 10.5587 - val_loss: 30.9746 - val_mean_squared_error: 26.7834\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 12.5950 - mean_squared_error: 8.4038 - val_loss: 18.9439 - val_mean_squared_error: 14.6452\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.5648 - mean_squared_error: 4.2661 - val_loss: 11.8021 - val_mean_squared_error: 7.3885\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 8.1828 - mean_squared_error: 3.7691 - val_loss: 11.6182 - val_mean_squared_error: 7.1102\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.1389 - mean_squared_error: 6.6309 - val_loss: 12.5542 - val_mean_squared_error: 7.9996\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 12.8813 - mean_squared_error: 8.3267 - val_loss: 11.3459 - val_mean_squared_error: 6.8020\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 18us/step - loss: 11.0562 - mean_squared_error: 6.5124 - val_loss: 11.3443 - val_mean_squared_error: 6.8528\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.1732 - mean_squared_error: 3.6816 - val_loss: 16.3571 - val_mean_squared_error: 11.9305\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.7219 - mean_squared_error: 3.2953 - val_loss: 23.7041 - val_mean_squared_error: 19.3321\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 9.4803 - mean_squared_error: 5.1083 - val_loss: 26.4938 - val_mean_squared_error: 22.1526\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 10.2903 - mean_squared_error: 5.9491 - val_loss: 22.3136 - val_mean_squared_error: 17.9782\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.8634 - mean_squared_error: 4.5280 - val_loss: 15.6102 - val_mean_squared_error: 11.2635\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.2489 - mean_squared_error: 2.9022 - val_loss: 11.2688 - val_mean_squared_error: 6.9065\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.3213 - mean_squared_error: 2.9590 - val_loss: 9.8903 - val_mean_squared_error: 5.5259\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.3392 - mean_squared_error: 3.9749 - val_loss: 9.6694 - val_mean_squared_error: 5.3342\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 8.4817 - mean_squared_error: 4.1465 - val_loss: 10.1609 - val_mean_squared_error: 5.8868\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.4538 - mean_squared_error: 3.1798 - val_loss: 12.4530 - val_mean_squared_error: 8.2582\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.5688 - mean_squared_error: 2.3739 - val_loss: 16.5211 - val_mean_squared_error: 12.4028\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.7176 - mean_squared_error: 2.5993 - val_loss: 20.0185 - val_mean_squared_error: 15.9619\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.2788 - mean_squared_error: 3.2222 - val_loss: 20.2839 - val_mean_squared_error: 16.2678\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.2031 - mean_squared_error: 3.1869 - val_loss: 17.2270 - val_mean_squared_error: 13.2324\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.4685 - mean_squared_error: 2.4738 - val_loss: 13.2985 - val_mean_squared_error: 9.3142\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.9612 - mean_squared_error: 1.9770 - val_loss: 10.6189 - val_mean_squared_error: 6.6471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.1082 - mean_squared_error: 2.1365 - val_loss: 9.5066 - val_mean_squared_error: 5.5625\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.3437 - mean_squared_error: 2.3996 - val_loss: 9.6854 - val_mean_squared_error: 5.7892\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.0510 - mean_squared_error: 2.1549 - val_loss: 11.5649 - val_mean_squared_error: 7.7310\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 149.9579 - mean_squared_error: 149.7182 - val_loss: 16.0367 - val_mean_squared_error: 13.0695\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.8967 - mean_squared_error: 4.9295 - val_loss: 3765.4844 - val_mean_squared_error: 3759.3159\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2370.9907 - mean_squared_error: 2364.8223 - val_loss: 12.6329 - val_mean_squared_error: 7.3016\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.6027 - mean_squared_error: 3.2714 - val_loss: 1404.0582 - val_mean_squared_error: 1398.7058\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 804.7194 - mean_squared_error: 799.3671 - val_loss: 1165.8540 - val_mean_squared_error: 1161.5376\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 667.2844 - mean_squared_error: 662.9679 - val_loss: 295.6859 - val_mean_squared_error: 291.9987\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 162.5720 - mean_squared_error: 158.8849 - val_loss: 49.7408 - val_mean_squared_error: 45.6312\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 38.0651 - mean_squared_error: 33.9555 - val_loss: 555.8420 - val_mean_squared_error: 550.8778\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 362.4210 - mean_squared_error: 357.4568 - val_loss: 540.4538 - val_mean_squared_error: 535.2803\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 355.6985 - mean_squared_error: 350.5249 - val_loss: 160.6062 - val_mean_squared_error: 155.5899\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 115.7990 - mean_squared_error: 110.7827 - val_loss: 24.9791 - val_mean_squared_error: 20.0591\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.7686 - mean_squared_error: 6.8486 - val_loss: 315.0924 - val_mean_squared_error: 310.0388\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 162.6112 - mean_squared_error: 157.5576 - val_loss: 213.8248 - val_mean_squared_error: 208.6548\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 106.4209 - mean_squared_error: 101.2509 - val_loss: 21.3977 - val_mean_squared_error: 15.8910\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 10.5501 - mean_squared_error: 5.0433 - val_loss: 75.9510 - val_mean_squared_error: 69.9883\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 62.5138 - mean_squared_error: 56.5511 - val_loss: 167.3615 - val_mean_squared_error: 161.0430\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 126.3565 - mean_squared_error: 120.0381 - val_loss: 78.6929 - val_mean_squared_error: 72.2186\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 66.1781 - mean_squared_error: 59.7039 - val_loss: 19.4235 - val_mean_squared_error: 12.8742\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.2645 - mean_squared_error: 3.7152 - val_loss: 164.4959 - val_mean_squared_error: 157.8286\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 76.9736 - mean_squared_error: 70.3063 - val_loss: 154.5254 - val_mean_squared_error: 147.7447\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 71.5012 - mean_squared_error: 64.7205 - val_loss: 20.4948 - val_mean_squared_error: 13.6003\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.4430 - mean_squared_error: 3.5485 - val_loss: 48.8310 - val_mean_squared_error: 41.8044\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 46.5340 - mean_squared_error: 39.5075 - val_loss: 81.1408 - val_mean_squared_error: 74.0565\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 42us/step - loss: 71.1454 - mean_squared_error: 64.0612 - val_loss: 23.4248 - val_mean_squared_error: 16.3923\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 25.7518 - mean_squared_error: 18.7193 - val_loss: 38.4293 - val_mean_squared_error: 31.4680\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 16.1405 - mean_squared_error: 9.1793 - val_loss: 119.0010 - val_mean_squared_error: 112.0748\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 53.4209 - mean_squared_error: 46.4948 - val_loss: 69.7263 - val_mean_squared_error: 62.8168\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 29.8068 - mean_squared_error: 22.8972 - val_loss: 11.3157 - val_mean_squared_error: 4.3941\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.0131 - mean_squared_error: 3.0915 - val_loss: 32.5775 - val_mean_squared_error: 25.6443\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 34.0497 - mean_squared_error: 27.1165 - val_loss: 32.0129 - val_mean_squared_error: 25.1338\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 33.5690 - mean_squared_error: 26.6898 - val_loss: 10.0664 - val_mean_squared_error: 3.3067\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.5605 - mean_squared_error: 3.8008 - val_loss: 40.5555 - val_mean_squared_error: 33.9125\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 17.1769 - mean_squared_error: 10.5339 - val_loss: 68.3468 - val_mean_squared_error: 61.7832\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 29.7922 - mean_squared_error: 23.2286 - val_loss: 33.0118 - val_mean_squared_error: 26.4896\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 14.2725 - mean_squared_error: 7.7504 - val_loss: 9.0066 - val_mean_squared_error: 2.4937\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.3544 - mean_squared_error: 2.8416 - val_loss: 17.4749 - val_mean_squared_error: 10.9815\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 20.2099 - mean_squared_error: 13.7165 - val_loss: 15.1225 - val_mean_squared_error: 8.7036\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 17.9017 - mean_squared_error: 11.4828 - val_loss: 8.6735 - val_mean_squared_error: 2.3729\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.9918 - mean_squared_error: 1.6912 - val_loss: 24.8702 - val_mean_squared_error: 18.6834\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.7603 - mean_squared_error: 5.5735 - val_loss: 36.6104 - val_mean_squared_error: 30.4992\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 16.9873 - mean_squared_error: 10.8761 - val_loss: 21.0306 - val_mean_squared_error: 14.9514\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 10.4793 - mean_squared_error: 4.4001 - val_loss: 7.8116 - val_mean_squared_error: 1.7338\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.4035 - mean_squared_error: 1.3258 - val_loss: 10.3398 - val_mean_squared_error: 4.2700\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.2977 - mean_squared_error: 6.2279 - val_loss: 10.2977 - val_mean_squared_error: 4.2792\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 12.1419 - mean_squared_error: 6.1234 - val_loss: 7.0770 - val_mean_squared_error: 1.1512\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.3176 - mean_squared_error: 1.3918 - val_loss: 13.4891 - val_mean_squared_error: 7.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.0497 - mean_squared_error: 2.2229 - val_loss: 20.3789 - val_mean_squared_error: 14.6247\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 11.0441 - mean_squared_error: 5.2898 - val_loss: 14.4309 - val_mean_squared_error: 8.7134\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.6251 - mean_squared_error: 2.9076 - val_loss: 7.0764 - val_mean_squared_error: 1.3706\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 6.4196 - mean_squared_error: 0.7138 - val_loss: 7.4406 - val_mean_squared_error: 1.7489\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 1/50\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 149.0809 - mean_squared_error: 148.8443 - val_loss: 9.8173 - val_mean_squared_error: 6.8570\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.1367 - mean_squared_error: 4.1765 - val_loss: 1366.2434 - val_mean_squared_error: 1360.5093\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 778.4645 - mean_squared_error: 772.7304 - val_loss: 1689.1835 - val_mean_squared_error: 1682.5266\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1098.7393 - mean_squared_error: 1092.0824 - val_loss: 496.8114 - val_mean_squared_error: 491.3894\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 342.2629 - mean_squared_error: 336.8408 - val_loss: 68.4983 - val_mean_squared_error: 64.2829\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 31.6952 - mean_squared_error: 27.4799 - val_loss: 517.0412 - val_mean_squared_error: 513.6472\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 283.0089 - mean_squared_error: 279.6150 - val_loss: 517.8839 - val_mean_squared_error: 515.2119\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 285.3282 - mean_squared_error: 282.6563 - val_loss: 224.9293 - val_mean_squared_error: 222.8170\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 118.9688 - mean_squared_error: 116.8566 - val_loss: 21.6287 - val_mean_squared_error: 19.6855\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 0s 33us/step - loss: 9.6299 - mean_squared_error: 7.6867 - val_loss: 85.0192 - val_mean_squared_error: 82.8696\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 62.5543 - mean_squared_error: 60.4047 - val_loss: 124.0597 - val_mean_squared_error: 121.7626\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 89.5470 - mean_squared_error: 87.2499 - val_loss: 22.2656 - val_mean_squared_error: 19.8569\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 19.9450 - mean_squared_error: 17.5362 - val_loss: 48.0573 - val_mean_squared_error: 45.4354\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 19.7357 - mean_squared_error: 17.1139 - val_loss: 171.7428 - val_mean_squared_error: 168.8413\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 80.9375 - mean_squared_error: 78.0360 - val_loss: 156.4437 - val_mean_squared_error: 153.3374\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 72.4127 - mean_squared_error: 69.3065 - val_loss: 50.4302 - val_mean_squared_error: 47.1544\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 0s 25us/step - loss: 20.5522 - mean_squared_error: 17.2763 - val_loss: 10.7768 - val_mean_squared_error: 7.2482\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.7486 - mean_squared_error: 5.2200 - val_loss: 30.4190 - val_mean_squared_error: 26.5534\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 28.1002 - mean_squared_error: 24.2346 - val_loss: 36.4761 - val_mean_squared_error: 32.3147\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 33.2973 - mean_squared_error: 29.1359 - val_loss: 15.6440 - val_mean_squared_error: 11.2917\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 15.8671 - mean_squared_error: 11.5148 - val_loss: 15.7609 - val_mean_squared_error: 11.2629\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.0224 - mean_squared_error: 3.5244 - val_loss: 43.3243 - val_mean_squared_error: 38.6549\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 17.7456 - mean_squared_error: 13.0762 - val_loss: 66.0180 - val_mean_squared_error: 61.1394\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 0s 32us/step - loss: 27.8534 - mean_squared_error: 22.9748 - val_loss: 60.8294 - val_mean_squared_error: 55.7179\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 25.3288 - mean_squared_error: 20.2173 - val_loss: 34.2497 - val_mean_squared_error: 28.8970\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 13.8706 - mean_squared_error: 8.5180 - val_loss: 13.5453 - val_mean_squared_error: 7.9525\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 0s 35us/step - loss: 8.7623 - mean_squared_error: 3.1696 - val_loss: 14.8328 - val_mean_squared_error: 9.0276\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 16.7237 - mean_squared_error: 10.9185 - val_loss: 19.5067 - val_mean_squared_error: 13.5564\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 22.2850 - mean_squared_error: 16.3347 - val_loss: 13.2393 - val_mean_squared_error: 7.2204\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 14.9865 - mean_squared_error: 8.9677 - val_loss: 14.7272 - val_mean_squared_error: 8.6814\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.7898 - mean_squared_error: 2.7441 - val_loss: 31.5886 - val_mean_squared_error: 25.5205\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 12.5665 - mean_squared_error: 6.4984 - val_loss: 44.3044 - val_mean_squared_error: 38.2047\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 17.3067 - mean_squared_error: 11.2069 - val_loss: 37.8759 - val_mean_squared_error: 31.7373\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 14.7265 - mean_squared_error: 8.5880 - val_loss: 21.1270 - val_mean_squared_error: 14.9469\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 9.3701 - mean_squared_error: 3.1901 - val_loss: 11.6541 - val_mean_squared_error: 5.4374\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.6622 - mean_squared_error: 3.4454 - val_loss: 11.5862 - val_mean_squared_error: 5.3541\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 13.6729 - mean_squared_error: 7.4409 - val_loss: 11.2533 - val_mean_squared_error: 5.0398\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 13.2133 - mean_squared_error: 6.9998 - val_loss: 11.3203 - val_mean_squared_error: 5.1533\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 9.2369 - mean_squared_error: 3.0698 - val_loss: 18.4770 - val_mean_squared_error: 12.3613\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.5961 - mean_squared_error: 2.4803 - val_loss: 27.8547 - val_mean_squared_error: 21.7823\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.0745 - mean_squared_error: 5.0021 - val_loss: 28.7808 - val_mean_squared_error: 22.7480\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 11.4159 - mean_squared_error: 5.3831 - val_loss: 20.6868 - val_mean_squared_error: 14.6924\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.9848 - mean_squared_error: 2.9904 - val_loss: 12.5101 - val_mean_squared_error: 6.5547\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.8585 - mean_squared_error: 1.9031 - val_loss: 9.6061 - val_mean_squared_error: 3.6956\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.2875 - mean_squared_error: 3.3771 - val_loss: 9.2671 - val_mean_squared_error: 3.4145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.9345 - mean_squared_error: 4.0819 - val_loss: 9.4965 - val_mean_squared_error: 3.7156\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.3890 - mean_squared_error: 2.6081 - val_loss: 12.4430 - val_mean_squared_error: 6.7414\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.3237 - mean_squared_error: 1.6221 - val_loss: 17.4169 - val_mean_squared_error: 11.7946\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.0643 - mean_squared_error: 2.4419 - val_loss: 19.4553 - val_mean_squared_error: 13.9061\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.6382 - mean_squared_error: 3.0890 - val_loss: 16.2999 - val_mean_squared_error: 10.8178\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 11.1721 - mean_squared_error: 2.3251 - val_loss: 135.2244 - val_mean_squared_error: 126.8967\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 77.9547 - mean_squared_error: 69.6270 - val_loss: 15.8466 - val_mean_squared_error: 7.1914\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 11.1806 - mean_squared_error: 2.5254 - val_loss: 53.1194 - val_mean_squared_error: 44.0870\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 44.7862 - mean_squared_error: 35.7538 - val_loss: 52.4900 - val_mean_squared_error: 43.5012\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 44.2058 - mean_squared_error: 35.2171 - val_loss: 13.3872 - val_mean_squared_error: 4.6369\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 14.3601 - mean_squared_error: 5.6098 - val_loss: 20.9473 - val_mean_squared_error: 12.4441\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 13.4117 - mean_squared_error: 4.9085 - val_loss: 51.3286 - val_mean_squared_error: 42.9835\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 29.3627 - mean_squared_error: 21.0176 - val_loss: 48.9806 - val_mean_squared_error: 40.6702\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 28.1469 - mean_squared_error: 19.8365 - val_loss: 23.2365 - val_mean_squared_error: 14.8620\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 14.5974 - mean_squared_error: 6.2229 - val_loss: 9.3381 - val_mean_squared_error: 0.8510\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 9.4144 - mean_squared_error: 0.9272 - val_loss: 17.0199 - val_mean_squared_error: 8.4411\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 17.1572 - mean_squared_error: 8.5785 - val_loss: 23.6607 - val_mean_squared_error: 15.0774\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 22.3231 - mean_squared_error: 13.7399 - val_loss: 16.3672 - val_mean_squared_error: 7.8783\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 16.6145 - mean_squared_error: 8.1255 - val_loss: 9.1666 - val_mean_squared_error: 0.8302\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 9.6344 - mean_squared_error: 1.2980 - val_loss: 14.6969 - val_mean_squared_error: 6.5170\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.5121 - mean_squared_error: 2.3323 - val_loss: 25.4535 - val_mean_squared_error: 17.3903\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 15.6053 - mean_squared_error: 7.5420 - val_loss: 27.0230 - val_mean_squared_error: 19.0161\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 16.3826 - mean_squared_error: 8.3758 - val_loss: 18.2601 - val_mean_squared_error: 10.2540\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 12.0153 - mean_squared_error: 4.0092 - val_loss: 9.9784 - val_mean_squared_error: 1.9396\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.7526 - mean_squared_error: 0.7138 - val_loss: 9.5039 - val_mean_squared_error: 1.4330\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.3813 - mean_squared_error: 2.3104 - val_loss: 12.4026 - val_mean_squared_error: 4.3384\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 13.2753 - mean_squared_error: 5.2111 - val_loss: 11.6115 - val_mean_squared_error: 3.6115\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 12.5663 - mean_squared_error: 4.5663 - val_loss: 8.7935 - val_mean_squared_error: 0.9049\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 9.5011 - mean_squared_error: 1.6125 - val_loss: 9.8920 - val_mean_squared_error: 2.1314\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.4764 - mean_squared_error: 0.7157 - val_loss: 14.7920 - val_mean_squared_error: 7.1437\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.1756 - mean_squared_error: 2.5273 - val_loss: 17.5085 - val_mean_squared_error: 9.9362\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 11.3513 - mean_squared_error: 3.7790 - val_loss: 14.8805 - val_mean_squared_error: 7.3429\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.1320 - mean_squared_error: 2.5944 - val_loss: 10.2549 - val_mean_squared_error: 2.7200\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 8.3655 - mean_squared_error: 0.8306 - val_loss: 8.1929 - val_mean_squared_error: 0.6508\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.3998 - mean_squared_error: 0.8577 - val_loss: 8.6833 - val_mean_squared_error: 1.1526\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 9.6221 - mean_squared_error: 2.0914 - val_loss: 8.7616 - val_mean_squared_error: 1.2789\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.7572 - mean_squared_error: 2.2745 - val_loss: 8.0222 - val_mean_squared_error: 0.6229\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.5576 - mean_squared_error: 1.1583 - val_loss: 8.7202 - val_mean_squared_error: 1.4215\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 42us/step - loss: 7.8399 - mean_squared_error: 0.5412 - val_loss: 11.2156 - val_mean_squared_error: 4.0110\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.3785 - mean_squared_error: 1.1739 - val_loss: 12.8740 - val_mean_squared_error: 5.7388\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.9440 - mean_squared_error: 1.8088 - val_loss: 11.8176 - val_mean_squared_error: 4.7217\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.5011 - mean_squared_error: 1.4052 - val_loss: 9.3554 - val_mean_squared_error: 2.2756\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.7162 - mean_squared_error: 0.6364 - val_loss: 7.8304 - val_mean_squared_error: 0.7599\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.6763 - mean_squared_error: 0.6057 - val_loss: 7.6027 - val_mean_squared_error: 0.5542\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.1536 - mean_squared_error: 1.1051 - val_loss: 7.5566 - val_mean_squared_error: 0.5558\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 8.1502 - mean_squared_error: 1.1493 - val_loss: 7.5590 - val_mean_squared_error: 0.6291\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.6043 - mean_squared_error: 0.6744 - val_loss: 8.4194 - val_mean_squared_error: 1.5697\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.3352 - mean_squared_error: 0.4856 - val_loss: 9.8703 - val_mean_squared_error: 3.0946\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.5810 - mean_squared_error: 0.8053 - val_loss: 10.4630 - val_mean_squared_error: 3.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.7237 - mean_squared_error: 1.0042 - val_loss: 9.5637 - val_mean_squared_error: 2.8803\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.4236 - mean_squared_error: 0.7401 - val_loss: 8.1444 - val_mean_squared_error: 1.4837\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.1146 - mean_squared_error: 0.4539 - val_loss: 7.3177 - val_mean_squared_error: 0.6783\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.1786 - mean_squared_error: 0.5392 - val_loss: 7.0995 - val_mean_squared_error: 0.4932\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.3236 - mean_squared_error: 0.7173 - val_loss: 7.0911 - val_mean_squared_error: 0.5356\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 7.1750 - mean_squared_error: 0.6194 - val_loss: 7.4149 - val_mean_squared_error: 0.9229\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 10.2500 - mean_squared_error: 3.9633 - val_loss: 89.1688 - val_mean_squared_error: 82.4696\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 67.0280 - mean_squared_error: 60.3288 - val_loss: 8.0701 - val_mean_squared_error: 1.7223\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 8.7164 - mean_squared_error: 2.3686 - val_loss: 53.7342 - val_mean_squared_error: 47.6855\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 30.9126 - mean_squared_error: 24.8638 - val_loss: 71.4754 - val_mean_squared_error: 65.5512\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 41.0972 - mean_squared_error: 35.1729 - val_loss: 31.9023 - val_mean_squared_error: 25.9658\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 18.5528 - mean_squared_error: 12.6163 - val_loss: 7.1619 - val_mean_squared_error: 1.1287\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.9591 - mean_squared_error: 0.9260 - val_loss: 19.5498 - val_mean_squared_error: 13.4280\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 18.3955 - mean_squared_error: 12.2738 - val_loss: 28.7927 - val_mean_squared_error: 22.6910\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 25.4244 - mean_squared_error: 19.3227 - val_loss: 16.9303 - val_mean_squared_error: 10.9527\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 16.5341 - mean_squared_error: 10.5565 - val_loss: 6.9465 - val_mean_squared_error: 1.1380\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.3007 - mean_squared_error: 1.4923 - val_loss: 14.6447 - val_mean_squared_error: 8.9979\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 9.1402 - mean_squared_error: 3.4934 - val_loss: 27.6438 - val_mean_squared_error: 22.1229\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 15.6035 - mean_squared_error: 10.0826 - val_loss: 27.8032 - val_mean_squared_error: 22.3585\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 15.6906 - mean_squared_error: 10.2460 - val_loss: 17.0130 - val_mean_squared_error: 11.5956\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.1608 - mean_squared_error: 4.7434 - val_loss: 7.9473 - val_mean_squared_error: 2.5185\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.4214 - mean_squared_error: 0.9926 - val_loss: 7.1032 - val_mean_squared_error: 1.6537\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.8314 - mean_squared_error: 2.3819 - val_loss: 10.1305 - val_mean_squared_error: 4.6862\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 10.9463 - mean_squared_error: 5.5021 - val_loss: 10.1282 - val_mean_squared_error: 4.7348\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.9710 - mean_squared_error: 5.5776 - val_loss: 7.2618 - val_mean_squared_error: 1.9563\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 8.1058 - mean_squared_error: 2.8003 - val_loss: 6.5932 - val_mean_squared_error: 1.3906\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.1125 - mean_squared_error: 0.9099 - val_loss: 10.1207 - val_mean_squared_error: 5.0127\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 6.8418 - mean_squared_error: 1.7338 - val_loss: 14.3761 - val_mean_squared_error: 9.3410\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.6022 - mean_squared_error: 3.5671 - val_loss: 14.9416 - val_mean_squared_error: 9.9497\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 8.8354 - mean_squared_error: 3.8435 - val_loss: 11.5120 - val_mean_squared_error: 6.5387\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.3000 - mean_squared_error: 2.3267 - val_loss: 7.5491 - val_mean_squared_error: 2.5777\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.9157 - mean_squared_error: 0.9443 - val_loss: 5.9955 - val_mean_squared_error: 1.0228\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.1223 - mean_squared_error: 1.1495 - val_loss: 6.4010 - val_mean_squared_error: 1.4428\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.1872 - mean_squared_error: 2.2290 - val_loss: 6.5571 - val_mean_squared_error: 1.6396\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 7.4242 - mean_squared_error: 2.5067 - val_loss: 5.9271 - val_mean_squared_error: 1.0758\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.4918 - mean_squared_error: 1.6406 - val_loss: 6.0055 - val_mean_squared_error: 1.2346\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.6027 - mean_squared_error: 0.8318 - val_loss: 7.6621 - val_mean_squared_error: 2.9727\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 5.6977 - mean_squared_error: 1.0083 - val_loss: 9.6246 - val_mean_squared_error: 5.0056\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.3139 - mean_squared_error: 1.6948 - val_loss: 9.9920 - val_mean_squared_error: 5.4247\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.4265 - mean_squared_error: 1.8593 - val_loss: 8.4755 - val_mean_squared_error: 3.9406\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.8381 - mean_squared_error: 1.3032 - val_loss: 6.5159 - val_mean_squared_error: 2.0007\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.2811 - mean_squared_error: 0.7658 - val_loss: 5.4715 - val_mean_squared_error: 0.9717\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.3365 - mean_squared_error: 0.8367 - val_loss: 5.3097 - val_mean_squared_error: 0.8337\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 14us/step - loss: 5.6987 - mean_squared_error: 1.2227 - val_loss: 5.2664 - val_mean_squared_error: 0.8304\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.7119 - mean_squared_error: 1.2760 - val_loss: 5.2013 - val_mean_squared_error: 0.8214\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.3026 - mean_squared_error: 0.9228 - val_loss: 5.6314 - val_mean_squared_error: 1.3163\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.9811 - mean_squared_error: 0.6660 - val_loss: 6.6413 - val_mean_squared_error: 2.3885\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.0541 - mean_squared_error: 0.8014 - val_loss: 7.4682 - val_mean_squared_error: 3.2685\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.2484 - mean_squared_error: 1.0487 - val_loss: 7.3583 - val_mean_squared_error: 3.1986\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 24us/step - loss: 5.1814 - mean_squared_error: 1.0217 - val_loss: 6.4335 - val_mean_squared_error: 2.3005\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.8937 - mean_squared_error: 0.7608 - val_loss: 5.4532 - val_mean_squared_error: 1.3404\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.7207 - mean_squared_error: 0.6078 - val_loss: 4.9277 - val_mean_squared_error: 0.8367\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7880 - mean_squared_error: 0.6970 - val_loss: 4.7677 - val_mean_squared_error: 0.7061\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.8705 - mean_squared_error: 0.8089 - val_loss: 4.7539 - val_mean_squared_error: 0.7331\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.7612 - mean_squared_error: 0.7404 - val_loss: 4.9521 - val_mean_squared_error: 0.9812\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5640 - mean_squared_error: 0.5931 - val_loss: 5.4588 - val_mean_squared_error: 1.5396\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 5.4077 - mean_squared_error: 1.5738 - val_loss: 76.2880 - val_mean_squared_error: 72.8561\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 31.9441 - mean_squared_error: 28.5122 - val_loss: 11.4198 - val_mean_squared_error: 7.8233\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.0301 - mean_squared_error: 1.4337 - val_loss: 15.7554 - val_mean_squared_error: 11.9455\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 21.2786 - mean_squared_error: 17.4687 - val_loss: 13.8628 - val_mean_squared_error: 10.1387\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 19.1749 - mean_squared_error: 15.4508 - val_loss: 6.7106 - val_mean_squared_error: 3.1587\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.4801 - mean_squared_error: 3.9282 - val_loss: 17.3679 - val_mean_squared_error: 13.9686\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.0549 - mean_squared_error: 2.6555 - val_loss: 34.0931 - val_mean_squared_error: 30.7973\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 23us/step - loss: 11.7704 - mean_squared_error: 8.4746 - val_loss: 34.5756 - val_mean_squared_error: 31.3329\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 12.1943 - mean_squared_error: 8.9516 - val_loss: 21.4098 - val_mean_squared_error: 18.1749\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.4305 - mean_squared_error: 4.1956 - val_loss: 8.9334 - val_mean_squared_error: 5.6653\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.9364 - mean_squared_error: 1.6683 - val_loss: 6.5507 - val_mean_squared_error: 3.2554\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.1560 - mean_squared_error: 4.8607 - val_loss: 6.8076 - val_mean_squared_error: 3.5600\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 8.9348 - mean_squared_error: 5.6872 - val_loss: 6.2887 - val_mean_squared_error: 3.1451\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 6.0944 - mean_squared_error: 2.9508 - val_loss: 9.5258 - val_mean_squared_error: 6.4984\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.6061 - mean_squared_error: 1.5787 - val_loss: 15.5907 - val_mean_squared_error: 12.6547\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 5.5714 - mean_squared_error: 2.6354 - val_loss: 19.3667 - val_mean_squared_error: 16.4886\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.6415 - mean_squared_error: 3.7634 - val_loss: 18.1202 - val_mean_squared_error: 15.2700\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 29us/step - loss: 6.2131 - mean_squared_error: 3.3629 - val_loss: 13.4887 - val_mean_squared_error: 10.6424\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.9292 - mean_squared_error: 2.0829 - val_loss: 8.9498 - val_mean_squared_error: 6.0947\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.2895 - mean_squared_error: 1.4344 - val_loss: 6.4693 - val_mean_squared_error: 3.6093\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.7382 - mean_squared_error: 1.8781 - val_loss: 5.7075 - val_mean_squared_error: 2.8601\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.3412 - mean_squared_error: 2.4938 - val_loss: 5.6747 - val_mean_squared_error: 2.8671\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1276 - mean_squared_error: 2.3200 - val_loss: 6.4473 - val_mean_squared_error: 3.7003\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.3270 - mean_squared_error: 1.5801 - val_loss: 8.5693 - val_mean_squared_error: 5.8898\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8679 - mean_squared_error: 1.1883 - val_loss: 11.4783 - val_mean_squared_error: 8.8604\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.1050 - mean_squared_error: 1.4871 - val_loss: 13.3913 - val_mean_squared_error: 10.8205\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.4753 - mean_squared_error: 1.9046 - val_loss: 12.9425 - val_mean_squared_error: 10.4004\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 4.3380 - mean_squared_error: 1.7959 - val_loss: 10.5523 - val_mean_squared_error: 8.0220\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 3.8153 - mean_squared_error: 1.2850 - val_loss: 7.8332 - val_mean_squared_error: 5.3052\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.5086 - mean_squared_error: 0.9807 - val_loss: 6.0246 - val_mean_squared_error: 3.4987\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6466 - mean_squared_error: 1.1207 - val_loss: 5.2845 - val_mean_squared_error: 2.7741\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8300 - mean_squared_error: 1.3195 - val_loss: 5.3214 - val_mean_squared_error: 2.8451\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6656 - mean_squared_error: 1.1894 - val_loss: 6.1202 - val_mean_squared_error: 3.6926\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.3154 - mean_squared_error: 0.8878 - val_loss: 7.6279 - val_mean_squared_error: 5.2544\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.1944 - mean_squared_error: 0.8210 - val_loss: 9.1004 - val_mean_squared_error: 6.7740\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.3357 - mean_squared_error: 1.0092 - val_loss: 9.4358 - val_mean_squared_error: 7.1423\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.3784 - mean_squared_error: 1.0848 - val_loss: 8.3210 - val_mean_squared_error: 6.0437\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.1657 - mean_squared_error: 0.8883 - val_loss: 6.5802 - val_mean_squared_error: 4.3061\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.9650 - mean_squared_error: 0.6909 - val_loss: 5.2319 - val_mean_squared_error: 2.9601\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9883 - mean_squared_error: 0.7166 - val_loss: 4.6243 - val_mean_squared_error: 2.3665\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 19us/step - loss: 3.0600 - mean_squared_error: 0.8022 - val_loss: 4.6603 - val_mean_squared_error: 2.4338\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.9550 - mean_squared_error: 0.7285 - val_loss: 5.2626 - val_mean_squared_error: 3.0797\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 2.7803 - mean_squared_error: 0.5975 - val_loss: 6.1887 - val_mean_squared_error: 4.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.7462 - mean_squared_error: 0.6100 - val_loss: 6.7958 - val_mean_squared_error: 4.6990\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7926 - mean_squared_error: 0.6959 - val_loss: 6.5326 - val_mean_squared_error: 4.4627\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7308 - mean_squared_error: 0.6609 - val_loss: 5.5701 - val_mean_squared_error: 3.5168\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.5884 - mean_squared_error: 0.5351 - val_loss: 4.5706 - val_mean_squared_error: 2.5305\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5327 - mean_squared_error: 0.4926 - val_loss: 3.9984 - val_mean_squared_error: 1.9773\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5511 - mean_squared_error: 0.5301 - val_loss: 3.9042 - val_mean_squared_error: 1.9142\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.4989 - mean_squared_error: 0.5089 - val_loss: 4.2138 - val_mean_squared_error: 2.2657\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 8.3207 - mean_squared_error: 2.6290 - val_loss: 105.1927 - val_mean_squared_error: 99.9481\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 59.5601 - mean_squared_error: 54.3156 - val_loss: 11.8296 - val_mean_squared_error: 6.3392\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.7581 - mean_squared_error: 2.2678 - val_loss: 31.2429 - val_mean_squared_error: 25.4510\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 27.9703 - mean_squared_error: 22.1783 - val_loss: 37.4037 - val_mean_squared_error: 31.6362\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 32.9899 - mean_squared_error: 27.2225 - val_loss: 11.4891 - val_mean_squared_error: 5.9182\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 12.6988 - mean_squared_error: 7.1280 - val_loss: 11.9421 - val_mean_squared_error: 6.5872\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 7.3552 - mean_squared_error: 2.0002 - val_loss: 36.3621 - val_mean_squared_error: 31.1625\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 18.6779 - mean_squared_error: 13.4784 - val_loss: 40.2372 - val_mean_squared_error: 35.0977\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 20.6114 - mean_squared_error: 15.4719 - val_loss: 23.1472 - val_mean_squared_error: 17.9829\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 12.0470 - mean_squared_error: 6.8827 - val_loss: 8.2636 - val_mean_squared_error: 3.0211\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.2262 - mean_squared_error: 0.9837 - val_loss: 8.2983 - val_mean_squared_error: 2.9743\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.6401 - mean_squared_error: 4.3161 - val_loss: 12.8594 - val_mean_squared_error: 7.5197\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 14.1263 - mean_squared_error: 8.7866 - val_loss: 10.5567 - val_mean_squared_error: 5.2858\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 12.0664 - mean_squared_error: 6.7955 - val_loss: 6.5969 - val_mean_squared_error: 1.4504\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.3674 - mean_squared_error: 2.2208 - val_loss: 8.8997 - val_mean_squared_error: 3.8783\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.1111 - mean_squared_error: 1.0897 - val_loss: 16.0264 - val_mean_squared_error: 11.1019\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.4041 - mean_squared_error: 3.4796 - val_loss: 20.4819 - val_mean_squared_error: 15.6123\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.2437 - mean_squared_error: 5.3741 - val_loss: 18.1507 - val_mean_squared_error: 13.2923\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.2048 - mean_squared_error: 4.3465 - val_loss: 11.8250 - val_mean_squared_error: 6.9459\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.7626 - mean_squared_error: 1.8835 - val_loss: 7.1028 - val_mean_squared_error: 2.1883\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.8271 - mean_squared_error: 0.9126 - val_loss: 6.2627 - val_mean_squared_error: 1.3218\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.0637 - mean_squared_error: 2.1228 - val_loss: 6.8937 - val_mean_squared_error: 1.9578\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.3061 - mean_squared_error: 3.3701 - val_loss: 6.4893 - val_mean_squared_error: 1.5989\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.7173 - mean_squared_error: 2.8269 - val_loss: 6.0682 - val_mean_squared_error: 1.2555\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.1624 - mean_squared_error: 1.3497 - val_loss: 7.8356 - val_mean_squared_error: 3.1125\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.5940 - mean_squared_error: 0.8708 - val_loss: 11.2824 - val_mean_squared_error: 6.6398\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.3545 - mean_squared_error: 1.7120 - val_loss: 13.3999 - val_mean_squared_error: 8.8147\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.0433 - mean_squared_error: 2.4581 - val_loss: 12.3030 - val_mean_squared_error: 7.7483\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.6239 - mean_squared_error: 2.0692 - val_loss: 9.1911 - val_mean_squared_error: 4.6461\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6626 - mean_squared_error: 1.1177 - val_loss: 6.5955 - val_mean_squared_error: 2.0520\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.3295 - mean_squared_error: 0.7859 - val_loss: 5.6414 - val_mean_squared_error: 1.1057\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.8065 - mean_squared_error: 1.2708 - val_loss: 5.5263 - val_mean_squared_error: 1.0184\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.1650 - mean_squared_error: 1.6571 - val_loss: 5.4842 - val_mean_squared_error: 1.0275\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.7919 - mean_squared_error: 1.3353 - val_loss: 5.9835 - val_mean_squared_error: 1.5935\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.1916 - mean_squared_error: 0.8015 - val_loss: 7.5112 - val_mean_squared_error: 3.1916\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.0947 - mean_squared_error: 0.7750 - val_loss: 9.2438 - val_mean_squared_error: 4.9845\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 26us/step - loss: 5.4198 - mean_squared_error: 1.1605 - val_loss: 9.7406 - val_mean_squared_error: 5.5256\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.5299 - mean_squared_error: 1.3149 - val_loss: 8.6099 - val_mean_squared_error: 4.4217\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.1997 - mean_squared_error: 1.0116 - val_loss: 6.8498 - val_mean_squared_error: 2.6764\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.8507 - mean_squared_error: 0.6773 - val_loss: 5.6138 - val_mean_squared_error: 1.4532\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.8661 - mean_squared_error: 0.7055 - val_loss: 5.1360 - val_mean_squared_error: 0.9971\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.0557 - mean_squared_error: 0.9168 - val_loss: 5.0626 - val_mean_squared_error: 0.9600\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.0130 - mean_squared_error: 0.9104 - val_loss: 5.3208 - val_mean_squared_error: 1.2688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.7407 - mean_squared_error: 0.6887 - val_loss: 6.0738 - val_mean_squared_error: 2.0787\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 4.5804 - mean_squared_error: 0.5853 - val_loss: 7.0402 - val_mean_squared_error: 3.0979\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.6534 - mean_squared_error: 0.7111 - val_loss: 7.4955 - val_mean_squared_error: 3.5932\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7240 - mean_squared_error: 0.8217 - val_loss: 7.0479 - val_mean_squared_error: 3.1718\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.6044 - mean_squared_error: 0.7283 - val_loss: 6.0713 - val_mean_squared_error: 2.2121\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.4221 - mean_squared_error: 0.5629 - val_loss: 5.2244 - val_mean_squared_error: 1.3796\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.3788 - mean_squared_error: 0.5339 - val_loss: 4.7959 - val_mean_squared_error: 0.9708\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 7.7605 - mean_squared_error: 2.2783 - val_loss: 40.6862 - val_mean_squared_error: 35.3373\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 42.7684 - mean_squared_error: 37.4195 - val_loss: 8.5679 - val_mean_squared_error: 3.3026\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.2962 - mean_squared_error: 2.0309 - val_loss: 54.5212 - val_mean_squared_error: 49.2708\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 23.8843 - mean_squared_error: 18.6339 - val_loss: 54.9316 - val_mean_squared_error: 49.8553\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 24.3842 - mean_squared_error: 19.3079 - val_loss: 23.1797 - val_mean_squared_error: 18.2844\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.0175 - mean_squared_error: 5.1221 - val_loss: 7.4997 - val_mean_squared_error: 2.7323\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.3450 - mean_squared_error: 2.5776 - val_loss: 11.8088 - val_mean_squared_error: 7.1461\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 14.7904 - mean_squared_error: 10.1277 - val_loss: 11.3854 - val_mean_squared_error: 6.8311\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 14.3426 - mean_squared_error: 9.7884 - val_loss: 7.2776 - val_mean_squared_error: 2.8351\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.4273 - mean_squared_error: 3.9849 - val_loss: 9.7931 - val_mean_squared_error: 5.4545\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.8139 - mean_squared_error: 1.4753 - val_loss: 18.3471 - val_mean_squared_error: 14.0923\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 7.9637 - mean_squared_error: 3.7090 - val_loss: 23.9615 - val_mean_squared_error: 19.7858\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 10.1530 - mean_squared_error: 5.9773 - val_loss: 21.8159 - val_mean_squared_error: 17.7185\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.2995 - mean_squared_error: 5.2022 - val_loss: 14.7113 - val_mean_squared_error: 10.6901\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.6922 - mean_squared_error: 2.6711 - val_loss: 8.5900 - val_mean_squared_error: 4.6382\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 5.3551 - mean_squared_error: 1.4032 - val_loss: 6.3817 - val_mean_squared_error: 2.4943\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.2871 - mean_squared_error: 2.3997 - val_loss: 6.4756 - val_mean_squared_error: 2.6557\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.6584 - mean_squared_error: 3.8385 - val_loss: 6.3451 - val_mean_squared_error: 2.5964\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.4990 - mean_squared_error: 3.7503 - val_loss: 6.0295 - val_mean_squared_error: 2.3499\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.0648 - mean_squared_error: 2.3852 - val_loss: 7.1108 - val_mean_squared_error: 3.4957\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.9890 - mean_squared_error: 1.3739 - val_loss: 9.9038 - val_mean_squared_error: 6.3454\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 38us/step - loss: 5.1278 - mean_squared_error: 1.5694 - val_loss: 12.6896 - val_mean_squared_error: 9.1847\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.8680 - mean_squared_error: 2.3631 - val_loss: 13.3555 - val_mean_squared_error: 9.9039\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.0920 - mean_squared_error: 2.6404 - val_loss: 11.4812 - val_mean_squared_error: 8.0845\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.4846 - mean_squared_error: 2.0879 - val_loss: 8.5441 - val_mean_squared_error: 5.2015\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.7177 - mean_squared_error: 1.3750 - val_loss: 6.2997 - val_mean_squared_error: 3.0086\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5237 - mean_squared_error: 1.2327 - val_loss: 5.3212 - val_mean_squared_error: 2.0812\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.8756 - mean_squared_error: 1.6355 - val_loss: 5.0728 - val_mean_squared_error: 1.8808\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.1521 - mean_squared_error: 1.9601 - val_loss: 5.0056 - val_mean_squared_error: 1.8611\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.9295 - mean_squared_error: 1.7850 - val_loss: 5.2319 - val_mean_squared_error: 2.1379\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4230 - mean_squared_error: 1.3290 - val_loss: 6.0945 - val_mean_squared_error: 3.0511\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.1339 - mean_squared_error: 1.0904 - val_loss: 7.3939 - val_mean_squared_error: 4.3978\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.2358 - mean_squared_error: 1.2397 - val_loss: 8.3361 - val_mean_squared_error: 5.3820\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4384 - mean_squared_error: 1.4843 - val_loss: 8.2465 - val_mean_squared_error: 5.3295\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.3953 - mean_squared_error: 1.4783 - val_loss: 7.2019 - val_mean_squared_error: 4.3198\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.1061 - mean_squared_error: 1.2240 - val_loss: 5.8905 - val_mean_squared_error: 3.0413\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.8574 - mean_squared_error: 1.0082 - val_loss: 4.9355 - val_mean_squared_error: 2.1198\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8402 - mean_squared_error: 1.0245 - val_loss: 4.4745 - val_mean_squared_error: 1.6942\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.9478 - mean_squared_error: 1.1675 - val_loss: 4.3283 - val_mean_squared_error: 1.5862\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.9485 - mean_squared_error: 1.2064 - val_loss: 4.3973 - val_mean_squared_error: 1.6958\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.7777 - mean_squared_error: 1.0763 - val_loss: 4.7466 - val_mean_squared_error: 2.0859\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.5863 - mean_squared_error: 0.9256 - val_loss: 5.3550 - val_mean_squared_error: 2.7315\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.5264 - mean_squared_error: 0.9030 - val_loss: 5.9405 - val_mean_squared_error: 3.3527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.5712 - mean_squared_error: 0.9834 - val_loss: 6.1082 - val_mean_squared_error: 3.5540\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.5742 - mean_squared_error: 1.0200 - val_loss: 5.7339 - val_mean_squared_error: 3.2101\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.4690 - mean_squared_error: 0.9452 - val_loss: 5.0626 - val_mean_squared_error: 2.5678\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.3384 - mean_squared_error: 0.8435 - val_loss: 4.4407 - val_mean_squared_error: 1.9724\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2830 - mean_squared_error: 0.8147 - val_loss: 4.0517 - val_mean_squared_error: 1.6089\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.2967 - mean_squared_error: 0.8539 - val_loss: 3.8959 - val_mean_squared_error: 1.4808\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 18us/step - loss: 3.2890 - mean_squared_error: 0.8739 - val_loss: 3.9305 - val_mean_squared_error: 1.5466\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 6.9200 - mean_squared_error: 0.4280 - val_loss: 39.1427 - val_mean_squared_error: 32.9178\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 23.0551 - mean_squared_error: 16.8301 - val_loss: 8.0020 - val_mean_squared_error: 1.6093\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.9092 - mean_squared_error: 0.5164 - val_loss: 16.7266 - val_mean_squared_error: 10.1402\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 16.0683 - mean_squared_error: 9.4820 - val_loss: 17.9138 - val_mean_squared_error: 11.3431\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 17.0009 - mean_squared_error: 10.4302 - val_loss: 8.3867 - val_mean_squared_error: 1.9403\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 9.1771 - mean_squared_error: 2.7307 - val_loss: 8.6262 - val_mean_squared_error: 2.3192\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 7.0255 - mean_squared_error: 0.7184 - val_loss: 17.8042 - val_mean_squared_error: 11.5969\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 11.2118 - mean_squared_error: 5.0045 - val_loss: 21.2429 - val_mean_squared_error: 15.0776\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 12.9853 - mean_squared_error: 6.8200 - val_loss: 15.4997 - val_mean_squared_error: 9.3253\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 10.0133 - mean_squared_error: 3.8389 - val_loss: 8.4302 - val_mean_squared_error: 2.2141\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.8900 - mean_squared_error: 0.6740 - val_loss: 6.7775 - val_mean_squared_error: 0.5097\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.3664 - mean_squared_error: 1.0987 - val_loss: 8.9357 - val_mean_squared_error: 2.6428\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 9.7465 - mean_squared_error: 3.4537 - val_loss: 9.1690 - val_mean_squared_error: 2.8987\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 9.9704 - mean_squared_error: 3.7001 - val_loss: 7.1697 - val_mean_squared_error: 0.9623\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.9511 - mean_squared_error: 1.7437 - val_loss: 6.7321 - val_mean_squared_error: 0.6049\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.5129 - mean_squared_error: 0.3857 - val_loss: 9.3652 - val_mean_squared_error: 3.3143\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.0979 - mean_squared_error: 1.0470 - val_loss: 12.3291 - val_mean_squared_error: 6.3333\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 8.3421 - mean_squared_error: 2.3463 - val_loss: 12.4382 - val_mean_squared_error: 6.4719\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 8.3769 - mean_squared_error: 2.4105 - val_loss: 9.8345 - val_mean_squared_error: 3.8743\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.2278 - mean_squared_error: 1.2675 - val_loss: 7.1692 - val_mean_squared_error: 1.1969\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.3616 - mean_squared_error: 0.3893 - val_loss: 6.3302 - val_mean_squared_error: 0.3437\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.6629 - mean_squared_error: 0.6765 - val_loss: 6.6969 - val_mean_squared_error: 0.7119\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.4159 - mean_squared_error: 1.4309 - val_loss: 6.7067 - val_mean_squared_error: 0.7483\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.4400 - mean_squared_error: 1.4817 - val_loss: 6.2709 - val_mean_squared_error: 0.3620\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.7153 - mean_squared_error: 0.8064 - val_loss: 6.5479 - val_mean_squared_error: 0.6996\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.1955 - mean_squared_error: 0.3472 - val_loss: 7.9096 - val_mean_squared_error: 2.1189\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.4012 - mean_squared_error: 0.6105 - val_loss: 9.2041 - val_mean_squared_error: 3.4574\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 6.8341 - mean_squared_error: 1.0874 - val_loss: 9.1654 - val_mean_squared_error: 3.4466\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.7998 - mean_squared_error: 1.0810 - val_loss: 7.9057 - val_mean_squared_error: 2.2005\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.3353 - mean_squared_error: 0.6301 - val_loss: 6.6034 - val_mean_squared_error: 0.9013\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.0362 - mean_squared_error: 0.3341 - val_loss: 6.0568 - val_mean_squared_error: 0.3578\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 6.1898 - mean_squared_error: 0.4909 - val_loss: 6.0184 - val_mean_squared_error: 0.3333\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.4338 - mean_squared_error: 0.7486 - val_loss: 5.9759 - val_mean_squared_error: 0.3208\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.3425 - mean_squared_error: 0.6874 - val_loss: 6.0239 - val_mean_squared_error: 0.4129\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 6.0264 - mean_squared_error: 0.4154 - val_loss: 6.5390 - val_mean_squared_error: 0.9766\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.8906 - mean_squared_error: 0.3282 - val_loss: 7.3483 - val_mean_squared_error: 1.8295\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.0227 - mean_squared_error: 0.5040 - val_loss: 7.7570 - val_mean_squared_error: 2.2726\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.1240 - mean_squared_error: 0.6397 - val_loss: 7.3867 - val_mean_squared_error: 1.9267\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.9925 - mean_squared_error: 0.5324 - val_loss: 6.6022 - val_mean_squared_error: 1.1566\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.7910 - mean_squared_error: 0.3454 - val_loss: 6.0029 - val_mean_squared_error: 0.5672\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.7572 - mean_squared_error: 0.3216 - val_loss: 5.7705 - val_mean_squared_error: 0.3490\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.8505 - mean_squared_error: 0.4290 - val_loss: 5.7217 - val_mean_squared_error: 0.3248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.8531 - mean_squared_error: 0.4562 - val_loss: 5.7855 - val_mean_squared_error: 0.4240\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.7192 - mean_squared_error: 0.3578 - val_loss: 6.0770 - val_mean_squared_error: 0.7563\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.6149 - mean_squared_error: 0.2942 - val_loss: 6.5312 - val_mean_squared_error: 1.2499\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.6344 - mean_squared_error: 0.3531 - val_loss: 6.8018 - val_mean_squared_error: 1.5540\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.6704 - mean_squared_error: 0.4226 - val_loss: 6.6435 - val_mean_squared_error: 1.4215\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6104 - mean_squared_error: 0.3884 - val_loss: 6.1978 - val_mean_squared_error: 0.9956\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.5067 - mean_squared_error: 0.3045 - val_loss: 5.7951 - val_mean_squared_error: 0.6101\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.4713 - mean_squared_error: 0.2863 - val_loss: 5.5899 - val_mean_squared_error: 0.4252\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.4931 - mean_squared_error: 0.5739 - val_loss: 13.5760 - val_mean_squared_error: 9.5699\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 14.9372 - mean_squared_error: 10.9310 - val_loss: 5.3282 - val_mean_squared_error: 1.4656\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4110 - mean_squared_error: 0.5484 - val_loss: 21.1669 - val_mean_squared_error: 17.3977\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 10.6873 - mean_squared_error: 6.9181 - val_loss: 21.9992 - val_mean_squared_error: 18.2612\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 11.1762 - mean_squared_error: 7.4381 - val_loss: 11.3139 - val_mean_squared_error: 7.5606\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.1668 - mean_squared_error: 2.4135 - val_loss: 4.7055 - val_mean_squared_error: 0.9062\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.4615 - mean_squared_error: 0.6623 - val_loss: 5.7866 - val_mean_squared_error: 1.9461\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 7.1687 - mean_squared_error: 3.3282 - val_loss: 6.8922 - val_mean_squared_error: 3.0546\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 8.3499 - mean_squared_error: 4.5123 - val_loss: 5.1708 - val_mean_squared_error: 1.3818\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.3494 - mean_squared_error: 2.5604 - val_loss: 4.5682 - val_mean_squared_error: 0.8524\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.4002 - mean_squared_error: 0.6845 - val_loss: 7.3984 - val_mean_squared_error: 3.7540\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7095 - mean_squared_error: 1.0651 - val_loss: 11.0153 - val_mean_squared_error: 7.4232\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 6.1234 - mean_squared_error: 2.5313 - val_loss: 11.6081 - val_mean_squared_error: 8.0448\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 6.3948 - mean_squared_error: 2.8314 - val_loss: 8.9536 - val_mean_squared_error: 5.3946\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.2720 - mean_squared_error: 1.7130 - val_loss: 5.7571 - val_mean_squared_error: 2.1855\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.2250 - mean_squared_error: 0.6534 - val_loss: 4.2937 - val_mean_squared_error: 0.7064\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.3495 - mean_squared_error: 0.7622 - val_loss: 4.4029 - val_mean_squared_error: 0.8100\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1495 - mean_squared_error: 1.5566 - val_loss: 4.5273 - val_mean_squared_error: 0.9517\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.3783 - mean_squared_error: 1.8027 - val_loss: 4.2000 - val_mean_squared_error: 0.6654\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7454 - mean_squared_error: 1.2108 - val_loss: 4.3624 - val_mean_squared_error: 0.8825\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.0742 - mean_squared_error: 0.5943 - val_loss: 5.6394 - val_mean_squared_error: 2.2127\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.0789 - mean_squared_error: 0.6522 - val_loss: 7.2278 - val_mean_squared_error: 3.8439\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5305 - mean_squared_error: 1.1466 - val_loss: 7.7515 - val_mean_squared_error: 4.3956\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7057 - mean_squared_error: 1.3498 - val_loss: 6.8150 - val_mean_squared_error: 3.4736\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 4.3558 - mean_squared_error: 1.0144 - val_loss: 5.2896 - val_mean_squared_error: 1.9525\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.9181 - mean_squared_error: 0.5810 - val_loss: 4.2446 - val_mean_squared_error: 0.9061\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.8701 - mean_squared_error: 0.5315 - val_loss: 3.9263 - val_mean_squared_error: 0.5907\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.1307 - mean_squared_error: 0.7950 - val_loss: 3.8854 - val_mean_squared_error: 0.5664\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.2395 - mean_squared_error: 0.9205 - val_loss: 3.8774 - val_mean_squared_error: 0.5892\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.0118 - mean_squared_error: 0.7236 - val_loss: 4.1635 - val_mean_squared_error: 0.9152\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.7335 - mean_squared_error: 0.4852 - val_loss: 4.9103 - val_mean_squared_error: 1.7017\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 33us/step - loss: 3.7115 - mean_squared_error: 0.5029 - val_loss: 5.6979 - val_mean_squared_error: 2.5229\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.8687 - mean_squared_error: 0.6936 - val_loss: 5.8761 - val_mean_squared_error: 2.7251\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.9046 - mean_squared_error: 0.7536 - val_loss: 5.3072 - val_mean_squared_error: 2.1719\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.7309 - mean_squared_error: 0.5956 - val_loss: 4.4808 - val_mean_squared_error: 1.3540\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.5605 - mean_squared_error: 0.4336 - val_loss: 3.9096 - val_mean_squared_error: 0.7883\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.5678 - mean_squared_error: 0.4466 - val_loss: 3.6858 - val_mean_squared_error: 0.5753\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.6565 - mean_squared_error: 0.5459 - val_loss: 3.6476 - val_mean_squared_error: 0.5573\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.6336 - mean_squared_error: 0.5433 - val_loss: 3.7628 - val_mean_squared_error: 0.7015\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.4975 - mean_squared_error: 0.4363 - val_loss: 4.1112 - val_mean_squared_error: 1.0812\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.4125 - mean_squared_error: 0.3826 - val_loss: 4.5691 - val_mean_squared_error: 1.5686\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.4420 - mean_squared_error: 0.4415 - val_loss: 4.7919 - val_mean_squared_error: 1.8172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.4716 - mean_squared_error: 0.4969 - val_loss: 4.5819 - val_mean_squared_error: 1.6264\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.4069 - mean_squared_error: 0.4514 - val_loss: 4.1121 - val_mean_squared_error: 1.1699\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.3099 - mean_squared_error: 0.3677 - val_loss: 3.7031 - val_mean_squared_error: 0.7702\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.2846 - mean_squared_error: 0.3517 - val_loss: 3.4959 - val_mean_squared_error: 0.5752\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.3087 - mean_squared_error: 0.3880 - val_loss: 3.4491 - val_mean_squared_error: 0.5479\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.2882 - mean_squared_error: 0.3870 - val_loss: 3.5353 - val_mean_squared_error: 0.6600\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.2153 - mean_squared_error: 0.3400 - val_loss: 3.7549 - val_mean_squared_error: 0.9075\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.1672 - mean_squared_error: 0.3198 - val_loss: 3.9960 - val_mean_squared_error: 1.1742\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.3860 - mean_squared_error: 0.4379 - val_loss: 18.0820 - val_mean_squared_error: 16.3162\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 7.2938 - mean_squared_error: 5.5279 - val_loss: 4.5546 - val_mean_squared_error: 2.6723\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3243 - mean_squared_error: 0.4421 - val_loss: 3.6615 - val_mean_squared_error: 1.6568\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.5000 - mean_squared_error: 3.4953 - val_loss: 3.4186 - val_mean_squared_error: 1.4369\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.1073 - mean_squared_error: 3.1256 - val_loss: 3.1122 - val_mean_squared_error: 1.2115\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6806 - mean_squared_error: 0.7799 - val_loss: 6.9490 - val_mean_squared_error: 5.1239\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6883 - mean_squared_error: 0.8633 - val_loss: 10.8684 - val_mean_squared_error: 9.0999\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.9571 - mean_squared_error: 2.1886 - val_loss: 10.2643 - val_mean_squared_error: 8.5206\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.6951 - mean_squared_error: 1.9513 - val_loss: 7.0613 - val_mean_squared_error: 5.3097\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.6291 - mean_squared_error: 0.8775 - val_loss: 4.2879 - val_mean_squared_error: 2.5085\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.2406 - mean_squared_error: 0.4612 - val_loss: 3.1469 - val_mean_squared_error: 1.3452\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.7222 - mean_squared_error: 0.9204 - val_loss: 2.9779 - val_mean_squared_error: 1.1785\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.0929 - mean_squared_error: 1.2936 - val_loss: 3.1389 - val_mean_squared_error: 1.3700\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.7779 - mean_squared_error: 1.0091 - val_loss: 3.9560 - val_mean_squared_error: 2.2333\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.2697 - mean_squared_error: 0.5470 - val_loss: 5.6651 - val_mean_squared_error: 3.9887\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2009 - mean_squared_error: 0.5245 - val_loss: 7.4791 - val_mean_squared_error: 5.8388\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.5146 - mean_squared_error: 0.8742 - val_loss: 8.1376 - val_mean_squared_error: 6.5199\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6641 - mean_squared_error: 1.0464 - val_loss: 7.2487 - val_mean_squared_error: 5.6436\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.4191 - mean_squared_error: 0.8140 - val_loss: 5.6030 - val_mean_squared_error: 4.0025\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.1093 - mean_squared_error: 0.5088 - val_loss: 4.2201 - val_mean_squared_error: 2.6147\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.0909 - mean_squared_error: 0.4855 - val_loss: 3.5266 - val_mean_squared_error: 1.9186\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2776 - mean_squared_error: 0.6696 - val_loss: 3.3875 - val_mean_squared_error: 1.7923\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.3267 - mean_squared_error: 0.7315 - val_loss: 3.6820 - val_mean_squared_error: 2.1154\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.1461 - mean_squared_error: 0.5794 - val_loss: 4.4531 - val_mean_squared_error: 2.9245\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.9683 - mean_squared_error: 0.4397 - val_loss: 5.5307 - val_mean_squared_error: 4.0390\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.9839 - mean_squared_error: 0.4922 - val_loss: 6.3476 - val_mean_squared_error: 4.8845\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.0909 - mean_squared_error: 0.6278 - val_loss: 6.3749 - val_mean_squared_error: 4.9305\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.0796 - mean_squared_error: 0.6352 - val_loss: 5.6377 - val_mean_squared_error: 4.2021\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9401 - mean_squared_error: 0.5045 - val_loss: 4.6540 - val_mean_squared_error: 3.2197\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.8439 - mean_squared_error: 0.4096 - val_loss: 3.9184 - val_mean_squared_error: 2.4845\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.8747 - mean_squared_error: 0.4409 - val_loss: 3.5921 - val_mean_squared_error: 2.1668\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.9222 - mean_squared_error: 0.4969 - val_loss: 3.6519 - val_mean_squared_error: 2.2459\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.8712 - mean_squared_error: 0.4652 - val_loss: 4.0595 - val_mean_squared_error: 2.6813\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 1.7692 - mean_squared_error: 0.3909 - val_loss: 4.6821 - val_mean_squared_error: 3.3319\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.7329 - mean_squared_error: 0.3827 - val_loss: 5.1856 - val_mean_squared_error: 3.8593\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 1.7582 - mean_squared_error: 0.4319 - val_loss: 5.2268 - val_mean_squared_error: 3.9170\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.7490 - mean_squared_error: 0.4392 - val_loss: 4.7779 - val_mean_squared_error: 3.4761\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.6830 - mean_squared_error: 0.3812 - val_loss: 4.1496 - val_mean_squared_error: 2.8498\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.6382 - mean_squared_error: 0.3385 - val_loss: 3.6785 - val_mean_squared_error: 2.3799\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.6487 - mean_squared_error: 0.3501 - val_loss: 3.5102 - val_mean_squared_error: 2.2197\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.6498 - mean_squared_error: 0.3592 - val_loss: 3.6433 - val_mean_squared_error: 2.3687\n",
      "Epoch 142/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 31us/step - loss: 1.6047 - mean_squared_error: 0.3301 - val_loss: 3.9962 - val_mean_squared_error: 2.7420\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5635 - mean_squared_error: 0.3094 - val_loss: 4.3567 - val_mean_squared_error: 3.1216\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.5614 - mean_squared_error: 0.3262 - val_loss: 4.4551 - val_mean_squared_error: 3.2344\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5567 - mean_squared_error: 0.3360 - val_loss: 4.1962 - val_mean_squared_error: 2.9854\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 1.5188 - mean_squared_error: 0.3080 - val_loss: 3.7632 - val_mean_squared_error: 2.5584\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4850 - mean_squared_error: 0.2802 - val_loss: 3.4165 - val_mean_squared_error: 2.2177\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4801 - mean_squared_error: 0.2812 - val_loss: 3.2969 - val_mean_squared_error: 2.1088\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 27us/step - loss: 1.4698 - mean_squared_error: 0.2817 - val_loss: 3.4149 - val_mean_squared_error: 2.2432\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.4356 - mean_squared_error: 0.2639 - val_loss: 3.6720 - val_mean_squared_error: 2.5186\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.4352 - mean_squared_error: 0.6101 - val_loss: 26.9384 - val_mean_squared_error: 23.2888\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 13.4624 - mean_squared_error: 9.8128 - val_loss: 6.6648 - val_mean_squared_error: 2.8985\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4692 - mean_squared_error: 0.7029 - val_loss: 7.2441 - val_mean_squared_error: 3.3221\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 8.7295 - mean_squared_error: 4.8076 - val_loss: 8.0581 - val_mean_squared_error: 4.1459\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 9.5568 - mean_squared_error: 5.6447 - val_loss: 4.5538 - val_mean_squared_error: 0.7393\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.4920 - mean_squared_error: 1.6776 - val_loss: 6.7926 - val_mean_squared_error: 3.0790\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.4499 - mean_squared_error: 0.7362 - val_loss: 12.9177 - val_mean_squared_error: 9.2765\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 6.6950 - mean_squared_error: 3.0538 - val_loss: 13.6885 - val_mean_squared_error: 10.0791\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 7.0510 - mean_squared_error: 3.4416 - val_loss: 9.4232 - val_mean_squared_error: 5.8021\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.2878 - mean_squared_error: 1.6667 - val_loss: 5.2890 - val_mean_squared_error: 1.6252\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.1501 - mean_squared_error: 0.4864 - val_loss: 4.2764 - val_mean_squared_error: 0.5656\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.8872 - mean_squared_error: 1.1764 - val_loss: 4.7354 - val_mean_squared_error: 1.0113\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.8295 - mean_squared_error: 2.1054 - val_loss: 4.4346 - val_mean_squared_error: 0.7419\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.3476 - mean_squared_error: 1.6549 - val_loss: 4.2880 - val_mean_squared_error: 0.6565\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.3044 - mean_squared_error: 0.6728 - val_loss: 5.7834 - val_mean_squared_error: 2.2186\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.1239 - mean_squared_error: 0.5592 - val_loss: 8.0827 - val_mean_squared_error: 4.5687\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7535 - mean_squared_error: 1.2394 - val_loss: 8.9461 - val_mean_squared_error: 5.4608\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.0583 - mean_squared_error: 1.5730 - val_loss: 7.6315 - val_mean_squared_error: 4.1561\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.5836 - mean_squared_error: 1.1082 - val_loss: 5.5193 - val_mean_squared_error: 2.0386\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.0042 - mean_squared_error: 0.5236 - val_loss: 4.2370 - val_mean_squared_error: 0.7456\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.0251 - mean_squared_error: 0.5337 - val_loss: 3.9814 - val_mean_squared_error: 0.4898\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.4212 - mean_squared_error: 0.9296 - val_loss: 3.9583 - val_mean_squared_error: 0.4880\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 4.4727 - mean_squared_error: 1.0024 - val_loss: 3.9738 - val_mean_squared_error: 0.5434\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.0835 - mean_squared_error: 0.6531 - val_loss: 4.5404 - val_mean_squared_error: 1.1565\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 38us/step - loss: 3.8036 - mean_squared_error: 0.4197 - val_loss: 5.6627 - val_mean_squared_error: 2.3208\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.9281 - mean_squared_error: 0.5862 - val_loss: 6.4627 - val_mean_squared_error: 3.1514\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.1348 - mean_squared_error: 0.8234 - val_loss: 6.2027 - val_mean_squared_error: 2.9107\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.0483 - mean_squared_error: 0.7563 - val_loss: 5.1729 - val_mean_squared_error: 1.8904\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.7774 - mean_squared_error: 0.4950 - val_loss: 4.2292 - val_mean_squared_error: 0.9497\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6772 - mean_squared_error: 0.3977 - val_loss: 3.8029 - val_mean_squared_error: 0.5296\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.8003 - mean_squared_error: 0.5270 - val_loss: 3.7063 - val_mean_squared_error: 0.4502\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.8649 - mean_squared_error: 0.6089 - val_loss: 3.7577 - val_mean_squared_error: 0.5302\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.7262 - mean_squared_error: 0.4987 - val_loss: 4.0808 - val_mean_squared_error: 0.8886\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.5705 - mean_squared_error: 0.3783 - val_loss: 4.6773 - val_mean_squared_error: 1.5190\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.5796 - mean_squared_error: 0.4214 - val_loss: 5.1353 - val_mean_squared_error: 2.0052\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6566 - mean_squared_error: 0.5265 - val_loss: 5.0459 - val_mean_squared_error: 1.9379\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6196 - mean_squared_error: 0.5116 - val_loss: 4.4997 - val_mean_squared_error: 1.4061\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.4936 - mean_squared_error: 0.4000 - val_loss: 3.9393 - val_mean_squared_error: 0.8541\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.4382 - mean_squared_error: 0.3530 - val_loss: 3.6358 - val_mean_squared_error: 0.5605\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.4783 - mean_squared_error: 0.4031 - val_loss: 3.5560 - val_mean_squared_error: 0.4974\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.4863 - mean_squared_error: 0.4277 - val_loss: 3.6382 - val_mean_squared_error: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.4079 - mean_squared_error: 0.3749 - val_loss: 3.9088 - val_mean_squared_error: 0.9059\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.3391 - mean_squared_error: 0.3361 - val_loss: 4.2686 - val_mean_squared_error: 1.2943\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 3.3438 - mean_squared_error: 0.3695 - val_loss: 4.4446 - val_mean_squared_error: 1.4948\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.3548 - mean_squared_error: 0.4051 - val_loss: 4.2780 - val_mean_squared_error: 1.3472\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.3070 - mean_squared_error: 0.3762 - val_loss: 3.9125 - val_mean_squared_error: 0.9942\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.2455 - mean_squared_error: 0.3272 - val_loss: 3.6009 - val_mean_squared_error: 0.6923\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2323 - mean_squared_error: 0.3237 - val_loss: 3.4517 - val_mean_squared_error: 0.5567\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2385 - mean_squared_error: 0.3435 - val_loss: 3.4486 - val_mean_squared_error: 0.5738\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.2085 - mean_squared_error: 0.3337 - val_loss: 3.5779 - val_mean_squared_error: 0.7277\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2124 - mean_squared_error: 0.8285 - val_loss: 15.7893 - val_mean_squared_error: 13.4168\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 7.6311 - mean_squared_error: 5.2586 - val_loss: 5.0287 - val_mean_squared_error: 2.6388\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.2209 - mean_squared_error: 0.8310 - val_loss: 4.2412 - val_mean_squared_error: 1.8086\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.4045 - mean_squared_error: 2.9720 - val_loss: 4.4112 - val_mean_squared_error: 2.0034\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.6844 - mean_squared_error: 3.2766 - val_loss: 3.4333 - val_mean_squared_error: 1.0723\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.7406 - mean_squared_error: 1.3797 - val_loss: 5.1095 - val_mean_squared_error: 2.7780\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.1552 - mean_squared_error: 0.8237 - val_loss: 8.4451 - val_mean_squared_error: 6.1272\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.1257 - mean_squared_error: 1.8078 - val_loss: 9.3838 - val_mean_squared_error: 7.0791\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.4736 - mean_squared_error: 2.1689 - val_loss: 7.3419 - val_mean_squared_error: 5.0586\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 3.7006 - mean_squared_error: 1.4172 - val_loss: 4.7498 - val_mean_squared_error: 2.4799\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.0412 - mean_squared_error: 0.7713 - val_loss: 3.4766 - val_mean_squared_error: 1.2152\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.2690 - mean_squared_error: 1.0077 - val_loss: 3.3054 - val_mean_squared_error: 1.0606\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.7386 - mean_squared_error: 1.4938 - val_loss: 3.2675 - val_mean_squared_error: 1.0499\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.6075 - mean_squared_error: 1.3900 - val_loss: 3.4594 - val_mean_squared_error: 1.2722\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.1150 - mean_squared_error: 0.9278 - val_loss: 4.3551 - val_mean_squared_error: 2.1911\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.8893 - mean_squared_error: 0.7253 - val_loss: 5.6867 - val_mean_squared_error: 3.5396\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 3.0784 - mean_squared_error: 0.9313 - val_loss: 6.4737 - val_mean_squared_error: 4.3440\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2793 - mean_squared_error: 1.1496 - val_loss: 6.0961 - val_mean_squared_error: 3.9853\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.1623 - mean_squared_error: 1.0514 - val_loss: 4.9383 - val_mean_squared_error: 2.8477\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.8769 - mean_squared_error: 0.7862 - val_loss: 3.8417 - val_mean_squared_error: 1.7658\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7657 - mean_squared_error: 0.6898 - val_loss: 3.2637 - val_mean_squared_error: 1.1994\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.8859 - mean_squared_error: 0.8216 - val_loss: 3.0914 - val_mean_squared_error: 1.0436\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.9740 - mean_squared_error: 0.9262 - val_loss: 3.1333 - val_mean_squared_error: 1.1072\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.8654 - mean_squared_error: 0.8393 - val_loss: 3.4445 - val_mean_squared_error: 1.4404\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6869 - mean_squared_error: 0.6828 - val_loss: 4.0638 - val_mean_squared_error: 2.0802\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.6360 - mean_squared_error: 0.6525 - val_loss: 4.6976 - val_mean_squared_error: 2.7324\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7088 - mean_squared_error: 0.7436 - val_loss: 4.8822 - val_mean_squared_error: 2.9350\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7334 - mean_squared_error: 0.7862 - val_loss: 4.4749 - val_mean_squared_error: 2.5458\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.6340 - mean_squared_error: 0.7049 - val_loss: 3.7854 - val_mean_squared_error: 1.8732\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.5212 - mean_squared_error: 0.6090 - val_loss: 3.2177 - val_mean_squared_error: 1.3204\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.5070 - mean_squared_error: 0.6097 - val_loss: 2.9304 - val_mean_squared_error: 1.0476\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.5461 - mean_squared_error: 0.6633 - val_loss: 2.8691 - val_mean_squared_error: 1.0033\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.5243 - mean_squared_error: 0.6584 - val_loss: 2.9984 - val_mean_squared_error: 1.1515\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.4368 - mean_squared_error: 0.5899 - val_loss: 3.3091 - val_mean_squared_error: 1.4802\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3778 - mean_squared_error: 0.5489 - val_loss: 3.6605 - val_mean_squared_error: 1.8486\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.3833 - mean_squared_error: 0.5714 - val_loss: 3.7909 - val_mean_squared_error: 1.9962\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.3869 - mean_squared_error: 0.5922 - val_loss: 3.5741 - val_mean_squared_error: 1.7983\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.3337 - mean_squared_error: 0.5578 - val_loss: 3.1654 - val_mean_squared_error: 1.4057\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.2697 - mean_squared_error: 0.5100 - val_loss: 2.8080 - val_mean_squared_error: 1.0614\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.2499 - mean_squared_error: 0.5032 - val_loss: 2.6141 - val_mean_squared_error: 0.8812\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.2516 - mean_squared_error: 0.5187 - val_loss: 2.5764 - val_mean_squared_error: 0.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.2235 - mean_squared_error: 0.5061 - val_loss: 2.6736 - val_mean_squared_error: 0.9738\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.1704 - mean_squared_error: 0.4706 - val_loss: 2.8642 - val_mean_squared_error: 1.1814\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 18us/step - loss: 2.1388 - mean_squared_error: 0.4559 - val_loss: 3.0186 - val_mean_squared_error: 1.3508\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.1321 - mean_squared_error: 0.4643 - val_loss: 2.9884 - val_mean_squared_error: 1.3358\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.1106 - mean_squared_error: 0.4580 - val_loss: 2.7720 - val_mean_squared_error: 1.1340\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.0682 - mean_squared_error: 0.4302 - val_loss: 2.5091 - val_mean_squared_error: 0.8836\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.0380 - mean_squared_error: 0.4125 - val_loss: 2.3249 - val_mean_squared_error: 0.7122\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.0260 - mean_squared_error: 0.4134 - val_loss: 2.2531 - val_mean_squared_error: 0.6529\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.0072 - mean_squared_error: 0.4070 - val_loss: 2.2781 - val_mean_squared_error: 0.6913\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 5.4920 - mean_squared_error: 0.3273 - val_loss: 7.3926 - val_mean_squared_error: 2.2676\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.7852 - mean_squared_error: 0.6602 - val_loss: 6.2133 - val_mean_squared_error: 1.0821\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.4496 - mean_squared_error: 0.3184 - val_loss: 5.4913 - val_mean_squared_error: 0.3497\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.5081 - mean_squared_error: 0.3665 - val_loss: 5.4231 - val_mean_squared_error: 0.2914\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.5771 - mean_squared_error: 0.4454 - val_loss: 5.5480 - val_mean_squared_error: 0.4425\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 5.4201 - mean_squared_error: 0.3146 - val_loss: 6.0019 - val_mean_squared_error: 0.9268\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 5.3642 - mean_squared_error: 0.2891 - val_loss: 6.4789 - val_mean_squared_error: 1.4302\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.4358 - mean_squared_error: 0.3872 - val_loss: 6.4592 - val_mean_squared_error: 1.4291\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 5.4161 - mean_squared_error: 0.3860 - val_loss: 6.0408 - val_mean_squared_error: 1.0213\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.3186 - mean_squared_error: 0.2991 - val_loss: 5.6269 - val_mean_squared_error: 0.6139\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.2863 - mean_squared_error: 0.2733 - val_loss: 5.4249 - val_mean_squared_error: 0.4223\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.3186 - mean_squared_error: 0.3160 - val_loss: 5.3939 - val_mean_squared_error: 0.4099\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.3050 - mean_squared_error: 0.3211 - val_loss: 5.4990 - val_mean_squared_error: 0.5406\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.2381 - mean_squared_error: 0.2798 - val_loss: 5.7421 - val_mean_squared_error: 0.8118\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 5.1991 - mean_squared_error: 0.2688 - val_loss: 5.9996 - val_mean_squared_error: 1.0950\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.2076 - mean_squared_error: 0.3030 - val_loss: 6.0656 - val_mean_squared_error: 1.1830\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.2005 - mean_squared_error: 0.3178 - val_loss: 5.8899 - val_mean_squared_error: 1.0256\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.1529 - mean_squared_error: 0.2886 - val_loss: 5.6185 - val_mean_squared_error: 0.7693\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.1110 - mean_squared_error: 0.2618 - val_loss: 5.4126 - val_mean_squared_error: 0.5784\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 5.1030 - mean_squared_error: 0.2688 - val_loss: 5.3283 - val_mean_squared_error: 0.5127\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.0960 - mean_squared_error: 0.2804 - val_loss: 5.3573 - val_mean_squared_error: 0.5652\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.0618 - mean_squared_error: 0.2697 - val_loss: 5.4857 - val_mean_squared_error: 0.7197\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 5.0229 - mean_squared_error: 0.2570 - val_loss: 5.6554 - val_mean_squared_error: 0.9158\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 5.0050 - mean_squared_error: 0.2655 - val_loss: 5.7493 - val_mean_squared_error: 1.0341\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.9938 - mean_squared_error: 0.2787 - val_loss: 5.6907 - val_mean_squared_error: 0.9970\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.9660 - mean_squared_error: 0.2723 - val_loss: 5.5222 - val_mean_squared_error: 0.8475\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.9309 - mean_squared_error: 0.2563 - val_loss: 5.3512 - val_mean_squared_error: 0.6944\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.9090 - mean_squared_error: 0.2522 - val_loss: 5.2517 - val_mean_squared_error: 0.6146\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.8941 - mean_squared_error: 0.2571 - val_loss: 5.2417 - val_mean_squared_error: 0.6278\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.8689 - mean_squared_error: 0.2550 - val_loss: 5.3111 - val_mean_squared_error: 0.7228\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 4.8372 - mean_squared_error: 0.2489 - val_loss: 5.4189 - val_mean_squared_error: 0.8565\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.8136 - mean_squared_error: 0.2512 - val_loss: 5.4884 - val_mean_squared_error: 0.9508\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7956 - mean_squared_error: 0.2579 - val_loss: 5.4602 - val_mean_squared_error: 0.9457\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.7708 - mean_squared_error: 0.2563 - val_loss: 5.3478 - val_mean_squared_error: 0.8546\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.7413 - mean_squared_error: 0.2480 - val_loss: 5.2202 - val_mean_squared_error: 0.7474\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.7173 - mean_squared_error: 0.2445 - val_loss: 5.1395 - val_mean_squared_error: 0.6879\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.6974 - mean_squared_error: 0.2458 - val_loss: 5.1282 - val_mean_squared_error: 0.7002\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 4.6727 - mean_squared_error: 0.2446 - val_loss: 5.1771 - val_mean_squared_error: 0.7743\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.6449 - mean_squared_error: 0.2422 - val_loss: 5.2468 - val_mean_squared_error: 0.8695\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.6214 - mean_squared_error: 0.2441 - val_loss: 5.2786 - val_mean_squared_error: 0.9256\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 21us/step - loss: 4.6000 - mean_squared_error: 0.2470 - val_loss: 5.2368 - val_mean_squared_error: 0.9070\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5746 - mean_squared_error: 0.2448 - val_loss: 5.1439 - val_mean_squared_error: 0.8360\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5484 - mean_squared_error: 0.2404 - val_loss: 5.0544 - val_mean_squared_error: 0.7678\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 4.5255 - mean_squared_error: 0.2390 - val_loss: 5.0074 - val_mean_squared_error: 0.7432\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.5030 - mean_squared_error: 0.2388 - val_loss: 5.0126 - val_mean_squared_error: 0.7723\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4780 - mean_squared_error: 0.2377 - val_loss: 5.0511 - val_mean_squared_error: 0.8355\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4531 - mean_squared_error: 0.2376 - val_loss: 5.0822 - val_mean_squared_error: 0.8910\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 4.4303 - mean_squared_error: 0.2391 - val_loss: 5.0686 - val_mean_squared_error: 0.9008\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 4.4067 - mean_squared_error: 0.2389 - val_loss: 5.0084 - val_mean_squared_error: 0.8632\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 4.3815 - mean_squared_error: 0.2363 - val_loss: 4.9340 - val_mean_squared_error: 0.8106\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1697 - mean_squared_error: 0.3478 - val_loss: 3.2074 - val_mean_squared_error: 0.3575\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.3964 - mean_squared_error: 0.5466 - val_loss: 3.4724 - val_mean_squared_error: 0.6468\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.1408 - mean_squared_error: 0.3153 - val_loss: 4.2432 - val_mean_squared_error: 1.4451\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.2051 - mean_squared_error: 0.4070 - val_loss: 4.4083 - val_mean_squared_error: 1.6244\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.2399 - mean_squared_error: 0.4560 - val_loss: 3.9345 - val_mean_squared_error: 1.1542\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1205 - mean_squared_error: 0.3401 - val_loss: 3.4495 - val_mean_squared_error: 0.6683\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.0809 - mean_squared_error: 0.2997 - val_loss: 3.2409 - val_mean_squared_error: 0.4632\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 46us/step - loss: 3.1328 - mean_squared_error: 0.3551 - val_loss: 3.2269 - val_mean_squared_error: 0.4624\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.1175 - mean_squared_error: 0.3529 - val_loss: 3.3584 - val_mean_squared_error: 0.6126\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.0448 - mean_squared_error: 0.2991 - val_loss: 3.6318 - val_mean_squared_error: 0.9059\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.0171 - mean_squared_error: 0.2911 - val_loss: 3.8867 - val_mean_squared_error: 1.1793\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 3.0375 - mean_squared_error: 0.3301 - val_loss: 3.9114 - val_mean_squared_error: 1.2187\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.0293 - mean_squared_error: 0.3367 - val_loss: 3.7013 - val_mean_squared_error: 1.0195\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.9799 - mean_squared_error: 0.2982 - val_loss: 3.4305 - val_mean_squared_error: 0.7566\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9459 - mean_squared_error: 0.2719 - val_loss: 3.2460 - val_mean_squared_error: 0.5800\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.9481 - mean_squared_error: 0.2820 - val_loss: 3.1806 - val_mean_squared_error: 0.5264\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.9451 - mean_squared_error: 0.2910 - val_loss: 3.2179 - val_mean_squared_error: 0.5805\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.9124 - mean_squared_error: 0.2749 - val_loss: 3.3456 - val_mean_squared_error: 0.7272\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.8779 - mean_squared_error: 0.2595 - val_loss: 3.5097 - val_mean_squared_error: 0.9099\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 32us/step - loss: 2.8673 - mean_squared_error: 0.2676 - val_loss: 3.5986 - val_mean_squared_error: 1.0159\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.8622 - mean_squared_error: 0.2795 - val_loss: 3.5414 - val_mean_squared_error: 0.9733\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 45us/step - loss: 2.8386 - mean_squared_error: 0.2704 - val_loss: 3.3817 - val_mean_squared_error: 0.8255\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.8074 - mean_squared_error: 0.2512 - val_loss: 3.2217 - val_mean_squared_error: 0.6762\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7905 - mean_squared_error: 0.2451 - val_loss: 3.1287 - val_mean_squared_error: 0.5952\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7822 - mean_squared_error: 0.2488 - val_loss: 3.1171 - val_mean_squared_error: 0.5990\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7632 - mean_squared_error: 0.2450 - val_loss: 3.1788 - val_mean_squared_error: 0.6779\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.7366 - mean_squared_error: 0.2357 - val_loss: 3.2802 - val_mean_squared_error: 0.7973\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.7176 - mean_squared_error: 0.2348 - val_loss: 3.3530 - val_mean_squared_error: 0.8872\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.7058 - mean_squared_error: 0.2400 - val_loss: 3.3370 - val_mean_squared_error: 0.8867\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.6877 - mean_squared_error: 0.2373 - val_loss: 3.2401 - val_mean_squared_error: 0.8036\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6636 - mean_squared_error: 0.2270 - val_loss: 3.1240 - val_mean_squared_error: 0.7001\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6447 - mean_squared_error: 0.2208 - val_loss: 3.0464 - val_mean_squared_error: 0.6360\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.6308 - mean_squared_error: 0.2204 - val_loss: 3.0289 - val_mean_squared_error: 0.6342\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.6125 - mean_squared_error: 0.2178 - val_loss: 3.0681 - val_mean_squared_error: 0.6906\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.5903 - mean_squared_error: 0.2129 - val_loss: 3.1332 - val_mean_squared_error: 0.7732\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5721 - mean_squared_error: 0.2120 - val_loss: 3.1724 - val_mean_squared_error: 0.8292\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5566 - mean_squared_error: 0.2134 - val_loss: 3.1489 - val_mean_squared_error: 0.8215\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.5378 - mean_squared_error: 0.2104 - val_loss: 3.0729 - val_mean_squared_error: 0.7605\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.5168 - mean_squared_error: 0.2043 - val_loss: 2.9932 - val_mean_squared_error: 0.6950\n",
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.4993 - mean_squared_error: 0.2011 - val_loss: 2.9499 - val_mean_squared_error: 0.6665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.4831 - mean_squared_error: 0.1997 - val_loss: 2.9541 - val_mean_squared_error: 0.6871\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.4639 - mean_squared_error: 0.1970 - val_loss: 2.9911 - val_mean_squared_error: 0.7413\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.4446 - mean_squared_error: 0.1949 - val_loss: 3.0279 - val_mean_squared_error: 0.7950\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.4278 - mean_squared_error: 0.1950 - val_loss: 3.0272 - val_mean_squared_error: 0.8104\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.4105 - mean_squared_error: 0.1938 - val_loss: 2.9801 - val_mean_squared_error: 0.7785\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 23us/step - loss: 2.3914 - mean_squared_error: 0.1898 - val_loss: 2.9187 - val_mean_squared_error: 0.7315\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3736 - mean_squared_error: 0.1864 - val_loss: 2.8782 - val_mean_squared_error: 0.7058\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.3569 - mean_squared_error: 0.1845 - val_loss: 2.8733 - val_mean_squared_error: 0.7168\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 14us/step - loss: 2.3391 - mean_squared_error: 0.1826 - val_loss: 2.8958 - val_mean_squared_error: 0.7558\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.3209 - mean_squared_error: 0.1809 - val_loss: 2.9162 - val_mean_squared_error: 0.7926\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 1.4105 - mean_squared_error: 0.2571 - val_loss: 3.2839 - val_mean_squared_error: 2.1525\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4218 - mean_squared_error: 0.2904 - val_loss: 4.2344 - val_mean_squared_error: 3.1223\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4048 - mean_squared_error: 0.2928 - val_loss: 4.1427 - val_mean_squared_error: 3.0423\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3830 - mean_squared_error: 0.2826 - val_loss: 3.6027 - val_mean_squared_error: 2.5028\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3548 - mean_squared_error: 0.2550 - val_loss: 3.3412 - val_mean_squared_error: 2.2455\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3634 - mean_squared_error: 0.2677 - val_loss: 3.4951 - val_mean_squared_error: 2.4121\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3362 - mean_squared_error: 0.2532 - val_loss: 3.8410 - val_mean_squared_error: 2.7740\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3200 - mean_squared_error: 0.2530 - val_loss: 4.0248 - val_mean_squared_error: 2.9705\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3193 - mean_squared_error: 0.2650 - val_loss: 3.8686 - val_mean_squared_error: 2.8212\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.2984 - mean_squared_error: 0.2510 - val_loss: 3.5708 - val_mean_squared_error: 2.5282\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.2813 - mean_squared_error: 0.2387 - val_loss: 3.3905 - val_mean_squared_error: 2.3547\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2766 - mean_squared_error: 0.2408 - val_loss: 3.4306 - val_mean_squared_error: 2.4058\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2605 - mean_squared_error: 0.2357 - val_loss: 3.6255 - val_mean_squared_error: 2.6141\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2427 - mean_squared_error: 0.2313 - val_loss: 3.8013 - val_mean_squared_error: 2.8021\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.2355 - mean_squared_error: 0.2363 - val_loss: 3.7873 - val_mean_squared_error: 2.7986\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2224 - mean_squared_error: 0.2336 - val_loss: 3.6118 - val_mean_squared_error: 2.6304\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.2051 - mean_squared_error: 0.2237 - val_loss: 3.4369 - val_mean_squared_error: 2.4622\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.1955 - mean_squared_error: 0.2208 - val_loss: 3.3850 - val_mean_squared_error: 2.4194\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.1849 - mean_squared_error: 0.2194 - val_loss: 3.4696 - val_mean_squared_error: 2.5154\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.1692 - mean_squared_error: 0.2149 - val_loss: 3.6041 - val_mean_squared_error: 2.6619\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.1571 - mean_squared_error: 0.2149 - val_loss: 3.6561 - val_mean_squared_error: 2.7242\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.1472 - mean_squared_error: 0.2154 - val_loss: 3.5745 - val_mean_squared_error: 2.6516\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.1329 - mean_squared_error: 0.2100 - val_loss: 3.4352 - val_mean_squared_error: 2.5202\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.1200 - mean_squared_error: 0.2050 - val_loss: 3.3532 - val_mean_squared_error: 2.4471\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.1096 - mean_squared_error: 0.2035 - val_loss: 3.3809 - val_mean_squared_error: 2.4848\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.0971 - mean_squared_error: 0.2011 - val_loss: 3.4769 - val_mean_squared_error: 2.5925\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.0843 - mean_squared_error: 0.1999 - val_loss: 3.5497 - val_mean_squared_error: 2.6765\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0737 - mean_squared_error: 0.2005 - val_loss: 3.5286 - val_mean_squared_error: 2.6650\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0617 - mean_squared_error: 0.1981 - val_loss: 3.4403 - val_mean_squared_error: 2.5850\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0497 - mean_squared_error: 0.1944 - val_loss: 3.3736 - val_mean_squared_error: 2.5264\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0399 - mean_squared_error: 0.1928 - val_loss: 3.3826 - val_mean_squared_error: 2.5450\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0287 - mean_squared_error: 0.1911 - val_loss: 3.4477 - val_mean_squared_error: 2.6205\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0171 - mean_squared_error: 0.1900 - val_loss: 3.4945 - val_mean_squared_error: 2.6772\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.0071 - mean_squared_error: 0.1898 - val_loss: 3.4702 - val_mean_squared_error: 2.6615\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 18us/step - loss: 0.9964 - mean_squared_error: 0.1877 - val_loss: 3.4040 - val_mean_squared_error: 2.6034\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.9858 - mean_squared_error: 0.1852 - val_loss: 3.3679 - val_mean_squared_error: 2.5753\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.9764 - mean_squared_error: 0.1838 - val_loss: 3.3958 - val_mean_squared_error: 2.6121\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.9666 - mean_squared_error: 0.1829 - val_loss: 3.4556 - val_mean_squared_error: 2.6813\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 35us/step - loss: 0.9570 - mean_squared_error: 0.1827 - val_loss: 3.4829 - val_mean_squared_error: 2.7179\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 21us/step - loss: 0.9473 - mean_squared_error: 0.1823 - val_loss: 3.4589 - val_mean_squared_error: 2.7024\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.9375 - mean_squared_error: 0.1810 - val_loss: 3.4202 - val_mean_squared_error: 2.6718\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.9283 - mean_squared_error: 0.1799 - val_loss: 3.4210 - val_mean_squared_error: 2.6813\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.9189 - mean_squared_error: 0.1792 - val_loss: 3.4566 - val_mean_squared_error: 2.7260\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.9094 - mean_squared_error: 0.1788 - val_loss: 3.4876 - val_mean_squared_error: 2.7655\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.9008 - mean_squared_error: 0.1787 - val_loss: 3.4849 - val_mean_squared_error: 2.7713\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.8915 - mean_squared_error: 0.1779 - val_loss: 3.4629 - val_mean_squared_error: 2.7571\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.8829 - mean_squared_error: 0.1770 - val_loss: 3.4575 - val_mean_squared_error: 2.7595\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.8746 - mean_squared_error: 0.1766 - val_loss: 3.4894 - val_mean_squared_error: 2.7996\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.8662 - mean_squared_error: 0.1764 - val_loss: 3.5274 - val_mean_squared_error: 2.8463\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.8576 - mean_squared_error: 0.1765 - val_loss: 3.5331 - val_mean_squared_error: 2.8603\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 3.1590 - mean_squared_error: 0.3088 - val_loss: 4.8669 - val_mean_squared_error: 2.0559\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.3990 - mean_squared_error: 0.5880 - val_loss: 3.6356 - val_mean_squared_error: 0.8076\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.1315 - mean_squared_error: 0.3035 - val_loss: 3.1794 - val_mean_squared_error: 0.3386\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.2834 - mean_squared_error: 0.4426 - val_loss: 3.1804 - val_mean_squared_error: 0.3515\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.2556 - mean_squared_error: 0.4268 - val_loss: 3.3974 - val_mean_squared_error: 0.5905\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.1180 - mean_squared_error: 0.3110 - val_loss: 3.8876 - val_mean_squared_error: 1.1003\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1166 - mean_squared_error: 0.3293 - val_loss: 4.2579 - val_mean_squared_error: 1.4847\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.1812 - mean_squared_error: 0.4079 - val_loss: 4.1659 - val_mean_squared_error: 1.4027\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.1505 - mean_squared_error: 0.3873 - val_loss: 3.7775 - val_mean_squared_error: 1.0202\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.0714 - mean_squared_error: 0.3141 - val_loss: 3.4109 - val_mean_squared_error: 0.6556\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.0516 - mean_squared_error: 0.2963 - val_loss: 3.2247 - val_mean_squared_error: 0.4729\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 3.0841 - mean_squared_error: 0.3323 - val_loss: 3.1917 - val_mean_squared_error: 0.4494\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 3.0827 - mean_squared_error: 0.3405 - val_loss: 3.2772 - val_mean_squared_error: 0.5497\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.0345 - mean_squared_error: 0.3070 - val_loss: 3.4794 - val_mean_squared_error: 0.7685\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.9988 - mean_squared_error: 0.2879 - val_loss: 3.7219 - val_mean_squared_error: 1.0268\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 3.0039 - mean_squared_error: 0.3088 - val_loss: 3.8476 - val_mean_squared_error: 1.1665\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 3.0120 - mean_squared_error: 0.3309 - val_loss: 3.7718 - val_mean_squared_error: 1.1020\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9885 - mean_squared_error: 0.3187 - val_loss: 3.5602 - val_mean_squared_error: 0.8982\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9524 - mean_squared_error: 0.2904 - val_loss: 3.3467 - val_mean_squared_error: 0.6899\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.9381 - mean_squared_error: 0.2814 - val_loss: 3.2173 - val_mean_squared_error: 0.5671\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.9417 - mean_squared_error: 0.2915 - val_loss: 3.1854 - val_mean_squared_error: 0.5460\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.9331 - mean_squared_error: 0.2937 - val_loss: 3.2415 - val_mean_squared_error: 0.6165\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 19us/step - loss: 2.9066 - mean_squared_error: 0.2816 - val_loss: 3.3648 - val_mean_squared_error: 0.7556\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.8840 - mean_squared_error: 0.2748 - val_loss: 3.4989 - val_mean_squared_error: 0.9042\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.8773 - mean_squared_error: 0.2827 - val_loss: 3.5588 - val_mean_squared_error: 0.9770\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.8719 - mean_squared_error: 0.2901 - val_loss: 3.5015 - val_mean_squared_error: 0.9313\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.8537 - mean_squared_error: 0.2834 - val_loss: 3.3661 - val_mean_squared_error: 0.8059\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.8313 - mean_squared_error: 0.2710 - val_loss: 3.2308 - val_mean_squared_error: 0.6796\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.8183 - mean_squared_error: 0.2671 - val_loss: 3.1500 - val_mean_squared_error: 0.6086\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.8111 - mean_squared_error: 0.2697 - val_loss: 3.1390 - val_mean_squared_error: 0.6098\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7974 - mean_squared_error: 0.2682 - val_loss: 3.1894 - val_mean_squared_error: 0.6746\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7779 - mean_squared_error: 0.2630 - val_loss: 3.2739 - val_mean_squared_error: 0.7737\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7626 - mean_squared_error: 0.2625 - val_loss: 3.3404 - val_mean_squared_error: 0.8540\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 2.7528 - mean_squared_error: 0.2664 - val_loss: 3.3421 - val_mean_squared_error: 0.8684\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.7401 - mean_squared_error: 0.2664 - val_loss: 3.2739 - val_mean_squared_error: 0.8116\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.7228 - mean_squared_error: 0.2606 - val_loss: 3.1762 - val_mean_squared_error: 0.7246\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.7071 - mean_squared_error: 0.2555 - val_loss: 3.0981 - val_mean_squared_error: 0.6571\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.6955 - mean_squared_error: 0.2545 - val_loss: 3.0660 - val_mean_squared_error: 0.6367\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6831 - mean_squared_error: 0.2538 - val_loss: 3.0822 - val_mean_squared_error: 0.6663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 31us/step - loss: 2.6671 - mean_squared_error: 0.2513 - val_loss: 3.1289 - val_mean_squared_error: 0.7270\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.6519 - mean_squared_error: 0.2501 - val_loss: 3.1707 - val_mean_squared_error: 0.7822\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.6398 - mean_squared_error: 0.2513 - val_loss: 3.1715 - val_mean_squared_error: 0.7959\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.6268 - mean_squared_error: 0.2512 - val_loss: 3.1268 - val_mean_squared_error: 0.7632\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 2.6115 - mean_squared_error: 0.2479 - val_loss: 3.0614 - val_mean_squared_error: 0.7088\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.5973 - mean_squared_error: 0.2447 - val_loss: 3.0074 - val_mean_squared_error: 0.6659\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.5847 - mean_squared_error: 0.2433 - val_loss: 2.9833 - val_mean_squared_error: 0.6542\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5714 - mean_squared_error: 0.2423 - val_loss: 2.9925 - val_mean_squared_error: 0.6765\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 2.5567 - mean_squared_error: 0.2408 - val_loss: 3.0202 - val_mean_squared_error: 0.7176\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5429 - mean_squared_error: 0.2402 - val_loss: 3.0405 - val_mean_squared_error: 0.7509\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 2.5301 - mean_squared_error: 0.2405 - val_loss: 3.0301 - val_mean_squared_error: 0.7533\n",
      "Train on 285 samples, validate on 142 samples\n",
      "Epoch 151/200\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 1.9725 - mean_squared_error: 0.3857 - val_loss: 3.0258 - val_mean_squared_error: 1.4503\n",
      "Epoch 152/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 2.0744 - mean_squared_error: 0.4989 - val_loss: 2.4025 - val_mean_squared_error: 0.8272\n",
      "Epoch 153/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9518 - mean_squared_error: 0.3765 - val_loss: 2.0610 - val_mean_squared_error: 0.4895\n",
      "Epoch 154/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.9939 - mean_squared_error: 0.4224 - val_loss: 2.0332 - val_mean_squared_error: 0.4691\n",
      "Epoch 155/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9912 - mean_squared_error: 0.4271 - val_loss: 2.1494 - val_mean_squared_error: 0.5952\n",
      "Epoch 156/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9279 - mean_squared_error: 0.3737 - val_loss: 2.3870 - val_mean_squared_error: 0.8402\n",
      "Epoch 157/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.9115 - mean_squared_error: 0.3648 - val_loss: 2.5688 - val_mean_squared_error: 1.0281\n",
      "Epoch 158/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.9311 - mean_squared_error: 0.3904 - val_loss: 2.5262 - val_mean_squared_error: 0.9937\n",
      "Epoch 159/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.9162 - mean_squared_error: 0.3837 - val_loss: 2.3267 - val_mean_squared_error: 0.8007\n",
      "Epoch 160/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8796 - mean_squared_error: 0.3536 - val_loss: 2.1203 - val_mean_squared_error: 0.6009\n",
      "Epoch 161/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8629 - mean_squared_error: 0.3435 - val_loss: 1.9975 - val_mean_squared_error: 0.4856\n",
      "Epoch 162/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.8666 - mean_squared_error: 0.3547 - val_loss: 1.9606 - val_mean_squared_error: 0.4576\n",
      "Epoch 163/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8580 - mean_squared_error: 0.3550 - val_loss: 1.9904 - val_mean_squared_error: 0.4972\n",
      "Epoch 164/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.8308 - mean_squared_error: 0.3376 - val_loss: 2.0731 - val_mean_squared_error: 0.5896\n",
      "Epoch 165/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.8084 - mean_squared_error: 0.3248 - val_loss: 2.1650 - val_mean_squared_error: 0.6894\n",
      "Epoch 166/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.8031 - mean_squared_error: 0.3276 - val_loss: 2.1940 - val_mean_squared_error: 0.7264\n",
      "Epoch 167/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.7980 - mean_squared_error: 0.3304 - val_loss: 2.1306 - val_mean_squared_error: 0.6718\n",
      "Epoch 168/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.7796 - mean_squared_error: 0.3208 - val_loss: 2.0152 - val_mean_squared_error: 0.5644\n",
      "Epoch 169/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.7585 - mean_squared_error: 0.3076 - val_loss: 1.9081 - val_mean_squared_error: 0.4647\n",
      "Epoch 170/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.7466 - mean_squared_error: 0.3032 - val_loss: 1.8436 - val_mean_squared_error: 0.4079\n",
      "Epoch 171/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.7396 - mean_squared_error: 0.3038 - val_loss: 1.8240 - val_mean_squared_error: 0.3971\n",
      "Epoch 172/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.7257 - mean_squared_error: 0.2988 - val_loss: 1.8416 - val_mean_squared_error: 0.4238\n",
      "Epoch 173/200\n",
      "285/285 [==============================] - 0s 25us/step - loss: 1.7070 - mean_squared_error: 0.2892 - val_loss: 1.8796 - val_mean_squared_error: 0.4711\n",
      "Epoch 174/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.6921 - mean_squared_error: 0.2835 - val_loss: 1.9068 - val_mean_squared_error: 0.5073\n",
      "Epoch 175/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.6821 - mean_squared_error: 0.2826 - val_loss: 1.8920 - val_mean_squared_error: 0.5010\n",
      "Epoch 176/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.6702 - mean_squared_error: 0.2792 - val_loss: 1.8335 - val_mean_squared_error: 0.4512\n",
      "Epoch 177/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.6537 - mean_squared_error: 0.2714 - val_loss: 1.7611 - val_mean_squared_error: 0.3877\n",
      "Epoch 178/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.6384 - mean_squared_error: 0.2650 - val_loss: 1.7045 - val_mean_squared_error: 0.3396\n",
      "Epoch 179/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.6271 - mean_squared_error: 0.2622 - val_loss: 1.6742 - val_mean_squared_error: 0.3186\n",
      "Epoch 180/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.6147 - mean_squared_error: 0.2591 - val_loss: 1.6688 - val_mean_squared_error: 0.3224\n",
      "Epoch 181/200\n",
      "285/285 [==============================] - 0s 28us/step - loss: 1.5996 - mean_squared_error: 0.2532 - val_loss: 1.6796 - val_mean_squared_error: 0.3425\n",
      "Epoch 182/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.5849 - mean_squared_error: 0.2478 - val_loss: 1.6894 - val_mean_squared_error: 0.3613\n",
      "Epoch 183/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5730 - mean_squared_error: 0.2449 - val_loss: 1.6791 - val_mean_squared_error: 0.3603\n",
      "Epoch 184/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.5606 - mean_squared_error: 0.2417 - val_loss: 1.6452 - val_mean_squared_error: 0.3348\n",
      "Epoch 185/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5469 - mean_squared_error: 0.2365 - val_loss: 1.6000 - val_mean_squared_error: 0.2984\n",
      "Epoch 186/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.5328 - mean_squared_error: 0.2313 - val_loss: 1.5604 - val_mean_squared_error: 0.2678\n",
      "Epoch 187/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5203 - mean_squared_error: 0.2276 - val_loss: 1.5353 - val_mean_squared_error: 0.2515\n",
      "Epoch 188/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.5078 - mean_squared_error: 0.2241 - val_loss: 1.5246 - val_mean_squared_error: 0.2499\n",
      "Epoch 189/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.4942 - mean_squared_error: 0.2195 - val_loss: 1.5223 - val_mean_squared_error: 0.2565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "285/285 [==============================] - 0s 17us/step - loss: 1.4810 - mean_squared_error: 0.2152 - val_loss: 1.5185 - val_mean_squared_error: 0.2610\n",
      "Epoch 191/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4693 - mean_squared_error: 0.2118 - val_loss: 1.5024 - val_mean_squared_error: 0.2538\n",
      "Epoch 192/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4567 - mean_squared_error: 0.2081 - val_loss: 1.4751 - val_mean_squared_error: 0.2355\n",
      "Epoch 193/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4433 - mean_squared_error: 0.2037 - val_loss: 1.4467 - val_mean_squared_error: 0.2154\n",
      "Epoch 194/200\n",
      "285/285 [==============================] - 0s 38us/step - loss: 1.4310 - mean_squared_error: 0.1997 - val_loss: 1.4240 - val_mean_squared_error: 0.2012\n",
      "Epoch 195/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.4192 - mean_squared_error: 0.1963 - val_loss: 1.4093 - val_mean_squared_error: 0.1951\n",
      "Epoch 196/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.4070 - mean_squared_error: 0.1928 - val_loss: 1.4008 - val_mean_squared_error: 0.1953\n",
      "Epoch 197/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3946 - mean_squared_error: 0.1892 - val_loss: 1.3934 - val_mean_squared_error: 0.1970\n",
      "Epoch 198/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3824 - mean_squared_error: 0.1860 - val_loss: 1.3821 - val_mean_squared_error: 0.1945\n",
      "Epoch 199/200\n",
      "285/285 [==============================] - 0s 21us/step - loss: 1.3706 - mean_squared_error: 0.1830 - val_loss: 1.3653 - val_mean_squared_error: 0.1862\n",
      "Epoch 200/200\n",
      "285/285 [==============================] - 0s 24us/step - loss: 1.3587 - mean_squared_error: 0.1797 - val_loss: 1.3469 - val_mean_squared_error: 0.1761\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.5, 0.1, 0.05, 0.01]:\n",
    "    for i in range(N_MODELS):\n",
    "        histories[i] = train(models[i], [x_train, y_train[:, 0]], (x_val, y_val[:, 0]), lr, 500, history=histories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict target feature using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = []\n",
    "y_val_preds = []\n",
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(x_train))\n",
    "    y_val_preds.append(model.predict(x_val))\n",
    "    y_test_preds.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Use ensemble variance to predict diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_var = np.var(y_train_preds, axis=0)\n",
    "y_val_preds_var = np.var(y_val_preds, axis=0)\n",
    "y_test_preds_var = np.var(y_test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(y_train_preds_var, color='b',  bins=50, label='train')\n",
    "plt.hist(y_val_preds_var, fc=(1, 0, 0, 0.5), bins=50, label='val')\n",
    "plt.hist(y_test_preds_var, fc=(0, 1, 0, 0.5), bins=50, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_preds_var, y, threshold):\n",
    "    for i, pred in enumerate(y_preds_var):\n",
    "        if y[i, 1] == 'B':\n",
    "            acc = y_preds_var < threshold\n",
    "        elif y[i, 1] == 'M':\n",
    "            acc = y_preds_var > threshold\n",
    "            \n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.2 * y_train_preds_var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7473684210526316"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train_preds_var, y_train, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253521126760564"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_val_preds_var, y_val, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6971830985915493"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test_preds_var, y_test, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But best single predictive variable is not known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_healthy.loc[:, TARGET] = y_healthy\n",
    "x_unhealthy.loc[:, TARGET] = y_unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = len(FEATURES + [TARGET])\n",
    "f, ax = plt.subplots(figsize=(width, width))\n",
    "sns.heatmap(x_healthy.corr(), annot=True, linewidths=.5, fmt= '.1f', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "basis = pca.fit(x_healthy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_healthy_transformed = basis.transform(x_healthy)\n",
    "x_unhealthy_transformed = basis.transform(x_unhealthy)\n",
    "\n",
    "plt.figure(figsize=(width, width))\n",
    "plt.scatter(x_healthy_transformed[:, 0], x_healthy_transformed[:, 1])\n",
    "plt.scatter(x_unhealthy_transformed[:, 0], x_unhealthy_transformed[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the fewer dimentions for ensembling variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(x_healthy_transformed))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(x_healthy_transformed)\n",
    "x_train_transformed = x_healthy_transformed[:TRAIN_SIZE, :-1]\n",
    "y_train_transformed = x_healthy_transformed[:TRAIN_SIZE, -1]\n",
    "print('# Examples for training:',  len(x_train_transformed))\n",
    "\n",
    "x_val_transformed = x_healthy_transformed[TRAIN_SIZE:, :-1]\n",
    "y_val_transformed = x_healthy_transformed[TRAIN_SIZE:, -1]\n",
    "print('# Examples for validation:',  len(x_val_transformed))\n",
    "\n",
    "N_FEATURES_TRANSFORMED = x_val_transformed.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "N_MODELS = 5\n",
    "n_hidden_neurons = 32\n",
    "for _ in range(N_MODELS):\n",
    "    models.append(create_base_model(N_FEATURES_TRANSFORMED, n_hidden_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [0.5, 0.1, 0.05, 0.01]:\n",
    "    for i in range(N_MODELS):\n",
    "        histories[i] = train(models[i], [x_train_transformed, y_train_transformed], (x_val_transformed, y_val_transformed), lr, 500, history=histories[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict target feature using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = []\n",
    "y_val_preds = []\n",
    "y_test_preds = []\n",
    "\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(x_train_transformed))\n",
    "    y_val_preds.append(model.predict(x_val_transformed))\n",
    "    y_test_preds.append(model.predict(x_unhealthy_transformed[:, :-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble variance to predict diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_var = np.var(y_train_preds, axis=0)\n",
    "y_val_preds_var = np.var(y_val_preds, axis=0)\n",
    "y_test_preds_var = np.var(y_test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(y_train_preds_var, color='b',  bins=50, label='train')\n",
    "plt.hist(y_val_preds_var, fc=(1, 0, 0, 0.5), bins=50, label='val')\n",
    "plt.hist(y_test_preds_var, fc=(0, 1, 0, 0.5), bins=500, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_var = 1.5 * y_train_preds_var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = (y_train_preds_var < threshold_var).mean()\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (y_val_preds_var < threshold_var).mean()\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (y_test_preds_var >= threshold_var).mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
